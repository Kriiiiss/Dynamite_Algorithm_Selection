{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddea530e-6be0-41c5-9465-167ce81f9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from art.attacks.evasion import SimBA, SpatialTransformation, DeepFool, BasicIterativeMethod, FastGradientMethod, ProjectedGradientDescent\n",
    "# from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac054ea5-7fdd-4616-856d-8a5f56d2d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\n",
    "            \"model\" : '',\n",
    "            \"attack_model\": '',\n",
    "            'epsilon': '',\n",
    "            'Accuracy': '',\n",
    "            'Macro Precision': '',\n",
    "            'Weighted Precision': '',\n",
    "            'Macro Recall': '',\n",
    "            'Weighted Recall': '',\n",
    "            'Macro F1': '',\n",
    "            'Weighted F1': '',\n",
    "\n",
    "        }\n",
    "head = pd.DataFrame([head])\n",
    "head.to_csv(\"./RSLAD_100.csv\", mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e4b2a1-406e-4f69-9a23-4f1a87c2633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    num_classes = len(np.unique(y_test))\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        probabilities = np.array(probabilities)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        print(\"\\nmacro\")\n",
    "        print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "    \n",
    "        print(\"\\nweighted\")\n",
    "        print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "        new_row = {\n",
    "            \"model\" : model_name,\n",
    "            \"attack_model\" : attack_name,\n",
    "            'epsilon': eps,\n",
    "            'Accuracy': accuracy,\n",
    "            'Macro Precision': precision_macro,\n",
    "            'Weighted Precision': precision_weighted,\n",
    "            'Macro Recall': recall_macro,\n",
    "            'Weighted Recall': recall_weighted,\n",
    "            'Macro F1': f1_macro,\n",
    "            'Weighted F1': f1_weighted,\n",
    "\n",
    "        }\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        new_row_df.to_csv(\"./RSLAD_100.csv\", mode='a', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4746ea78-bcfd-4b6d-b6cb-beec089293c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "#     model.eval()\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model.to(device)\n",
    "    \n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     probabilities = []\n",
    "\n",
    "#     num_classes = len(np.unique(y_test))\n",
    "    \n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "#     test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "#     test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "#         all_preds = np.array(all_preds)\n",
    "#         all_labels = np.array(all_labels)\n",
    "#         probabilities = np.array(probabilities)\n",
    "\n",
    "#         np.save(f\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense_Label/UNSW_Def10/y_pred_{attack_name}{eps}_Def10.npy\", all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc5288c-f704-4c1e-8b20-f7df5fcf0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4e66be-bf25-4a39-b3ef-4d0d8b807d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03857e0-e780-4fa8-96f3-e1399d7f2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ac046-77b7-4630-a4a8-fe44438ac801",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884d3dd2-ab96-48dc-85be-71553ba9454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5f35a4-8402-4f6a-bcec-7288dc61b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping variables\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca2345c-93cf-4ba4-8667-fac5279d7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def attack_pgd(model,train_batch_data,train_batch_labels,attack_iters=10,step_size=2/255.0,epsilon=8.0/255.0):\n",
    "    ce_loss = torch.nn.CrossEntropyLoss().cuda()\n",
    "    train_ifgsm_data = train_batch_data.detach() + torch.zeros_like(train_batch_data).uniform_(-epsilon,epsilon)\n",
    "    train_ifgsm_data = torch.clamp(train_ifgsm_data,0,1)\n",
    "    for i in range(attack_iters):\n",
    "        train_ifgsm_data.requires_grad_()\n",
    "        logits = model(train_ifgsm_data)\n",
    "        loss = ce_loss(logits,train_batch_labels.cuda())\n",
    "        loss.backward()\n",
    "        train_grad = train_ifgsm_data.grad.detach()\n",
    "        train_ifgsm_data = train_ifgsm_data + step_size*torch.sign(train_grad)\n",
    "        train_ifgsm_data = torch.clamp(train_ifgsm_data.detach(),0,1)\n",
    "        train_ifgsm_pert = train_ifgsm_data - train_batch_data\n",
    "        train_ifgsm_pert = torch.clamp(train_ifgsm_pert,-epsilon,epsilon)\n",
    "        train_ifgsm_data = train_batch_data + train_ifgsm_pert\n",
    "        train_ifgsm_data = train_ifgsm_data.detach()\n",
    "    return train_ifgsm_data\n",
    "\n",
    "def rslad_inner_loss(model,\n",
    "                teacher_logits,\n",
    "                x_natural,\n",
    "                y,\n",
    "                optimizer,\n",
    "                step_size=0.003,\n",
    "                epsilon=0.031,\n",
    "                perturb_steps=10,\n",
    "                beta=6.0):\n",
    "    # define KL-loss\n",
    "    criterion_kl = nn.KLDivLoss(size_average=False,reduce=False)\n",
    "    model.eval()\n",
    "    batch_size = len(x_natural)\n",
    "    # generate adversarial example\n",
    "    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).cuda().detach()\n",
    "\n",
    "    for _ in range(perturb_steps):\n",
    "        x_adv.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            loss_kl = criterion_kl(F.log_softmax(model(x_adv), dim=1),\n",
    "                                       F.softmax(teacher_logits, dim=1))\n",
    "            loss_kl = torch.sum(loss_kl)\n",
    "        grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n",
    "        x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
    "        x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
    "        x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    x_adv = Variable(torch.clamp(x_adv, 0.0, 1.0), requires_grad=False)\n",
    "    # zero gradient\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(x_adv)\n",
    "    return logits\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17abf728-a664-4a9b-87fa-387a92bdf414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2381/291553794.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load('/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/dnn_pytorch.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DNNModel(\n",
       "    (fc1): Linear(in_features=56, out_features=50, bias=True)\n",
       "    (fc2): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (fc3): Linear(in_features=30, out_features=20, bias=True)\n",
       "    (fc4): Linear(in_features=20, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "# from rslad_loss import *\n",
    "# from cifar10_models import *\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "# # we fix the random seed to 0, in the same computer, this method can make the results same as before.\n",
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed_all(0)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# prefix = 'mobilenet_v2-CIFAR10_RSLAD'\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "epsilon = 8/255.0\n",
    "multiply = 1\n",
    "\n",
    "\n",
    "\n",
    "student = DNNModel(input_shape,output_shape )\n",
    "student = torch.nn.DataParallel(student)\n",
    "student = student.cuda()\n",
    "student.train()\n",
    "optimizer = optim.SGD(student.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-4)\n",
    "def kl_loss(a,b):\n",
    "    loss = -a*b + torch.log(b+1e-5)*b\n",
    "    return loss\n",
    "teacher = DNNModel(input_shape,output_shape )\n",
    "teacher.load_state_dict(torch.load('/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/dnn_pytorch.pt'))\n",
    "teacher = torch.nn.DataParallel(teacher)\n",
    "teacher = teacher.cuda()\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffab852c-4d7b-4449-b6cf-d7ad427319df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750/686676599.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load('/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/dnn_pytorch.pt'))\n",
      "/opt/conda/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/82332 (0%)]\tLoss: 0.309907\n",
      "Epoch 1, Training Loss: 0.0941, Validation Loss: 0.0535, Validation Accuracy: 0.9203\n",
      "Train Epoch: 1 [0/82332 (0%)]\tLoss: 0.050294\n",
      "Epoch 2, Training Loss: 0.0638, Validation Loss: 0.0914, Validation Accuracy: 0.9379\n",
      "Train Epoch: 2 [0/82332 (0%)]\tLoss: 0.064553\n",
      "Epoch 3, Training Loss: 0.0593, Validation Loss: 0.0238, Validation Accuracy: 0.9503\n",
      "Train Epoch: 3 [0/82332 (0%)]\tLoss: 0.057707\n",
      "Epoch 4, Training Loss: 0.0568, Validation Loss: 0.1077, Validation Accuracy: 0.9292\n",
      "Train Epoch: 4 [0/82332 (0%)]\tLoss: 0.051246\n",
      "Epoch 5, Training Loss: 0.0557, Validation Loss: 0.0553, Validation Accuracy: 0.9538\n",
      "Train Epoch: 5 [0/82332 (0%)]\tLoss: 0.057016\n",
      "Epoch 6, Training Loss: 0.0549, Validation Loss: 0.0232, Validation Accuracy: 0.9525\n",
      "Train Epoch: 6 [0/82332 (0%)]\tLoss: 0.039768\n",
      "Epoch 7, Training Loss: 0.0540, Validation Loss: 0.0534, Validation Accuracy: 0.9530\n",
      "Train Epoch: 7 [0/82332 (0%)]\tLoss: 0.052672\n",
      "Epoch 8, Training Loss: 0.0539, Validation Loss: 0.0586, Validation Accuracy: 0.9351\n",
      "Train Epoch: 8 [0/82332 (0%)]\tLoss: 0.078758\n",
      "Epoch 9, Training Loss: 0.0533, Validation Loss: 0.0310, Validation Accuracy: 0.9413\n",
      "Train Epoch: 9 [0/82332 (0%)]\tLoss: 0.051835\n",
      "Epoch 10, Training Loss: 0.0530, Validation Loss: 0.0735, Validation Accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train_loss = 0.0\n",
    "    for step,(train_batch_data,train_batch_labels) in enumerate(train_loader):\n",
    "        student.train()\n",
    "        train_batch_data = train_batch_data.float().cuda()\n",
    "        train_batch_labels = train_batch_labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(train_batch_data)\n",
    "\n",
    "        adv_logits = rslad_inner_loss(student,teacher_logits,train_batch_data,train_batch_labels,optimizer,step_size=2/255.0,epsilon=epsilon,perturb_steps=3)\n",
    "        student.train()\n",
    "        nat_logits = student(train_batch_data)\n",
    "        kl_Loss1 = kl_loss(torch.log(F.softmax(adv_logits,dim=1)),F.softmax(teacher_logits.detach(),dim=1))\n",
    "        kl_Loss2 = kl_loss(torch.log(F.softmax(nat_logits,dim=1)),F.softmax(teacher_logits.detach(),dim=1))\n",
    "        # multiply 10 to keep consistent with CIFAR-10 dataset\n",
    "        kl_Loss1 = multiply*torch.mean(kl_Loss1)\n",
    "        kl_Loss2 = multiply*torch.mean(kl_Loss2)\n",
    "        loss = 5.0/6.0*kl_Loss1 + 1.0/6.0*kl_Loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, step * len(train_batch_data), len(train_loader.dataset),\n",
    "                100. * step / len(train_loader), loss.item()))\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = student(inputs)\n",
    "            kl_Loss1 = kl_loss(torch.log(F.softmax(adv_logits,dim=1)),F.softmax(teacher_logits.detach(),dim=1))\n",
    "            kl_Loss2 = kl_loss(torch.log(F.softmax(nat_logits,dim=1)),F.softmax(teacher_logits.detach(),dim=1))\n",
    "            # multiply 10 to keep consistent with CIFAR-10 dataset\n",
    "            kl_Loss1 = multiply*torch.mean(kl_Loss1)\n",
    "            kl_Loss2 = multiply*torch.mean(kl_Loss2)\n",
    "            loss = 5.0/6.0*kl_Loss1 + 1.0/6.0*kl_Loss2\n",
    "            \n",
    "            val_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_train_loss / len(val_loader)\n",
    "    val_accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    # print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    \n",
    "    # if (epoch%2 == 0):\n",
    "    #     test_accs = []\n",
    "    #     student.eval()\n",
    "    #     for step,(test_batch_data,test_batch_labels) in enumerate(test_loader):\n",
    "    #         test_ifgsm_data = attack_pgd(student,test_batch_data,test_batch_labels,attack_iters=20,step_size=0.003,epsilon=8.0/255.0)\n",
    "    #         logits = student(test_ifgsm_data)\n",
    "    #         predictions = np.argmax(logits.cpu().detach().numpy(),axis=1)\n",
    "    #         predictions = predictions - test_batch_labels.cpu().detach().numpy()\n",
    "    #         test_accs = test_accs + predictions.tolist()\n",
    "    #     test_accs = np.array(test_accs)\n",
    "    #     test_acc = np.sum(test_accs==0)/len(test_accs)\n",
    "    #     print('robust acc',np.sum(test_accs==0)/len(test_accs))\n",
    "    #     # torch.save(student.state_dict(),'./models/'+prefix+str(np.sum(test_accs==0)/len(test_accs))+'.pth')\n",
    "\n",
    "\n",
    "    # # Early stopping check using min_delta\n",
    "    # if best_loss - avg_val_loss > min_delta:\n",
    "    #     best_loss = avg_val_loss\n",
    "    #     patience_counter = 0\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "\n",
    "    # if patience_counter >= patience:\n",
    "    #     print(\"Early stopping triggered\")\n",
    "    #     break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "224b811e-86a0-49e7-aaea-717094934225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2381/2390732642.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/RSLAD/RSLAD_100.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/RSLAD/RSLAD_100.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f8ba48-e84d-42c6-b472-b24b2e15feda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate_performance_metrics(x_test, y_test, student, 'DNN', 'baseline', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0575444-678d-4c09-909d-4ec33601e1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start XGB 100 baseline\n",
      "(201, 56) (201,)\n",
      "Accuracy: 0.8308457711442786\n",
      "\n",
      "macro\n",
      "Precision: 0.8508196721311476\n",
      "Recall: 0.8059015723912599\n",
      "F1 Score: 0.8160529715762274\n",
      "\n",
      "weighted\n",
      "Precision: 0.8419704754913956\n",
      "Recall: 0.8308457711442786\n",
      "F1 Score: 0.8251362695566098\n",
      "\n",
      "start XGB 100 BIM\n",
      "(26, 56) (26,)\n",
      "Accuracy: 0.8461538461538461\n",
      "\n",
      "macro\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.9047619047619048\n",
      "F1 Score: 0.8045112781954887\n",
      "\n",
      "weighted\n",
      "Precision: 0.9145299145299146\n",
      "Recall: 0.8461538461538461\n",
      "F1 Score: 0.8600347021399654\n",
      "\n",
      "start XGB 100 FGSM\n",
      "(16, 56) (16,)\n",
      "Accuracy: 0.5625\n",
      "\n",
      "macro\n",
      "Precision: 0.75\n",
      "Recall: 0.6111111111111112\n",
      "F1 Score: 0.5151515151515151\n",
      "\n",
      "weighted\n",
      "Precision: 0.78125\n",
      "Recall: 0.5625\n",
      "F1 Score: 0.4962121212121212\n",
      "\n",
      "start XGB 100 PGD\n",
      "(26, 56) (26,)\n",
      "Accuracy: 0.8461538461538461\n",
      "\n",
      "macro\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.9047619047619048\n",
      "F1 Score: 0.8045112781954887\n",
      "\n",
      "weighted\n",
      "Precision: 0.9145299145299146\n",
      "Recall: 0.8461538461538461\n",
      "F1 Score: 0.8600347021399654\n",
      "\n",
      "start XGB 100 DF\n",
      "(318, 56) (318,)\n",
      "Accuracy: 0.9308176100628931\n",
      "\n",
      "macro\n",
      "Precision: 0.8366477272727273\n",
      "Recall: 0.8034869976359338\n",
      "F1 Score: 0.8188690969345485\n",
      "\n",
      "weighted\n",
      "Precision: 0.9278516295025729\n",
      "Recall: 0.9308176100628931\n",
      "F1 Score: 0.9290264338528397\n",
      "\n",
      "start XGB 100 AutoPGD\n",
      "(321, 56) (321,)\n",
      "Accuracy: 0.9314641744548287\n",
      "\n",
      "macro\n",
      "Precision: 0.7560907569276548\n",
      "Recall: 0.8863636363636365\n",
      "F1 Score: 0.8036151279199111\n",
      "\n",
      "weighted\n",
      "Precision: 0.9515068507436486\n",
      "Recall: 0.9314641744548287\n",
      "F1 Score: 0.9383749337269864\n",
      "\n",
      "start XGB 100 ZOO\n",
      "(530, 56) (530,)\n",
      "Accuracy: 0.9056603773584906\n",
      "\n",
      "macro\n",
      "Precision: 0.9026143790849673\n",
      "Recall: 0.8870319175672279\n",
      "F1 Score: 0.8939677662009251\n",
      "\n",
      "weighted\n",
      "Precision: 0.9052114934023923\n",
      "Recall: 0.9056603773584906\n",
      "F1 Score: 0.9047302832891387\n",
      "\n",
      "start XGB 100 CaFA\n",
      "(1731, 56) (1731,)\n",
      "Accuracy: 0.8272674754477181\n",
      "\n",
      "macro\n",
      "Precision: 0.7439162247708307\n",
      "Recall: 0.7885363481643569\n",
      "F1 Score: 0.7608958074338323\n",
      "\n",
      "weighted\n",
      "Precision: 0.8475670420332331\n",
      "Recall: 0.8272674754477181\n",
      "F1 Score: 0.8344722946729096\n",
      "\n",
      "start XGB 100 SINIFGSM\n",
      "(29, 56) (29,)\n",
      "Accuracy: 0.5862068965517241\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.29310344827586204\n",
      "F1 Score: 0.3695652173913043\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.5862068965517241\n",
      "F1 Score: 0.7391304347826086\n",
      "\n",
      "start XGB 100 VNIFGSM\n",
      "(21, 56) (21,)\n",
      "Accuracy: 0.5238095238095238\n",
      "\n",
      "macro\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6875\n",
      "F1 Score: 0.5227272727272727\n",
      "\n",
      "weighted\n",
      "Precision: 0.8412698412698413\n",
      "Recall: 0.5238095238095238\n",
      "F1 Score: 0.5346320346320346\n",
      "\n",
      "start XGB 50 baseline\n",
      "(208, 56) (208,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8509615384615384\n",
      "\n",
      "macro\n",
      "Precision: 0.8705719163465642\n",
      "Recall: 0.8299135556188848\n",
      "F1 Score: 0.8397574492407863\n",
      "\n",
      "weighted\n",
      "Precision: 0.8617988525558947\n",
      "Recall: 0.8509615384615384\n",
      "F1 Score: 0.8466836134863421\n",
      "\n",
      "start XGB 50 BIM\n",
      "(93, 56) (93,)\n",
      "Accuracy: 0.7526881720430108\n",
      "\n",
      "macro\n",
      "Precision: 0.5892857142857143\n",
      "Recall: 0.8693181818181819\n",
      "F1 Score: 0.5763517528223411\n",
      "\n",
      "weighted\n",
      "Precision: 0.955837173579109\n",
      "Recall: 0.7526881720430108\n",
      "F1 Score: 0.8202837994109342\n",
      "\n",
      "start XGB 50 FGSM\n",
      "(20, 56) (20,)\n",
      "Accuracy: 0.5\n",
      "\n",
      "macro\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.5\n",
      "\n",
      "weighted\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.5\n",
      "F1 Score: 0.5\n",
      "\n",
      "start XGB 50 PGD\n",
      "(93, 56) (93,)\n",
      "Accuracy: 0.7526881720430108\n",
      "\n",
      "macro\n",
      "Precision: 0.5892857142857143\n",
      "Recall: 0.8693181818181819\n",
      "F1 Score: 0.5763517528223411\n",
      "\n",
      "weighted\n",
      "Precision: 0.955837173579109\n",
      "Recall: 0.7526881720430108\n",
      "F1 Score: 0.8202837994109342\n",
      "\n",
      "start XGB 50 DF\n",
      "(294, 56) (294,)\n",
      "Accuracy: 0.9047619047619048\n",
      "\n",
      "macro\n",
      "Precision: 0.6499278036258623\n",
      "Recall: 0.663003663003663\n",
      "F1 Score: 0.6560828877005347\n",
      "\n",
      "weighted\n",
      "Precision: 0.9088721321995828\n",
      "Recall: 0.9047619047619048\n",
      "F1 Score: 0.9067513368983956\n",
      "\n",
      "start XGB 50 AutoPGD\n",
      "(375, 56) (375,)\n",
      "Accuracy: 0.9306666666666666\n",
      "\n",
      "macro\n",
      "Precision: 0.8668734491315137\n",
      "Recall: 0.8859507152552992\n",
      "F1 Score: 0.8759920634920635\n",
      "\n",
      "weighted\n",
      "Precision: 0.9327497105045492\n",
      "Recall: 0.9306666666666666\n",
      "F1 Score: 0.9315449735449737\n",
      "\n",
      "start XGB 50 ZOO\n",
      "(566, 56) (566,)\n",
      "Accuracy: 0.9134275618374559\n",
      "\n",
      "macro\n",
      "Precision: 0.9142918825561313\n",
      "Recall: 0.8941368970191557\n",
      "F1 Score: 0.9028196799433751\n",
      "\n",
      "weighted\n",
      "Precision: 0.9135869996399298\n",
      "Recall: 0.9134275618374559\n",
      "F1 Score: 0.9123497556557043\n",
      "\n",
      "start XGB 50 CaFA\n",
      "(1630, 56) (1630,)\n",
      "Accuracy: 0.8460122699386503\n",
      "\n",
      "macro\n",
      "Precision: 0.7597441813971311\n",
      "Recall: 0.7940760389036251\n",
      "F1 Score: 0.774253050891693\n",
      "\n",
      "weighted\n",
      "Precision: 0.8582788279830156\n",
      "Recall: 0.8460122699386503\n",
      "F1 Score: 0.8507753954684265\n",
      "\n",
      "start XGB 50 SINIFGSM\n",
      "(61, 56) (61,)\n",
      "Accuracy: 0.5901639344262295\n",
      "\n",
      "macro\n",
      "Precision: 0.5833333333333334\n",
      "Recall: 0.7767857142857143\n",
      "F1 Score: 0.49917898193760263\n",
      "\n",
      "weighted\n",
      "Precision: 0.9316939890710383\n",
      "Recall: 0.5901639344262295\n",
      "F1 Score: 0.6776494656652939\n",
      "\n",
      "start XGB 50 VNIFGSM\n",
      "(50, 56) (50,)\n",
      "Accuracy: 0.5\n",
      "\n",
      "macro\n",
      "Precision: 0.5833333333333334\n",
      "Recall: 0.7222222222222222\n",
      "F1 Score: 0.45054945054945056\n",
      "\n",
      "weighted\n",
      "Precision: 0.9166666666666667\n",
      "Recall: 0.5\n",
      "F1 Score: 0.5824175824175825\n",
      "\n",
      "start XGB 20 baseline\n",
      "(186, 56) (186,)\n",
      "Accuracy: 0.8225806451612904\n",
      "\n",
      "macro\n",
      "Precision: 0.8454545454545455\n",
      "Recall: 0.8169234333371944\n",
      "F1 Score: 0.8175115207373271\n",
      "\n",
      "weighted\n",
      "Precision: 0.8420658194851743\n",
      "Recall: 0.8225806451612904\n",
      "F1 Score: 0.8188196818789951\n",
      "\n",
      "start XGB 20 BIM\n",
      "(26, 56) (26,)\n",
      "Accuracy: 0.6538461538461539\n",
      "\n",
      "macro\n",
      "Precision: 0.55\n",
      "Recall: 0.8200000000000001\n",
      "F1 Score: 0.48115299334811534\n",
      "\n",
      "weighted\n",
      "Precision: 0.9653846153846154\n",
      "Recall: 0.6538461538461539\n",
      "F1 Score: 0.757462050144977\n",
      "\n",
      "start XGB 20 FGSM\n",
      "(5, 56) (5,)\n",
      "Accuracy: 0.6\n",
      "\n",
      "macro\n",
      "Precision: 0.75\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.5833333333333333\n",
      "\n",
      "weighted\n",
      "Precision: 0.8\n",
      "Recall: 0.6\n",
      "F1 Score: 0.5666666666666667\n",
      "\n",
      "start XGB 20 PGD\n",
      "(26, 56) (26,)\n",
      "Accuracy: 0.6538461538461539\n",
      "\n",
      "macro\n",
      "Precision: 0.55\n",
      "Recall: 0.8200000000000001\n",
      "F1 Score: 0.48115299334811534\n",
      "\n",
      "weighted\n",
      "Precision: 0.9653846153846154\n",
      "Recall: 0.6538461538461539\n",
      "F1 Score: 0.757462050144977\n",
      "\n",
      "start XGB 20 DF\n",
      "(258, 56) (258,)\n",
      "Accuracy: 0.9224806201550387\n",
      "\n",
      "macro\n",
      "Precision: 0.5949764521193093\n",
      "Recall: 0.5949764521193093\n",
      "F1 Score: 0.5949764521193093\n",
      "\n",
      "weighted\n",
      "Precision: 0.9224806201550387\n",
      "Recall: 0.9224806201550387\n",
      "F1 Score: 0.9224806201550387\n",
      "\n",
      "start XGB 20 AutoPGD\n",
      "(308, 56) (308,)\n",
      "Accuracy: 0.9058441558441559\n",
      "\n",
      "macro\n",
      "Precision: 0.7162897046100606\n",
      "Recall: 0.7232142857142857\n",
      "F1 Score: 0.7196748579857515\n",
      "\n",
      "weighted\n",
      "Precision: 0.9073605914540287\n",
      "Recall: 0.9058441558441559\n",
      "F1 Score: 0.9065858661941892\n",
      "\n",
      "start XGB 20 ZOO\n",
      "(495, 56) (495,)\n",
      "Accuracy: 0.8909090909090909\n",
      "\n",
      "macro\n",
      "Precision: 0.8965706232383338\n",
      "Recall: 0.880827067669173\n",
      "F1 Score: 0.8863636363636364\n",
      "\n",
      "weighted\n",
      "Precision: 0.8931184693790393\n",
      "Recall: 0.8909090909090909\n",
      "F1 Score: 0.8898071625344353\n",
      "\n",
      "start XGB 20 CaFA\n",
      "(1183, 56) (1183,)\n",
      "Accuracy: 0.7920540997464074\n",
      "\n",
      "macro\n",
      "Precision: 0.7453132931416929\n",
      "Recall: 0.7470414201183432\n",
      "F1 Score: 0.7461639104040192\n",
      "\n",
      "weighted\n",
      "Precision: 0.7928034513553006\n",
      "Recall: 0.7920540997464074\n",
      "F1 Score: 0.7924190316696074\n",
      "\n",
      "start XGB 20 SINIFGSM\n",
      "(4, 56) (4,)\n",
      "Accuracy: 0.75\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.375\n",
      "F1 Score: 0.42857142857142855\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "F1 Score: 0.8571428571428571\n",
      "\n",
      "start XGB 20 VNIFGSM\n",
      "(7, 56) (7,)\n",
      "Accuracy: 0.8571428571428571\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.42857142857142855\n",
      "F1 Score: 0.46153846153846156\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.8571428571428571\n",
      "F1 Score: 0.9230769230769231\n",
      "\n",
      "start XGB 1 baseline\n",
      "(52, 56) (52,)\n",
      "Accuracy: 0.4230769230769231\n",
      "\n",
      "macro\n",
      "Precision: 0.6938775510204082\n",
      "Recall: 0.5454545454545454\n",
      "F1 Score: 0.3627450980392157\n",
      "\n",
      "weighted\n",
      "Precision: 0.7762951334379906\n",
      "Recall: 0.4230769230769231\n",
      "F1 Score: 0.30995475113122173\n",
      "\n",
      "start XGB 1 BIM\n",
      "(3, 56) (3,)\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "macro\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "weighted\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "start XGB 1 FGSM\n",
      "(5, 56) (5,)\n",
      "Accuracy: 0.4\n",
      "\n",
      "macro\n",
      "Precision: 0.625\n",
      "Recall: 0.625\n",
      "F1 Score: 0.4\n",
      "\n",
      "weighted\n",
      "Precision: 0.85\n",
      "Recall: 0.4\n",
      "F1 Score: 0.4\n",
      "\n",
      "start XGB 1 PGD\n",
      "(3, 56) (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "macro\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "weighted\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.6666666666666666\n",
      "\n",
      "start XGB 1 DF\n",
      "(139, 56) (139,)\n",
      "Accuracy: 0.9568345323741008\n",
      "\n",
      "macro\n",
      "Precision: 0.8383720930232558\n",
      "Recall: 0.8383720930232558\n",
      "F1 Score: 0.8383720930232558\n",
      "\n",
      "weighted\n",
      "Precision: 0.9568345323741008\n",
      "Recall: 0.9568345323741008\n",
      "F1 Score: 0.9568345323741008\n",
      "\n",
      "start XGB 1 AutoPGD\n",
      "(69, 56) (69,)\n",
      "Accuracy: 0.8985507246376812\n",
      "\n",
      "macro\n",
      "Precision: 0.9426229508196722\n",
      "Recall: 0.7666666666666666\n",
      "F1 Score: 0.817391304347826\n",
      "\n",
      "weighted\n",
      "Precision: 0.910192444761226\n",
      "Recall: 0.8985507246376812\n",
      "F1 Score: 0.8862003780718337\n",
      "\n",
      "start XGB 1 ZOO\n",
      "(151, 56) (151,)\n",
      "Accuracy: 0.4370860927152318\n",
      "\n",
      "macro\n",
      "Precision: 0.698581560283688\n",
      "Recall: 0.5526315789473684\n",
      "F1 Score: 0.3795020546289582\n",
      "\n",
      "weighted\n",
      "Precision: 0.776431355972007\n",
      "Recall: 0.4370860927152318\n",
      "F1 Score: 0.33068080494711755\n",
      "\n",
      "start XGB 1 CaFA\n",
      "(375, 56) (375,)\n",
      "Accuracy: 0.448\n",
      "\n",
      "macro\n",
      "Precision: 0.4268967334035827\n",
      "Recall: 0.4251124437781109\n",
      "F1 Score: 0.42563392995878624\n",
      "\n",
      "weighted\n",
      "Precision: 0.4553693946844632\n",
      "Recall: 0.448\n",
      "F1 Score: 0.45132468608720744\n",
      "\n",
      "start XGB 1 SINIFGSM\n",
      "(3, 56) (3,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start XGB 1 VNIFGSM\n",
      "(5, 56) (5,)\n",
      "Accuracy: 0.6\n",
      "\n",
      "macro\n",
      "Precision: 0.75\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.5833333333333333\n",
      "\n",
      "weighted\n",
      "Precision: 0.8\n",
      "Recall: 0.6\n",
      "F1 Score: 0.5666666666666667\n",
      "\n",
      "start RF 100 baseline\n",
      "(237, 56) (237,)\n",
      "Accuracy: 0.9831223628691983\n",
      "\n",
      "macro\n",
      "Precision: 0.9864864864864865\n",
      "Recall: 0.978494623655914\n",
      "F1 Score: 0.9821616739424959\n",
      "\n",
      "weighted\n",
      "Precision: 0.9835785152240849\n",
      "Recall: 0.9831223628691983\n",
      "F1 Score: 0.98305249458362\n",
      "\n",
      "start RF 100 BIM\n",
      "(12, 56) (12,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 100 FGSM\n",
      "(13, 56) (13,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 100 PGD\n",
      "(12, 56) (12,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 100 DF\n",
      "(296, 56) (296,)\n",
      "Accuracy: 0.9222972972972973\n",
      "\n",
      "macro\n",
      "Precision: 0.7573316811235027\n",
      "Recall: 0.7662393162393162\n",
      "F1 Score: 0.7616830608744356\n",
      "\n",
      "weighted\n",
      "Precision: 0.9236606494970808\n",
      "Recall: 0.9222972972972973\n",
      "F1 Score: 0.9229582612331939\n",
      "\n",
      "start RF 100 AutoPGD\n",
      "(371, 56) (371,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 100 ZOO\n",
      "(619, 56) (619,)\n",
      "Accuracy: 0.9983844911147012\n",
      "\n",
      "macro\n",
      "Precision: 0.9988399071925754\n",
      "Recall: 0.9973544973544973\n",
      "F1 Score: 0.9980930199601352\n",
      "\n",
      "weighted\n",
      "Precision: 0.9983882393951775\n",
      "Recall: 0.9983844911147012\n",
      "F1 Score: 0.9983832866884426\n",
      "\n",
      "start RF 100 CaFA\n",
      "(1556, 56) (1556,)\n",
      "Accuracy: 0.903598971722365\n",
      "\n",
      "macro\n",
      "Precision: 0.8612526621657742\n",
      "Recall: 0.8819060206918554\n",
      "F1 Score: 0.8707984588813604\n",
      "\n",
      "weighted\n",
      "Precision: 0.9072029129612238\n",
      "Recall: 0.903598971722365\n",
      "F1 Score: 0.9049377681648549\n",
      "\n",
      "start RF 100 SINIFGSM\n",
      "(5, 56) (5,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 100 VNIFGSM\n",
      "(12, 56) (12,)\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.4583333333333333\n",
      "F1 Score: 0.4782608695652174\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9166666666666666\n",
      "F1 Score: 0.9565217391304349\n",
      "\n",
      "start RF 50 baseline\n",
      "(240, 56) (240,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9208333333333333\n",
      "\n",
      "macro\n",
      "Precision: 0.9363553113553114\n",
      "Recall: 0.9072939668067526\n",
      "F1 Score: 0.9164452588181402\n",
      "\n",
      "weighted\n",
      "Precision: 0.9281631562881562\n",
      "Recall: 0.9208333333333333\n",
      "F1 Score: 0.9194770193922736\n",
      "\n",
      "start RF 50 BIM\n",
      "(8, 56) (8,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 50 FGSM\n",
      "(9, 56) (9,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 50 PGD\n",
      "(8, 56) (8,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 50 DF\n",
      "(273, 56) (273,)\n",
      "Accuracy: 0.9157509157509157\n",
      "\n",
      "macro\n",
      "Precision: 0.6552371541501976\n",
      "Recall: 0.6804917279411764\n",
      "F1 Score: 0.6665958689534328\n",
      "\n",
      "weighted\n",
      "Precision: 0.9224594246333376\n",
      "Recall: 0.9157509157509157\n",
      "F1 Score: 0.9189181409220701\n",
      "\n",
      "start RF 50 AutoPGD\n",
      "(349, 56) (349,)\n",
      "Accuracy: 0.9828080229226361\n",
      "\n",
      "macro\n",
      "Precision: 0.4956647398843931\n",
      "Recall: 0.4956647398843931\n",
      "F1 Score: 0.4956647398843931\n",
      "\n",
      "weighted\n",
      "Precision: 0.9828080229226361\n",
      "Recall: 0.9828080229226361\n",
      "F1 Score: 0.9828080229226361\n",
      "\n",
      "start RF 50 ZOO\n",
      "(644, 56) (644,)\n",
      "Accuracy: 0.9565217391304348\n",
      "\n",
      "macro\n",
      "Precision: 0.9635416666666667\n",
      "Recall: 0.9454181476488132\n",
      "F1 Score: 0.953097851532019\n",
      "\n",
      "weighted\n",
      "Precision: 0.9580976412304052\n",
      "Recall: 0.9565217391304348\n",
      "F1 Score: 0.9560888338018994\n",
      "\n",
      "start RF 50 CaFA\n",
      "(1326, 56) (1326,)\n",
      "Accuracy: 0.8823529411764706\n",
      "\n",
      "macro\n",
      "Precision: 0.8386999001568962\n",
      "Recall: 0.849638036809816\n",
      "F1 Score: 0.8439190168050995\n",
      "\n",
      "weighted\n",
      "Precision: 0.8845287936883497\n",
      "Recall: 0.8823529411764706\n",
      "F1 Score: 0.8832875046870207\n",
      "\n",
      "start RF 50 SINIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input50/x_test_adv_SINIFGSM_Def10.npy not found\n",
      "start RF 50 VNIFGSM\n",
      "(7, 56) (7,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 20 baseline\n",
      "(173, 56) (173,)\n",
      "Accuracy: 0.8670520231213873\n",
      "\n",
      "macro\n",
      "Precision: 0.8830260648442467\n",
      "Recall: 0.8393410306955786\n",
      "F1 Score: 0.8527005515862733\n",
      "\n",
      "weighted\n",
      "Precision: 0.8739972586530652\n",
      "Recall: 0.8670520231213873\n",
      "F1 Score: 0.8630655032505223\n",
      "\n",
      "start RF 20 BIM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input20/x_test_adv_BIM_Def10.npy not found\n",
      "start RF 20 FGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input20/x_test_adv_FGSM_Def10.npy not found\n",
      "start RF 20 PGD\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input20/x_test_adv_PGD_Def10.npy not found\n",
      "start RF 20 DF\n",
      "(222, 56) (222,)\n",
      "Accuracy: 0.9144144144144144\n",
      "\n",
      "macro\n",
      "Precision: 0.6404761904761904\n",
      "Recall: 0.6140096618357488\n",
      "F1 Score: 0.6253663735678123\n",
      "\n",
      "weighted\n",
      "Precision: 0.9061132561132561\n",
      "Recall: 0.9144144144144144\n",
      "F1 Score: 0.9099675214783128\n",
      "\n",
      "start RF 20 AutoPGD\n",
      "(288, 56) (288,)\n",
      "Accuracy: 0.9375\n",
      "\n",
      "macro\n",
      "Precision: 0.4891304347826087\n",
      "Recall: 0.4787234042553192\n",
      "F1 Score: 0.4838709677419355\n",
      "\n",
      "weighted\n",
      "Precision: 0.9578804347826088\n",
      "Recall: 0.9375\n",
      "F1 Score: 0.9475806451612905\n",
      "\n",
      "start RF 20 ZOO\n",
      "(448, 56) (448,)\n",
      "Accuracy: 0.9263392857142857\n",
      "\n",
      "macro\n",
      "Precision: 0.9241358976685112\n",
      "Recall: 0.9117802488164704\n",
      "F1 Score: 0.9174516318155168\n",
      "\n",
      "weighted\n",
      "Precision: 0.926085048632081\n",
      "Recall: 0.9263392857142857\n",
      "F1 Score: 0.9257951436388508\n",
      "\n",
      "start RF 20 CaFA\n",
      "(913, 56) (913,)\n",
      "Accuracy: 0.8378970427163198\n",
      "\n",
      "macro\n",
      "Precision: 0.8275926649729659\n",
      "Recall: 0.8149246954942544\n",
      "F1 Score: 0.8203959890688303\n",
      "\n",
      "weighted\n",
      "Precision: 0.8361741242511931\n",
      "Recall: 0.8378970427163198\n",
      "F1 Score: 0.8363004553660226\n",
      "\n",
      "start RF 20 SINIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input20/x_test_adv_SINIFGSM_Def10.npy not found\n",
      "start RF 20 VNIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input20/x_test_adv_VNIFGSM_Def10.npy not found\n",
      "start RF 1 baseline\n",
      "(8, 56) (8,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 1 BIM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_BIM_Def10.npy not found\n",
      "start RF 1 FGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_FGSM_Def10.npy not found\n",
      "start RF 1 PGD\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_PGD_Def10.npy not found\n",
      "start RF 1 DF\n",
      "(84, 56) (84,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 1 AutoPGD\n",
      "(21, 56) (21,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 1 ZOO\n",
      "(24, 56) (24,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 1 CaFA\n",
      "(78, 56) (78,)\n",
      "Accuracy: 0.6794871794871795\n",
      "\n",
      "macro\n",
      "Precision: 0.6924851680949242\n",
      "Recall: 0.7517241379310344\n",
      "F1 Score: 0.6635030198446936\n",
      "\n",
      "weighted\n",
      "Precision: 0.8159660598684989\n",
      "Recall: 0.6794871794871795\n",
      "F1 Score: 0.6992323178690737\n",
      "\n",
      "start RF 1 SINIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_SINIFGSM_Def10.npy not found\n",
      "start RF 1 VNIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_VNIFGSM_Def10.npy not found\n",
      "start DT 100 baseline\n",
      "(91, 56) (91,)\n",
      "Accuracy: 0.978021978021978\n",
      "\n",
      "macro\n",
      "Precision: 0.9795918367346939\n",
      "Recall: 0.9772727272727273\n",
      "F1 Score: 0.977955426356589\n",
      "\n",
      "weighted\n",
      "Precision: 0.9789190401435299\n",
      "Recall: 0.978021978021978\n",
      "F1 Score: 0.9779953573558223\n",
      "\n",
      "start DT 100 BIM\n",
      "(749, 56) (749,)\n",
      "Accuracy: 0.8491321762349799\n",
      "\n",
      "macro\n",
      "Precision: 0.8678977704778417\n",
      "Recall: 0.8453502648221908\n",
      "F1 Score: 0.8460487662910516\n",
      "\n",
      "weighted\n",
      "Precision: 0.8653890011940367\n",
      "Recall: 0.8491321762349799\n",
      "F1 Score: 0.8467759856174498\n",
      "\n",
      "start DT 100 FGSM\n",
      "(799, 56) (799,)\n",
      "Accuracy: 0.47434292866082606\n",
      "\n",
      "macro\n",
      "Precision: 0.5970476680273858\n",
      "Recall: 0.5930116139367241\n",
      "F1 Score: 0.47415759915759914\n",
      "\n",
      "weighted\n",
      "Precision: 0.7099360282446208\n",
      "Recall: 0.47434292866082606\n",
      "F1 Score: 0.469895020583381\n",
      "\n",
      "start DT 100 PGD\n",
      "(749, 56) (749,)\n",
      "Accuracy: 0.8491321762349799\n",
      "\n",
      "macro\n",
      "Precision: 0.8678977704778417\n",
      "Recall: 0.8453502648221908\n",
      "F1 Score: 0.8460487662910516\n",
      "\n",
      "weighted\n",
      "Precision: 0.8653890011940367\n",
      "Recall: 0.8491321762349799\n",
      "F1 Score: 0.8467759856174498\n",
      "\n",
      "start DT 100 DF\n",
      "(430, 56) (430,)\n",
      "Accuracy: 0.6813953488372093\n",
      "\n",
      "macro\n",
      "Precision: 0.548581452104942\n",
      "Recall: 0.5873041253597697\n",
      "F1 Score: 0.5389696272470438\n",
      "\n",
      "weighted\n",
      "Precision: 0.7982075712643841\n",
      "Recall: 0.6813953488372093\n",
      "F1 Score: 0.7248977658919462\n",
      "\n",
      "start DT 100 AutoPGD\n",
      "(587, 56) (587,)\n",
      "Accuracy: 0.938671209540034\n",
      "\n",
      "macro\n",
      "Precision: 0.9292296527549568\n",
      "Recall: 0.9265778515635632\n",
      "F1 Score: 0.9278869778869778\n",
      "\n",
      "weighted\n",
      "Precision: 0.9385062915175872\n",
      "Recall: 0.938671209540034\n",
      "F1 Score: 0.938576194283179\n",
      "\n",
      "start DT 100 ZOO\n",
      "(240, 56) (240,)\n",
      "Accuracy: 0.9375\n",
      "\n",
      "macro\n",
      "Precision: 0.9603174603174602\n",
      "Recall: 0.8863636363636364\n",
      "F1 Score: 0.9152362788726425\n",
      "\n",
      "weighted\n",
      "Precision: 0.9424603174603174\n",
      "Recall: 0.9375\n",
      "F1 Score: 0.9347849120576394\n",
      "\n",
      "start DT 100 CaFA\n",
      "(4591, 56) (4591,)\n",
      "Accuracy: 0.7203223698540623\n",
      "\n",
      "macro\n",
      "Precision: 0.7157822779518691\n",
      "Recall: 0.7181233329347662\n",
      "F1 Score: 0.7165591534342688\n",
      "\n",
      "weighted\n",
      "Precision: 0.7225977823440504\n",
      "Recall: 0.7203223698540623\n",
      "F1 Score: 0.7210764359041533\n",
      "\n",
      "start DT 100 SINIFGSM\n",
      "(685, 56) (685,)\n",
      "Accuracy: 0.7299270072992701\n",
      "\n",
      "macro\n",
      "Precision: 0.7016666666666667\n",
      "Recall: 0.7342953813542049\n",
      "F1 Score: 0.70584412117667\n",
      "\n",
      "weighted\n",
      "Precision: 0.7697372262773723\n",
      "Recall: 0.7299270072992701\n",
      "F1 Score: 0.7398796286050385\n",
      "\n",
      "start DT 100 VNIFGSM\n",
      "(832, 56) (832,)\n",
      "Accuracy: 0.6514423076923077\n",
      "\n",
      "macro\n",
      "Precision: 0.6862010478308394\n",
      "Recall: 0.6429170692757664\n",
      "F1 Score: 0.6262516109844354\n",
      "\n",
      "weighted\n",
      "Precision: 0.6836071119996057\n",
      "Recall: 0.6514423076923077\n",
      "F1 Score: 0.6297503188605288\n",
      "\n",
      "start DT 50 baseline\n",
      "(212, 56) (212,)\n",
      "Accuracy: 0.8820754716981132\n",
      "\n",
      "macro\n",
      "Precision: 0.8941592261904762\n",
      "Recall: 0.8780215859423781\n",
      "F1 Score: 0.8801311772023069\n",
      "\n",
      "weighted\n",
      "Precision: 0.8914129183513029\n",
      "Recall: 0.8820754716981132\n",
      "F1 Score: 0.8808512862748278\n",
      "\n",
      "start DT 50 BIM\n",
      "(771, 56) (771,)\n",
      "Accuracy: 0.5590142671854734\n",
      "\n",
      "macro\n",
      "Precision: 0.5591932059447984\n",
      "Recall: 0.5563156477242122\n",
      "F1 Score: 0.552215860174645\n",
      "\n",
      "weighted\n",
      "Precision: 0.559173323860429\n",
      "Recall: 0.5590142671854734\n",
      "F1 Score: 0.5535755415768107\n",
      "\n",
      "start DT 50 FGSM\n",
      "(1645, 56) (1645,)\n",
      "Accuracy: 0.37872340425531914\n",
      "\n",
      "macro\n",
      "Precision: 0.3813280609966373\n",
      "Recall: 0.3724570883661793\n",
      "F1 Score: 0.36930714909529627\n",
      "\n",
      "weighted\n",
      "Precision: 0.4156621725867396\n",
      "Recall: 0.37872340425531914\n",
      "F1 Score: 0.3896856117550473\n",
      "\n",
      "start DT 50 PGD\n",
      "(771, 56) (771,)\n",
      "Accuracy: 0.5590142671854734\n",
      "\n",
      "macro\n",
      "Precision: 0.5591932059447984\n",
      "Recall: 0.5563156477242122\n",
      "F1 Score: 0.552215860174645\n",
      "\n",
      "weighted\n",
      "Precision: 0.559173323860429\n",
      "Recall: 0.5590142671854734\n",
      "F1 Score: 0.5535755415768107\n",
      "\n",
      "start DT 50 DF\n",
      "(921, 56) (921,)\n",
      "Accuracy: 0.3550488599348534\n",
      "\n",
      "macro\n",
      "Precision: 0.30228897154972134\n",
      "Recall: 0.3531134460122236\n",
      "F1 Score: 0.3093127897463867\n",
      "\n",
      "weighted\n",
      "Precision: 0.30307980499446635\n",
      "Recall: 0.3550488599348534\n",
      "F1 Score: 0.3106636441401389\n",
      "\n",
      "start DT 50 AutoPGD\n",
      "(802, 56) (802,)\n",
      "Accuracy: 0.78428927680798\n",
      "\n",
      "macro\n",
      "Precision: 0.7672609529900863\n",
      "Recall: 0.732305543394417\n",
      "F1 Score: 0.7437477259840832\n",
      "\n",
      "weighted\n",
      "Precision: 0.7789735566743519\n",
      "Recall: 0.78428927680798\n",
      "F1 Score: 0.7767909962480745\n",
      "\n",
      "start DT 50 ZOO\n",
      "(637, 56) (637,)\n",
      "Accuracy: 0.902668759811617\n",
      "\n",
      "macro\n",
      "Precision: 0.9106087849987157\n",
      "Recall: 0.890028669608182\n",
      "F1 Score: 0.8973499261846838\n",
      "\n",
      "weighted\n",
      "Precision: 0.9056850822290622\n",
      "Recall: 0.902668759811617\n",
      "F1 Score: 0.9014215850301291\n",
      "\n",
      "start DT 50 CaFA\n",
      "(3725, 56) (3725,)\n",
      "Accuracy: 0.6429530201342282\n",
      "\n",
      "macro\n",
      "Precision: 0.5845570599613152\n",
      "Recall: 0.6037133733977522\n",
      "F1 Score: 0.584124637449525\n",
      "\n",
      "weighted\n",
      "Precision: 0.6939821053314813\n",
      "Recall: 0.6429530201342282\n",
      "F1 Score: 0.6608408795372858\n",
      "\n",
      "start DT 50 SINIFGSM\n",
      "(521, 56) (521,)\n",
      "Accuracy: 0.3877159309021113\n",
      "\n",
      "macro\n",
      "Precision: 0.4609556368262045\n",
      "Recall: 0.447077460235355\n",
      "F1 Score: 0.3744038544783844\n",
      "\n",
      "weighted\n",
      "Precision: 0.6131487845975471\n",
      "Recall: 0.3877159309021113\n",
      "F1 Score: 0.4257254122698578\n",
      "\n",
      "start DT 50 VNIFGSM\n",
      "(668, 56) (668,)\n",
      "Accuracy: 0.6452095808383234\n",
      "\n",
      "macro\n",
      "Precision: 0.6311199510403916\n",
      "Recall: 0.5958157475473069\n",
      "F1 Score: 0.5890191191931778\n",
      "\n",
      "weighted\n",
      "Precision: 0.6361519616825101\n",
      "Recall: 0.6452095808383234\n",
      "F1 Score: 0.6185930463748334\n",
      "\n",
      "start DT 20 baseline\n",
      "(323, 56) (323,)\n",
      "Accuracy: 0.7213622291021672\n",
      "\n",
      "macro\n",
      "Precision: 0.7270522100723857\n",
      "Recall: 0.7309831570701135\n",
      "F1 Score: 0.7209101382488479\n",
      "\n",
      "weighted\n",
      "Precision: 0.7397869293866841\n",
      "Recall: 0.7213622291021672\n",
      "F1 Score: 0.7225446205646944\n",
      "\n",
      "start DT 20 BIM\n",
      "(258, 56) (258,)\n",
      "Accuracy: 0.36046511627906974\n",
      "\n",
      "macro\n",
      "Precision: 0.44360955056179774\n",
      "Recall: 0.43725091818394934\n",
      "F1 Score: 0.35883726184200615\n",
      "\n",
      "weighted\n",
      "Precision: 0.5488127123072902\n",
      "Recall: 0.36046511627906974\n",
      "F1 Score: 0.37436448878015116\n",
      "\n",
      "start DT 20 FGSM\n",
      "(205, 56) (205,)\n",
      "Accuracy: 0.33658536585365856\n",
      "\n",
      "macro\n",
      "Precision: 0.44313545491636064\n",
      "Recall: 0.3043859649122807\n",
      "F1 Score: 0.27213868003341685\n",
      "\n",
      "weighted\n",
      "Precision: 0.7949517867271696\n",
      "Recall: 0.33658536585365856\n",
      "F1 Score: 0.457026713124274\n",
      "\n",
      "start DT 20 PGD\n",
      "(258, 56) (258,)\n",
      "Accuracy: 0.36046511627906974\n",
      "\n",
      "macro\n",
      "Precision: 0.44360955056179774\n",
      "Recall: 0.43725091818394934\n",
      "F1 Score: 0.35883726184200615\n",
      "\n",
      "weighted\n",
      "Precision: 0.5488127123072902\n",
      "Recall: 0.36046511627906974\n",
      "F1 Score: 0.37436448878015116\n",
      "\n",
      "start DT 20 DF\n",
      "(496, 56) (496,)\n",
      "Accuracy: 0.4637096774193548\n",
      "\n",
      "macro\n",
      "Precision: 0.3957688338493292\n",
      "Recall: 0.3625226860254084\n",
      "F1 Score: 0.37148192610377484\n",
      "\n",
      "weighted\n",
      "Precision: 0.5503928226638704\n",
      "Recall: 0.46370967741935487\n",
      "F1 Score: 0.499629959510686\n",
      "\n",
      "start DT 20 AutoPGD\n",
      "(639, 56) (639,)\n",
      "Accuracy: 0.7167449139280125\n",
      "\n",
      "macro\n",
      "Precision: 0.6306100217864924\n",
      "Recall: 0.6425985146813965\n",
      "F1 Score: 0.635279723256716\n",
      "\n",
      "weighted\n",
      "Precision: 0.7309463656789441\n",
      "Recall: 0.7167449139280125\n",
      "F1 Score: 0.7229492165288067\n",
      "\n",
      "start DT 20 ZOO\n",
      "(880, 56) (880,)\n",
      "Accuracy: 0.7545454545454545\n",
      "\n",
      "macro\n",
      "Precision: 0.7552437436713438\n",
      "Recall: 0.7575429012281323\n",
      "F1 Score: 0.7541339845609387\n",
      "\n",
      "weighted\n",
      "Precision: 0.760131767552569\n",
      "Recall: 0.7545454545454545\n",
      "F1 Score: 0.7550940811914757\n",
      "\n",
      "start DT 20 CaFA\n",
      "(5003, 56) (5003,)\n",
      "Accuracy: 0.6817909254447332\n",
      "\n",
      "macro\n",
      "Precision: 0.6830024207409288\n",
      "Recall: 0.682591025462663\n",
      "F1 Score: 0.6817268257845525\n",
      "\n",
      "weighted\n",
      "Precision: 0.6835743906391326\n",
      "Recall: 0.6817909254447332\n",
      "F1 Score: 0.6816121686459194\n",
      "\n",
      "start DT 20 SINIFGSM\n",
      "(258, 56) (258,)\n",
      "Accuracy: 0.5116279069767442\n",
      "\n",
      "macro\n",
      "Precision: 0.5331521739130435\n",
      "Recall: 0.5527884615384615\n",
      "F1 Score: 0.47282044628956926\n",
      "\n",
      "weighted\n",
      "Precision: 0.7220874059094483\n",
      "Recall: 0.5116279069767442\n",
      "F1 Score: 0.5604144289834784\n",
      "\n",
      "start DT 20 VNIFGSM\n",
      "(234, 56) (234,)\n",
      "Accuracy: 0.4017094017094017\n",
      "\n",
      "macro\n",
      "Precision: 0.4413461538461539\n",
      "Recall: 0.3773205445544554\n",
      "F1 Score: 0.3391430646332607\n",
      "\n",
      "weighted\n",
      "Precision: 0.700509533201841\n",
      "Recall: 0.4017094017094017\n",
      "F1 Score: 0.48686913828526024\n",
      "\n",
      "start DT 1 baseline\n",
      "(272, 56) (272,)\n",
      "Accuracy: 0.7757352941176471\n",
      "\n",
      "macro\n",
      "Precision: 0.7169949639829158\n",
      "Recall: 0.7363888888888889\n",
      "F1 Score: 0.7248196367858031\n",
      "\n",
      "weighted\n",
      "Precision: 0.7879266833908932\n",
      "Recall: 0.7757352941176471\n",
      "F1 Score: 0.7805222362599572\n",
      "\n",
      "start DT 1 BIM\n",
      "(118, 56) (118,)\n",
      "Accuracy: 0.4576271186440678\n",
      "\n",
      "macro\n",
      "Precision: 0.49175906502846867\n",
      "Recall: 0.4910743265173645\n",
      "F1 Score: 0.4551226551226551\n",
      "\n",
      "weighted\n",
      "Precision: 0.5486456423358035\n",
      "Recall: 0.4576271186440678\n",
      "F1 Score: 0.4676449727297185\n",
      "\n",
      "start DT 1 FGSM\n",
      "(157, 56) (157,)\n",
      "Accuracy: 0.5732484076433121\n",
      "\n",
      "macro\n",
      "Precision: 0.5741642323920805\n",
      "Recall: 0.5807991513437059\n",
      "F1 Score: 0.5647010138630251\n",
      "\n",
      "weighted\n",
      "Precision: 0.6153763460866581\n",
      "Recall: 0.5732484076433121\n",
      "F1 Score: 0.5821843193227031\n",
      "\n",
      "start DT 1 PGD\n",
      "(118, 56) (118,)\n",
      "Accuracy: 0.4576271186440678\n",
      "\n",
      "macro\n",
      "Precision: 0.49175906502846867\n",
      "Recall: 0.4910743265173645\n",
      "F1 Score: 0.4551226551226551\n",
      "\n",
      "weighted\n",
      "Precision: 0.5486456423358035\n",
      "Recall: 0.4576271186440678\n",
      "F1 Score: 0.4676449727297185\n",
      "\n",
      "start DT 1 DF\n",
      "(1010, 56) (1010,)\n",
      "Accuracy: 0.7168316831683168\n",
      "\n",
      "macro\n",
      "Precision: 0.5211690032782312\n",
      "Recall: 0.5389252276516608\n",
      "F1 Score: 0.512377106741573\n",
      "\n",
      "weighted\n",
      "Precision: 0.8139162189916418\n",
      "Recall: 0.7168316831683168\n",
      "F1 Score: 0.7574725011124708\n",
      "\n",
      "start DT 1 AutoPGD\n",
      "(338, 56) (338,)\n",
      "Accuracy: 0.5532544378698225\n",
      "\n",
      "macro\n",
      "Precision: 0.5580061059058848\n",
      "Recall: 0.5601703552708213\n",
      "F1 Score: 0.5507969617757593\n",
      "\n",
      "weighted\n",
      "Precision: 0.577606736554642\n",
      "Recall: 0.5532544378698225\n",
      "F1 Score: 0.5572846986640861\n",
      "\n",
      "start DT 1 ZOO\n",
      "(740, 56) (740,)\n",
      "Accuracy: 0.768918918918919\n",
      "\n",
      "macro\n",
      "Precision: 0.7154468403019296\n",
      "Recall: 0.7280735245991055\n",
      "F1 Score: 0.7208785245869095\n",
      "\n",
      "weighted\n",
      "Precision: 0.7767714619326026\n",
      "Recall: 0.768918918918919\n",
      "F1 Score: 0.7722050696712713\n",
      "\n",
      "start DT 1 CaFA\n",
      "(6001, 56) (6001,)\n",
      "Accuracy: 0.7647058823529411\n",
      "\n",
      "macro\n",
      "Precision: 0.7040251001677069\n",
      "Recall: 0.7104381958654383\n",
      "F1 Score: 0.7070094941873621\n",
      "\n",
      "weighted\n",
      "Precision: 0.7686587212079701\n",
      "Recall: 0.7647058823529411\n",
      "F1 Score: 0.7665258209957908\n",
      "\n",
      "start DT 1 SINIFGSM\n",
      "(109, 56) (109,)\n",
      "Accuracy: 0.43119266055045874\n",
      "\n",
      "macro\n",
      "Precision: 0.5402173913043478\n",
      "Recall: 0.6029684601113172\n",
      "F1 Score: 0.3878623188405797\n",
      "\n",
      "weighted\n",
      "Precision: 0.8672915835660151\n",
      "Recall: 0.43119266055045874\n",
      "F1 Score: 0.5178533439702168\n",
      "\n",
      "start DT 1 VNIFGSM\n",
      "(1237, 56) (1237,)\n",
      "Accuracy: 0.9482619240097009\n",
      "\n",
      "macro\n",
      "Precision: 0.692042306052856\n",
      "Recall: 0.7339662447257385\n",
      "F1 Score: 0.7105671083033547\n",
      "\n",
      "weighted\n",
      "Precision: 0.9538068030277029\n",
      "Recall: 0.9482619240097009\n",
      "F1 Score: 0.9508063823401882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def10\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "percentage = [\"100\", \"50\", \"20\", \"1\"]\n",
    "model_name = [\"XGB\", \"RF\", \"DT\" ]\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                new_row = {\n",
    "                    \"model\" : \"0\",\n",
    "                    \"attack_model\" : \"0\",\n",
    "                    'epsilon': \"0\",\n",
    "                    'Accuracy': \"0\",\n",
    "                    'Macro Precision': \"0\",\n",
    "                    'Weighted Precision': \"0\",\n",
    "                    'Macro Recall': \"0\",\n",
    "                    'Weighted Recall': \"0\",\n",
    "                    'Macro F1': \"0\",\n",
    "                    'Weighted F1': \"0\",\n",
    "                }\n",
    "                new_row_df = pd.DataFrame([new_row])\n",
    "                new_row_df.to_csv(\"./RSLAD_100.csv\", mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fdd08f-c86d-4544-804e-c1bf1c0cf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.save(student.state_dict(), \"./RSLAD_100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b838afa-55ff-4afe-a1b3-d10e5f610b17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for epsilon in epsilon_values:\n",
    "#     filename = f'/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "#     x_test_adv = np.load(filename)\n",
    "\n",
    "#     calculate_performance_metrics(x_test_adv, y_test, student, 'DNN', 'BIM', epsilon)\n",
    "\n",
    "# end_time = time.time()\n",
    "# result = end_time - start_time\n",
    "# print(f\"Execution Time: {result:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e50a5-0df0-4ed8-9798-fcea03c75181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
