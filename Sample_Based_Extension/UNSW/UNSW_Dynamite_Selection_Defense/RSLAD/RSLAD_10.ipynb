{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddea530e-6be0-41c5-9465-167ce81f9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from art.attacks.evasion import SimBA, SpatialTransformation, DeepFool, BasicIterativeMethod, FastGradientMethod, ProjectedGradientDescent\n",
    "# from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac054ea5-7fdd-4616-856d-8a5f56d2d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\n",
    "            \"model\" : '',\n",
    "            \"attack_model\": '',\n",
    "            'epsilon': '',\n",
    "            'Accuracy': '',\n",
    "            'Macro Precision': '',\n",
    "            'Weighted Precision': '',\n",
    "            'Macro Recall': '',\n",
    "            'Weighted Recall': '',\n",
    "            'Macro F1': '',\n",
    "            'Weighted F1': '',\n",
    "\n",
    "        }\n",
    "head = pd.DataFrame([head])\n",
    "head.to_csv(\"./RSLAD10.csv\", mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e4b2a1-406e-4f69-9a23-4f1a87c2633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    num_classes = len(np.unique(y_test))\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        probabilities = np.array(probabilities)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        print(\"\\nmacro\")\n",
    "        print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "    \n",
    "        print(\"\\nweighted\")\n",
    "        print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "\n",
    "        new_row = {\n",
    "            \"model\" : model_name,\n",
    "            \"attack_model\" : attack_name,\n",
    "            'epsilon': eps,\n",
    "            'Accuracy': accuracy,\n",
    "            'Macro Precision': precision_macro,\n",
    "            'Weighted Precision': precision_weighted,\n",
    "            'Macro Recall': recall_macro,\n",
    "            'Weighted Recall': recall_weighted,\n",
    "            'Macro F1': f1_macro,\n",
    "            'Weighted F1': f1_weighted,\n",
    "\n",
    "        }\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        new_row_df.to_csv(\"./RSLAD10.csv\", mode='a', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4edb633-fc01-4e38-926c-aff9c1dc4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "#     model.eval()\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model.to(device)\n",
    "    \n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     probabilities = []\n",
    "\n",
    "#     num_classes = len(np.unique(y_test))\n",
    "    \n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "#     test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "#     test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "#         all_preds = np.array(all_preds)\n",
    "#         all_labels = np.array(all_labels)\n",
    "#         probabilities = np.array(probabilities)\n",
    "\n",
    "#         np.save(f\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense_Label/UNSW_Def9/y_pred_{attack_name}{eps}_Def9.npy\", all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc5288c-f704-4c1e-8b20-f7df5fcf0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4e66be-bf25-4a39-b3ef-4d0d8b807d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03857e0-e780-4fa8-96f3-e1399d7f2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ac046-77b7-4630-a4a8-fe44438ac801",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884d3dd2-ab96-48dc-85be-71553ba9454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5f35a4-8402-4f6a-bcec-7288dc61b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping variables\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca2345c-93cf-4ba4-8667-fac5279d7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def attack_pgd(model,train_batch_data,train_batch_labels,attack_iters=10,step_size=2/255.0,epsilon=8.0/255.0):\n",
    "    ce_loss = torch.nn.CrossEntropyLoss().cuda()\n",
    "    train_ifgsm_data = train_batch_data.detach() + torch.zeros_like(train_batch_data).uniform_(-epsilon,epsilon)\n",
    "    train_ifgsm_data = torch.clamp(train_ifgsm_data,0,1)\n",
    "    for i in range(attack_iters):\n",
    "        train_ifgsm_data.requires_grad_()\n",
    "        logits = model(train_ifgsm_data)\n",
    "        loss = ce_loss(logits,train_batch_labels.cuda())\n",
    "        loss.backward()\n",
    "        train_grad = train_ifgsm_data.grad.detach()\n",
    "        train_ifgsm_data = train_ifgsm_data + step_size*torch.sign(train_grad)\n",
    "        train_ifgsm_data = torch.clamp(train_ifgsm_data.detach(),0,1)\n",
    "        train_ifgsm_pert = train_ifgsm_data - train_batch_data\n",
    "        train_ifgsm_pert = torch.clamp(train_ifgsm_pert,-epsilon,epsilon)\n",
    "        train_ifgsm_data = train_batch_data + train_ifgsm_pert\n",
    "        train_ifgsm_data = train_ifgsm_data.detach()\n",
    "    return train_ifgsm_data\n",
    "\n",
    "def rslad_inner_loss(model,\n",
    "                teacher_logits,\n",
    "                x_natural,\n",
    "                y,\n",
    "                optimizer,\n",
    "                step_size=0.003,\n",
    "                epsilon=0.031,\n",
    "                perturb_steps=10,\n",
    "                beta=6.0):\n",
    "    # define KL-loss\n",
    "    criterion_kl = nn.KLDivLoss(size_average=False,reduce=False)\n",
    "    model.eval()\n",
    "    batch_size = len(x_natural)\n",
    "    # generate adversarial example\n",
    "    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).cuda().detach()\n",
    "\n",
    "    for _ in range(perturb_steps):\n",
    "        x_adv.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            loss_kl = criterion_kl(F.log_softmax(model(x_adv), dim=1),\n",
    "                                       F.softmax(teacher_logits, dim=1))\n",
    "            loss_kl = torch.sum(loss_kl)\n",
    "        grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n",
    "        x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
    "        x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
    "        x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    x_adv = Variable(torch.clamp(x_adv, 0.0, 1.0), requires_grad=False)\n",
    "    # zero gradient\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(x_adv)\n",
    "    return logits\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca52dce-1486-4d31-afa5-69050f518d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3643/713280558.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load('/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/dnn_pytorch.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DNNModel(\n",
       "    (fc1): Linear(in_features=56, out_features=50, bias=True)\n",
       "    (fc2): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (fc3): Linear(in_features=30, out_features=20, bias=True)\n",
       "    (fc4): Linear(in_features=20, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "# from rslad_loss import *\n",
    "# from cifar10_models import *\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "# # we fix the random seed to 0, in the same computer, this method can make the results same as before.\n",
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed_all(0)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# prefix = 'mobilenet_v2-CIFAR10_RSLAD'\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "epsilon = 8/255.0\n",
    "\n",
    "\n",
    "\n",
    "student = DNNModel(input_shape,output_shape )\n",
    "student = torch.nn.DataParallel(student)\n",
    "student = student.cuda()\n",
    "student.train()\n",
    "optimizer = optim.SGD(student.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-4)\n",
    "def kl_loss(a,b):\n",
    "    loss = -a*b + torch.log(b+1e-5)*b\n",
    "    return loss\n",
    "teacher = DNNModel(input_shape,output_shape )\n",
    "teacher.load_state_dict(torch.load('/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/dnn_pytorch.pt'))\n",
    "teacher = torch.nn.DataParallel(teacher)\n",
    "teacher = teacher.cuda()\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffab852c-4d7b-4449-b6cf-d7ad427319df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for epoch in range(0,epochs):\n",
    "#     train_loss = 0.0\n",
    "#     for step,(train_batch_data,train_batch_labels) in enumerate(train_loader):\n",
    "#         student.train()\n",
    "#         train_batch_data = train_batch_data.float().cuda()\n",
    "#         train_batch_labels = train_batch_labels.cuda()\n",
    "#         optimizer.zero_grad()\n",
    "#         with torch.no_grad():\n",
    "#             teacher_logits = teacher(train_batch_data)\n",
    "\n",
    "#         adv_logits = rslad_inner_loss(student,teacher_logits,train_batch_data,train_batch_labels,optimizer,step_size=2/255.0,epsilon=epsilon,perturb_steps=3)\n",
    "#         student.train()\n",
    "#         nat_logits = student(train_batch_data)\n",
    "#         kl_Loss1 = kl_loss(F.log_softmax(adv_logits,dim=1),F.softmax(teacher_logits.detach(),dim=1))\n",
    "#         kl_Loss2 = kl_loss(F.log_softmax(nat_logits,dim=1),F.softmax(teacher_logits.detach(),dim=1))\n",
    "#         kl_Loss1 = torch.mean(kl_Loss1)\n",
    "#         kl_Loss2 = torch.mean(kl_Loss2)\n",
    "#         loss = 5/6.0*kl_Loss1 + 1/6.0*kl_Loss2\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if step % 1000 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, step * len(train_batch_data), len(train_loader.dataset),\n",
    "#                 100. * step / len(train_loader), loss.item()))\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "#     model.eval()\n",
    "#     val_train_loss = 0.0\n",
    "#     correct_predictions = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "#             outputs = student(inputs)\n",
    "#             kl_Loss1 = kl_loss(F.log_softmax(adv_logits,dim=1),F.softmax(teacher_logits.detach(),dim=1))\n",
    "#             kl_Loss2 = kl_loss(F.log_softmax(nat_logits,dim=1),F.softmax(teacher_logits.detach(),dim=1))\n",
    "#             kl_Loss1 = torch.mean(kl_Loss1)\n",
    "#             kl_Loss2 = torch.mean(kl_Loss2)\n",
    "#             loss = 5/6.0*kl_Loss1 + 1/6.0*kl_Loss2\n",
    "            \n",
    "#             val_train_loss += loss.item()\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "#     avg_val_loss = val_train_loss / len(val_loader)\n",
    "#     val_accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "#     # print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    \n",
    "#     # if (epoch%2 == 0):\n",
    "#     #     test_accs = []\n",
    "#     #     student.eval()\n",
    "#     #     for step,(test_batch_data,test_batch_labels) in enumerate(test_loader):\n",
    "#     #         test_ifgsm_data = attack_pgd(student,test_batch_data,test_batch_labels,attack_iters=20,step_size=0.003,epsilon=8.0/255.0)\n",
    "#     #         logits = student(test_ifgsm_data)\n",
    "#     #         predictions = np.argmax(logits.cpu().detach().numpy(),axis=1)\n",
    "#     #         predictions = predictions - test_batch_labels.cpu().detach().numpy()\n",
    "#     #         test_accs = test_accs + predictions.tolist()\n",
    "#     #     test_accs = np.array(test_accs)\n",
    "#     #     test_acc = np.sum(test_accs==0)/len(test_accs)\n",
    "#     #     print('robust acc',np.sum(test_accs==0)/len(test_accs))\n",
    "#     #     # torch.save(student.state_dict(),'./models/'+prefix+str(np.sum(test_accs==0)/len(test_accs))+'.pth')\n",
    "\n",
    "\n",
    "#     # Early stopping check using min_delta\n",
    "#     if best_loss - avg_val_loss > min_delta:\n",
    "#         best_loss = avg_val_loss\n",
    "#         patience_counter = 0\n",
    "#     else:\n",
    "#         patience_counter += 1\n",
    "\n",
    "#     if patience_counter >= patience:\n",
    "#         print(\"Early stopping triggered\")\n",
    "#         break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fffa164-7c22-41d2-a1f0-09ae69276110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3643/3878617628.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/RSLAD/RSLAD_10.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "student.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/RSLAD/RSLAD_10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f8ba48-e84d-42c6-b472-b24b2e15feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_performance_metrics(x_test, y_test, student, 'DNN', 'baseline', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3b32d46-5202-486e-ba9f-4165ffac2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_empty_file():\n",
    "    new_row = {\n",
    "        \"model\" : \"0\",\n",
    "        \"attack_model\" : \"0\",\n",
    "        'epsilon': \"0\",\n",
    "        'Accuracy': \"0\",\n",
    "        'Macro Precision': \"0\",\n",
    "        'Weighted Precision': \"0\",\n",
    "        'Macro Recall': \"0\",\n",
    "        'Weighted Recall': \"0\",\n",
    "        'Macro F1': \"0\",\n",
    "        'Weighted F1': \"0\",\n",
    "    }\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    new_row_df.to_csv(\"./RSLAD10.csv\", mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b45da5d-7819-443b-9ee0-1f31e22f1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage = [\"100\", \"50\", \"20\", \"1\"]\n",
    "# model_name = [\"XGB\", \"RF\", \"DT\" ]\n",
    "\n",
    "percentage = [\"10\"]\n",
    "model_name = [\"RF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0575444-678d-4c09-909d-4ec33601e1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(83075, 56) (83075,)\n",
      "Accuracy: 0.9621667168221487\n",
      "\n",
      "macro\n",
      "Precision: 0.9620425318283572\n",
      "Recall: 0.9579665915529111\n",
      "F1 Score: 0.9599163502312063\n",
      "\n",
      "weighted\n",
      "Precision: 0.9621577999782981\n",
      "Recall: 0.9621667168221487\n",
      "F1 Score: 0.962082916846983\n",
      "\n",
      "start RF 10 BIM\n",
      "(22304, 56) (22304,)\n",
      "Accuracy: 0.8861639167862266\n",
      "\n",
      "macro\n",
      "Precision: 0.8839597219270828\n",
      "Recall: 0.8899162995998431\n",
      "F1 Score: 0.885262442326477\n",
      "\n",
      "weighted\n",
      "Precision: 0.8903168104402914\n",
      "Recall: 0.8861639167862266\n",
      "F1 Score: 0.8866012025762622\n",
      "\n",
      "start RF 10 FGSM\n",
      "(21469, 56) (21469,)\n",
      "Accuracy: 0.8895616936047324\n",
      "\n",
      "macro\n",
      "Precision: 0.8884390161514093\n",
      "Recall: 0.8915896216304152\n",
      "F1 Score: 0.8891141025230904\n",
      "\n",
      "weighted\n",
      "Precision: 0.8917873811691307\n",
      "Recall: 0.8895616936047324\n",
      "F1 Score: 0.8897845047076907\n",
      "\n",
      "start RF 10 PGD\n",
      "(22304, 56) (22304,)\n",
      "Accuracy: 0.8861639167862266\n",
      "\n",
      "macro\n",
      "Precision: 0.8839597219270828\n",
      "Recall: 0.8899162995998431\n",
      "F1 Score: 0.885262442326477\n",
      "\n",
      "weighted\n",
      "Precision: 0.8903168104402914\n",
      "Recall: 0.8861639167862266\n",
      "F1 Score: 0.8866012025762622\n",
      "\n",
      "start RF 10 DF\n",
      "(1863, 56) (1863,)\n",
      "Accuracy: 0.7987117552334944\n",
      "\n",
      "macro\n",
      "Precision: 0.7959809176947344\n",
      "Recall: 0.7777309812038218\n",
      "F1 Score: 0.7838830671667762\n",
      "\n",
      "weighted\n",
      "Precision: 0.7977446795452321\n",
      "Recall: 0.7987117552334944\n",
      "F1 Score: 0.7955211563666801\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(22000, 56) (22000,)\n",
      "Accuracy: 0.6215\n",
      "\n",
      "macro\n",
      "Precision: 0.6268204634762969\n",
      "Recall: 0.6280158166337677\n",
      "F1 Score: 0.6212908578762621\n",
      "\n",
      "weighted\n",
      "Precision: 0.6354630037850161\n",
      "Recall: 0.6215\n",
      "F1 Score: 0.622379044168051\n",
      "\n",
      "start RF 10 ZOO\n",
      "(254178, 56) (254178,)\n",
      "Accuracy: 0.9611571418454784\n",
      "\n",
      "macro\n",
      "Precision: 0.9602490378935629\n",
      "Recall: 0.9572672058248166\n",
      "F1 Score: 0.9587130472419929\n",
      "\n",
      "weighted\n",
      "Precision: 0.9611114217316319\n",
      "Recall: 0.9611571418454784\n",
      "F1 Score: 0.9610940268756069\n",
      "\n",
      "start RF 10 CaFA\n",
      "(70119, 56) (70119,)\n",
      "Accuracy: 0.9977324263038548\n",
      "\n",
      "macro\n",
      "Precision: 0.896484375\n",
      "Recall: 0.9988562796719896\n",
      "F1 Score: 0.9416932802459674\n",
      "\n",
      "weighted\n",
      "Precision: 0.9982018849206349\n",
      "Recall: 0.9977324263038548\n",
      "F1 Score: 0.997862044648145\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(22393, 56) (22393,)\n",
      "Accuracy: 0.9102398070825705\n",
      "\n",
      "macro\n",
      "Precision: 0.9020277782268519\n",
      "Recall: 0.90666470115168\n",
      "F1 Score: 0.9042221030960759\n",
      "\n",
      "weighted\n",
      "Precision: 0.9109734333343377\n",
      "Recall: 0.9102398070825705\n",
      "F1 Score: 0.9104971113684709\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(23107, 56) (23107,)\n",
      "Accuracy: 0.9092915566711386\n",
      "\n",
      "macro\n",
      "Precision: 0.9043456976154653\n",
      "Recall: 0.9116813157884185\n",
      "F1 Score: 0.9071901192218547\n",
      "\n",
      "weighted\n",
      "Precision: 0.9116700861064035\n",
      "Recall: 0.9092915566711386\n",
      "F1 Score: 0.9096989103785926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c459c7a-b0cc-4890-a7b2-37687752ac4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(106624, 56) (106624,)\n",
      "Accuracy: 0.9635635504201681\n",
      "\n",
      "macro\n",
      "Precision: 0.9608442479034335\n",
      "Recall: 0.9530469301274818\n",
      "F1 Score: 0.9568182744076168\n",
      "\n",
      "weighted\n",
      "Precision: 0.9634410581793187\n",
      "Recall: 0.9635635504201681\n",
      "F1 Score: 0.9634081278386397\n",
      "\n",
      "start RF 10 BIM\n",
      "(23291, 56) (23291,)\n",
      "Accuracy: 0.8982439568932206\n",
      "\n",
      "macro\n",
      "Precision: 0.8906725587216529\n",
      "Recall: 0.8993422804098501\n",
      "F1 Score: 0.8942708145464983\n",
      "\n",
      "weighted\n",
      "Precision: 0.900717683479551\n",
      "Recall: 0.8982439568932206\n",
      "F1 Score: 0.8988018687975\n",
      "\n",
      "start RF 10 FGSM\n",
      "(22952, 56) (22952,)\n",
      "Accuracy: 0.8902492157546184\n",
      "\n",
      "macro\n",
      "Precision: 0.8831510371199198\n",
      "Recall: 0.8932853785751131\n",
      "F1 Score: 0.8869116458773537\n",
      "\n",
      "weighted\n",
      "Precision: 0.8941213661395895\n",
      "Recall: 0.8902492157546184\n",
      "F1 Score: 0.8909644697607781\n",
      "\n",
      "start RF 10 PGD\n",
      "(23291, 56) (23291,)\n",
      "Accuracy: 0.8982439568932206\n",
      "\n",
      "macro\n",
      "Precision: 0.8906725587216529\n",
      "Recall: 0.8993422804098501\n",
      "F1 Score: 0.8942708145464983\n",
      "\n",
      "weighted\n",
      "Precision: 0.900717683479551\n",
      "Recall: 0.8982439568932206\n",
      "F1 Score: 0.8988018687975\n",
      "\n",
      "start RF 10 DF\n",
      "(1702, 56) (1702,)\n",
      "Accuracy: 0.7773207990599295\n",
      "\n",
      "macro\n",
      "Precision: 0.7983989806658911\n",
      "Recall: 0.7626999609832228\n",
      "F1 Score: 0.765312184950842\n",
      "\n",
      "weighted\n",
      "Precision: 0.7927827546458815\n",
      "Recall: 0.7773207990599295\n",
      "F1 Score: 0.7703651602383021\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(21830, 56) (21830,)\n",
      "Accuracy: 0.5436555199267064\n",
      "\n",
      "macro\n",
      "Precision: 0.5567444564916435\n",
      "Recall: 0.5578709096155585\n",
      "F1 Score: 0.5432405354312695\n",
      "\n",
      "weighted\n",
      "Precision: 0.5759676667458458\n",
      "Recall: 0.5436555199267064\n",
      "F1 Score: 0.5458414412962876\n",
      "\n",
      "start RF 10 ZOO\n",
      "(321471, 56) (321471,)\n",
      "Accuracy: 0.9632346308065113\n",
      "\n",
      "macro\n",
      "Precision: 0.9601576192026364\n",
      "Recall: 0.9531546364315435\n",
      "F1 Score: 0.9565519352262031\n",
      "\n",
      "weighted\n",
      "Precision: 0.9631075204813517\n",
      "Recall: 0.9632346308065113\n",
      "F1 Score: 0.9630936897269399\n",
      "\n",
      "start RF 10 CaFA\n",
      "(182262, 56) (182262,)\n",
      "Accuracy: 0.9445578343264093\n",
      "\n",
      "macro\n",
      "Precision: 0.953531410729525\n",
      "Recall: 0.8994321952116343\n",
      "F1 Score: 0.9224459791330767\n",
      "\n",
      "weighted\n",
      "Precision: 0.9458767040190148\n",
      "Recall: 0.9445578343264093\n",
      "F1 Score: 0.9428040359659594\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(20450, 56) (20450,)\n",
      "Accuracy: 0.9094376528117359\n",
      "\n",
      "macro\n",
      "Precision: 0.9061151756342682\n",
      "Recall: 0.906417787006224\n",
      "F1 Score: 0.9062655277867492\n",
      "\n",
      "weighted\n",
      "Precision: 0.9094731683347447\n",
      "Recall: 0.9094376528117359\n",
      "F1 Score: 0.9094545168469566\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(23148, 56) (23148,)\n",
      "Accuracy: 0.9003801624330395\n",
      "\n",
      "macro\n",
      "Precision: 0.8930857604815398\n",
      "Recall: 0.901950951081161\n",
      "F1 Score: 0.8967124756236837\n",
      "\n",
      "weighted\n",
      "Precision: 0.9029810837123426\n",
      "Recall: 0.9003801624330395\n",
      "F1 Score: 0.9009351081676051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}_ExcludeCaFA/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}_ExcludeCaFA/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}_ExcludeCaFA\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280014b3-a2ff-4c2a-97cb-3bc91872e054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(110787, 56) (110787,)\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "total_num_attack = [\"2\", \"3\"]\n",
    "for num_attack in total_num_attack:\n",
    "    for m_name in model_name:\n",
    "        for p in percentage:\n",
    "            for attack in attack_names:\n",
    "                print(f\"start {m_name} {p} {attack}\")\n",
    "                \n",
    "                x_path = f\"{base_path}/{m_name}_Exclude{num_attack}Attack/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "                y_path = f\"{base_path}/{m_name}_Exclude{num_attack}Attack/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "    \n",
    "                try:\n",
    "                    x_test_adv = np.load(x_path)\n",
    "                    y_test_adv = np.load(y_path)\n",
    "                    print(x_test_adv.shape, y_test_adv.shape)\n",
    "    \n",
    "                    m_per_name = f\"{m_name}{p}_Exclude{num_attack}Attack\"\n",
    "                    calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "                except FileNotFoundError:\n",
    "                    print(x_path, \"not found\")\n",
    "                    print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50527dba-174d-462f-a747-2eca42318a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start baseline\n",
      "Accuracy: 0.9908060225717311\n",
      "\n",
      "macro\n",
      "Precision: 0.9902313436147947\n",
      "Recall: 0.989985370497293\n",
      "F1 Score: 0.9901081208591951\n",
      "\n",
      "weighted\n",
      "Precision: 0.9908041259415102\n",
      "Recall: 0.9908060225717311\n",
      "F1 Score: 0.9908048690151815\n",
      "\n",
      "start BIM\n",
      "Accuracy: 0.9608836744882676\n",
      "\n",
      "macro\n",
      "Precision: 0.9555090643349888\n",
      "Recall: 0.9612220242445997\n",
      "F1 Score: 0.9582115725029385\n",
      "\n",
      "weighted\n",
      "Precision: 0.9613973422356434\n",
      "Recall: 0.9608836744882676\n",
      "F1 Score: 0.9610055413310338\n",
      "\n",
      "start FGSM\n",
      "Accuracy: 0.965627679427044\n",
      "\n",
      "macro\n",
      "Precision: 0.9616681820326014\n",
      "Recall: 0.9650463040593638\n",
      "F1 Score: 0.9633037569050852\n",
      "\n",
      "weighted\n",
      "Precision: 0.9658470624958607\n",
      "Recall: 0.965627679427044\n",
      "F1 Score: 0.9656903244975327\n",
      "\n",
      "start PGD\n",
      "Accuracy: 0.9608836744882676\n",
      "\n",
      "macro\n",
      "Precision: 0.9555090643349888\n",
      "Recall: 0.9612220242445997\n",
      "F1 Score: 0.9582115725029385\n",
      "\n",
      "weighted\n",
      "Precision: 0.9613973422356434\n",
      "Recall: 0.9608836744882676\n",
      "F1 Score: 0.9610055413310338\n",
      "\n",
      "start DF\n",
      "Accuracy: 0.6889433170048985\n",
      "\n",
      "macro\n",
      "Precision: 0.6683447491414045\n",
      "Recall: 0.6584798742216635\n",
      "F1 Score: 0.6615564135472702\n",
      "\n",
      "weighted\n",
      "Precision: 0.6829281889943404\n",
      "Recall: 0.6889433170048985\n",
      "F1 Score: 0.6842609312968907\n",
      "\n",
      "start AutoPGD\n",
      "Accuracy: 0.9623805900752388\n",
      "\n",
      "macro\n",
      "Precision: 0.9571150992274129\n",
      "Recall: 0.9631017443714258\n",
      "F1 Score: 0.9599328683113121\n",
      "\n",
      "weighted\n",
      "Precision: 0.9629346812275636\n",
      "Recall: 0.9623805900752388\n",
      "F1 Score: 0.9625029402836087\n",
      "\n",
      "start ZOO\n",
      "Accuracy: 0.9918160513367934\n",
      "\n",
      "macro\n",
      "Precision: 0.9914032887309351\n",
      "Recall: 0.9912647642064958\n",
      "F1 Score: 0.9913339331044551\n",
      "\n",
      "weighted\n",
      "Precision: 0.9918150648070715\n",
      "Recall: 0.9918160513367934\n",
      "F1 Score: 0.991815474500344\n",
      "\n",
      "start CaFA\n",
      "Accuracy: 0.9968526973713374\n",
      "\n",
      "macro\n",
      "Precision: 0.8966992946275845\n",
      "Recall: 0.9695965822556716\n",
      "F1 Score: 0.9300033453709876\n",
      "\n",
      "weighted\n",
      "Precision: 0.9972502338677522\n",
      "Recall: 0.9968526973713374\n",
      "F1 Score: 0.9969851063512286\n",
      "\n",
      "start SINIFGSM\n",
      "Accuracy: 0.9520222775617356\n",
      "\n",
      "macro\n",
      "Precision: 0.94370026073728\n",
      "Recall: 0.9543822900570372\n",
      "F1 Score: 0.9485185873673484\n",
      "\n",
      "weighted\n",
      "Precision: 0.9534971084932056\n",
      "Recall: 0.9520222775617356\n",
      "F1 Score: 0.9523074693103711\n",
      "\n",
      "start VNIFGSM\n",
      "Accuracy: 0.9579165712249624\n",
      "\n",
      "macro\n",
      "Precision: 0.9523575799995836\n",
      "Recall: 0.9585601401084332\n",
      "F1 Score: 0.955262225640541\n",
      "\n",
      "weighted\n",
      "Precision: 0.9585508144252955\n",
      "Recall: 0.9579165712249624\n",
      "F1 Score: 0.9580598207411166\n",
      "\n",
      "start baseline\n",
      "Accuracy: 0.9911919396742919\n",
      "\n",
      "macro\n",
      "Precision: 0.9906641120917727\n",
      "Recall: 0.9901995185576207\n",
      "F1 Score: 0.9904310622250349\n",
      "\n",
      "weighted\n",
      "Precision: 0.9911890534314043\n",
      "Recall: 0.9911919396742919\n",
      "F1 Score: 0.991189853673195\n",
      "\n",
      "start BIM\n",
      "Accuracy: 0.9586841323296355\n",
      "\n",
      "macro\n",
      "Precision: 0.9516250789775338\n",
      "Recall: 0.9604607079798904\n",
      "F1 Score: 0.9556907310608161\n",
      "\n",
      "weighted\n",
      "Precision: 0.959695245331473\n",
      "Recall: 0.9586841323296355\n",
      "F1 Score: 0.9588841867277755\n",
      "\n",
      "start FGSM\n",
      "Accuracy: 0.9722089604744076\n",
      "\n",
      "macro\n",
      "Precision: 0.9696567289232212\n",
      "Recall: 0.9706912867964033\n",
      "F1 Score: 0.9701694384383494\n",
      "\n",
      "weighted\n",
      "Precision: 0.9722475108347858\n",
      "Recall: 0.9722089604744076\n",
      "F1 Score: 0.9722242480699114\n",
      "\n",
      "start PGD\n",
      "Accuracy: 0.9586841323296355\n",
      "\n",
      "macro\n",
      "Precision: 0.9516250789775338\n",
      "Recall: 0.9604607079798904\n",
      "F1 Score: 0.9556907310608161\n",
      "\n",
      "weighted\n",
      "Precision: 0.959695245331473\n",
      "Recall: 0.9586841323296355\n",
      "F1 Score: 0.9588841867277755\n",
      "\n",
      "start DF\n",
      "Accuracy: 0.839541547277937\n",
      "\n",
      "macro\n",
      "Precision: 0.8328239795918367\n",
      "Recall: 0.8241232086199186\n",
      "F1 Score: 0.8279152075534625\n",
      "\n",
      "weighted\n",
      "Precision: 0.8384171059336547\n",
      "Recall: 0.839541547277937\n",
      "F1 Score: 0.8384796138857803\n",
      "\n",
      "start AutoPGD\n",
      "Accuracy: 0.9619108643030044\n",
      "\n",
      "macro\n",
      "Precision: 0.9558916315010064\n",
      "Recall: 0.9629770258021965\n",
      "F1 Score: 0.9592062504775954\n",
      "\n",
      "weighted\n",
      "Precision: 0.9626018940506659\n",
      "Recall: 0.9619108643030044\n",
      "F1 Score: 0.9620576861963839\n",
      "\n",
      "start ZOO\n",
      "Accuracy: 0.9922780697179991\n",
      "\n",
      "macro\n",
      "Precision: 0.9919025690815593\n",
      "Recall: 0.9916223870837239\n",
      "F1 Score: 0.991762137019288\n",
      "\n",
      "weighted\n",
      "Precision: 0.9922764720985285\n",
      "Recall: 0.9922780697179991\n",
      "F1 Score: 0.992276969824609\n",
      "\n",
      "start CaFA\n",
      "Accuracy: 0.9971868646074145\n",
      "\n",
      "macro\n",
      "Precision: 0.9012978292733449\n",
      "Recall: 0.9703301691326474\n",
      "F1 Score: 0.9330162070276659\n",
      "\n",
      "weighted\n",
      "Precision: 0.99752034414877\n",
      "Recall: 0.9971868646074145\n",
      "F1 Score: 0.9972982561475632\n",
      "\n",
      "start SINIFGSM\n",
      "Accuracy: 0.9638384918611737\n",
      "\n",
      "macro\n",
      "Precision: 0.9571797048511557\n",
      "Recall: 0.965064299405443\n",
      "F1 Score: 0.9608741587418231\n",
      "\n",
      "weighted\n",
      "Precision: 0.9645709869957775\n",
      "Recall: 0.9638384918611737\n",
      "F1 Score: 0.963993036266854\n",
      "\n",
      "start VNIFGSM\n",
      "Accuracy: 0.9604022391143726\n",
      "\n",
      "macro\n",
      "Precision: 0.9545652588249816\n",
      "Recall: 0.9609665728326504\n",
      "F1 Score: 0.9575793966440957\n",
      "\n",
      "weighted\n",
      "Precision: 0.9610041432536636\n",
      "Recall: 0.9604022391143726\n",
      "F1 Score: 0.9605406473329745\n",
      "\n",
      "start baseline\n",
      "Accuracy: 0.9916973585956386\n",
      "\n",
      "macro\n",
      "Precision: 0.9911591769201683\n",
      "Recall: 0.9907923501254791\n",
      "F1 Score: 0.9909752974596144\n",
      "\n",
      "weighted\n",
      "Precision: 0.991695051793797\n",
      "Recall: 0.9916973585956386\n",
      "F1 Score: 0.9916958077909257\n",
      "\n",
      "start BIM\n",
      "Accuracy: 0.9593865521031072\n",
      "\n",
      "macro\n",
      "Precision: 0.9530643928255648\n",
      "Recall: 0.9605537527473882\n",
      "F1 Score: 0.956548471258342\n",
      "\n",
      "weighted\n",
      "Precision: 0.9601741965313725\n",
      "Recall: 0.9593865521031072\n",
      "F1 Score: 0.959552975921213\n",
      "\n",
      "start FGSM\n",
      "Accuracy: 0.9677435480847341\n",
      "\n",
      "macro\n",
      "Precision: 0.963982310723448\n",
      "Recall: 0.9669268512005804\n",
      "F1 Score: 0.9654164535175674\n",
      "\n",
      "weighted\n",
      "Precision: 0.9679121469714278\n",
      "Recall: 0.9677435480847341\n",
      "F1 Score: 0.9677945611907305\n",
      "\n",
      "start PGD\n",
      "Accuracy: 0.9593865521031072\n",
      "\n",
      "macro\n",
      "Precision: 0.9530643928255648\n",
      "Recall: 0.9605537527473882\n",
      "F1 Score: 0.956548471258342\n",
      "\n",
      "weighted\n",
      "Precision: 0.9601741965313725\n",
      "Recall: 0.9593865521031072\n",
      "F1 Score: 0.959552975921213\n",
      "\n",
      "start DF\n",
      "Accuracy: 0.6771653543307087\n",
      "\n",
      "macro\n",
      "Precision: 0.6665704931862966\n",
      "Recall: 0.6627663294299085\n",
      "F1 Score: 0.6640995533638288\n",
      "\n",
      "weighted\n",
      "Precision: 0.6745210462247823\n",
      "Recall: 0.6771653543307087\n",
      "F1 Score: 0.6753023598962676\n",
      "\n",
      "start AutoPGD\n",
      "Accuracy: 0.962873514230241\n",
      "\n",
      "macro\n",
      "Precision: 0.9567359752165092\n",
      "Recall: 0.9638171663890382\n",
      "F1 Score: 0.9600618409950757\n",
      "\n",
      "weighted\n",
      "Precision: 0.9635301391618596\n",
      "Recall: 0.962873514230241\n",
      "F1 Score: 0.963016280790192\n",
      "\n",
      "start ZOO\n",
      "Accuracy: 0.9920996218416552\n",
      "\n",
      "macro\n",
      "Precision: 0.9917174430383063\n",
      "Recall: 0.9914216346443914\n",
      "F1 Score: 0.9915691601079117\n",
      "\n",
      "weighted\n",
      "Precision: 0.9920979130708177\n",
      "Recall: 0.9920996218416552\n",
      "F1 Score: 0.9920984333031057\n",
      "\n",
      "start CaFA\n",
      "Accuracy: 0.996876084692815\n",
      "\n",
      "macro\n",
      "Precision: 0.8910013499893037\n",
      "Recall: 0.9735351167799029\n",
      "F1 Score: 0.928232414381262\n",
      "\n",
      "weighted\n",
      "Precision: 0.9973370187036459\n",
      "Recall: 0.996876084692815\n",
      "F1 Score: 0.997025182954565\n",
      "\n",
      "start SINIFGSM\n",
      "Accuracy: 0.9607645017956054\n",
      "\n",
      "macro\n",
      "Precision: 0.9553655477014575\n",
      "Recall: 0.959552029896449\n",
      "F1 Score: 0.957390929594393\n",
      "\n",
      "weighted\n",
      "Precision: 0.9610596577374605\n",
      "Recall: 0.9607645017956054\n",
      "F1 Score: 0.9608542632779858\n",
      "\n",
      "start VNIFGSM\n",
      "Accuracy: 0.9538289944599696\n",
      "\n",
      "macro\n",
      "Precision: 0.9462167860635242\n",
      "Recall: 0.9552542384593952\n",
      "F1 Score: 0.9503714415195637\n",
      "\n",
      "weighted\n",
      "Precision: 0.9549207822871099\n",
      "Recall: 0.9538289944599696\n",
      "F1 Score: 0.9540603542829147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "rec_list = [\"Euclidean\", \"cosine\", \"manhattan\"]\n",
    "for rec in rec_list:\n",
    "    for attack in attack_names:\n",
    "        print(f\"start {attack}\")\n",
    "        \n",
    "        x_path = f\"{base_path}/Recommendation_{rec}/x_test_adv_{attack}_{Def}.npy\"\n",
    "        y_path = f\"{base_path}/Recommendation_{rec}/y_test_adv_{attack}_{Def}.npy\"\n",
    "    \n",
    "        try:\n",
    "            x_test_adv = np.load(x_path)\n",
    "            y_test_adv = np.load(y_path)\n",
    "            m_per_name = f\"Recommendation_{rec}\"\n",
    "            calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "        except FileNotFoundError:\n",
    "            print(x_path, \"not found\")\n",
    "            print_empty_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2d8a0-fd58-4076-bba7-6ec334b7de91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}_Cluster/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}_Cluster/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}_Cluster\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2c66e-f2a1-4ed9-b5e6-59b2f2189a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}_ActiveLearning/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}_ActiveLearning/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}_ActiveLearning\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3a839-9b34-4d68-a994-930ad644abba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0\n",
    "\n",
    "Def = \"Def9\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "active_learning_name = [\"DensityWeighted\", \"BatchMode\"]\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for ac_name in active_learning_name:\n",
    "    for m_name in model_name:\n",
    "        for p in percentage:\n",
    "            for attack in attack_names:\n",
    "                print(f\"start {m_name} {p} {attack}\")\n",
    "                \n",
    "                x_path = f\"{base_path}/{m_name}_ActiveLearning_{ac_name}/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "                y_path = f\"{base_path}/{m_name}_ActiveLearning_{ac_name}/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "    \n",
    "                try:\n",
    "                    x_test_adv = np.load(x_path)\n",
    "                    y_test_adv = np.load(y_path)\n",
    "                    m_per_name = f\"{m_name}{p}_ActiveLearning_{ac_name}\"\n",
    "                    calculate_performance_metrics(x_test_adv, y_test_adv, student, m_per_name, attack, epsilon)\n",
    "                except FileNotFoundError:\n",
    "                    print(x_path, \"not found\")\n",
    "                    print_empty_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae3110-7c5b-4c3d-b2b6-f8ae975c84f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fdd08f-c86d-4544-804e-c1bf1c0cf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(student.state_dict(), \"./RSLAD_10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ace4220-4ead-4605-a8b5-68ad9e2c8acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for epsilon in epsilon_values:\n",
    "#     filename = f'/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "#     x_test_adv = np.load(filename)\n",
    "\n",
    "#     calculate_performance_metrics(x_test_adv, y_test, student, 'DNN', 'BIM', epsilon)\n",
    "\n",
    "# end_time = time.time()\n",
    "# result = end_time - start_time\n",
    "# print(f\"Execution Time: {result:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b7048d-d68a-4f93-9869-8479d4974a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
