{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddea530e-6be0-41c5-9465-167ce81f9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from art.attacks.evasion import SimBA, SpatialTransformation, DeepFool, BasicIterativeMethod, FastGradientMethod, ProjectedGradientDescent\n",
    "# from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac054ea5-7fdd-4616-856d-8a5f56d2d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\n",
    "            \"model\" : '',\n",
    "            \"attack_model\": '',\n",
    "            'epsilon': '',\n",
    "            'Accuracy': '',\n",
    "            'Macro Precision': '',\n",
    "            'Weighted Precision': '',\n",
    "            'Macro Recall': '',\n",
    "            'Weighted Recall': '',\n",
    "            'Macro F1': '',\n",
    "            'Weighted F1': '',\n",
    "\n",
    "        }\n",
    "head = pd.DataFrame([head])\n",
    "head.to_csv(\"./TRADES.csv\", mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e4b2a1-406e-4f69-9a23-4f1a87c2633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    num_classes = len(np.unique(y_test))\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        probabilities = np.array(probabilities)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        print(\"\\nmacro\")\n",
    "        print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "    \n",
    "        print(\"\\nweighted\")\n",
    "        print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "\n",
    "        new_row = {\n",
    "            \"model\" : model_name,\n",
    "            \"attack_model\" : attack_name,\n",
    "            'epsilon': eps,\n",
    "            'Accuracy': accuracy,\n",
    "            'Macro Precision': precision_macro,\n",
    "            'Weighted Precision': precision_weighted,\n",
    "            'Macro Recall': recall_macro,\n",
    "            'Weighted Recall': recall_weighted,\n",
    "            'Macro F1': f1_macro,\n",
    "            'Weighted F1': f1_weighted,\n",
    "\n",
    "        }\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        new_row_df.to_csv(\"./TRADES.csv\", mode='a', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbe616e-3fb4-406b-94df-75aa67c86013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "#     model.eval()\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model.to(device)\n",
    "    \n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     probabilities = []\n",
    "\n",
    "#     num_classes = len(np.unique(y_test))\n",
    "    \n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "#     test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "#     test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "#         all_preds = np.array(all_preds)\n",
    "#         all_labels = np.array(all_labels)\n",
    "#         probabilities = np.array(probabilities)\n",
    "\n",
    "#         np.save(f\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense_Label/UNSW_Def3/y_pred_{attack_name}{eps}_Def3.npy\", all_preds)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc5288c-f704-4c1e-8b20-f7df5fcf0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4e66be-bf25-4a39-b3ef-4d0d8b807d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03857e0-e780-4fa8-96f3-e1399d7f2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ac046-77b7-4630-a4a8-fe44438ac801",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884d3dd2-ab96-48dc-85be-71553ba9454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5f35a4-8402-4f6a-bcec-7288dc61b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping variables\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffab852c-4d7b-4449-b6cf-d7ad427319df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_l2_norm(x):\n",
    "    flattened = x.view(x.unsqueeze(0).shape[0], -1)\n",
    "    return (flattened ** 2).sum(1)\n",
    "\n",
    "\n",
    "def l2_norm(x):\n",
    "    return squared_l2_norm(x).sqrt()\n",
    "\n",
    "def trades_loss(model,\n",
    "                x_natural,\n",
    "                y,\n",
    "                optimizer,\n",
    "                step_size=0.003,\n",
    "                epsilon=0.031,\n",
    "                perturb_steps=10,\n",
    "                beta=1.0,\n",
    "                distance='l_inf'):\n",
    "    # define KL-loss\n",
    "    criterion_kl = nn.KLDivLoss(size_average=False)\n",
    "    model.eval()\n",
    "    batch_size = len(x_natural)\n",
    "    # generate adversarial example\n",
    "    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).cuda().detach()\n",
    "    if distance == 'l_inf':\n",
    "        for _ in range(perturb_steps):\n",
    "            x_adv.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                loss_kl = criterion_kl(F.log_softmax(model(x_adv), dim=1),\n",
    "                                       F.softmax(model(x_natural), dim=1))\n",
    "            grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n",
    "            x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
    "            x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
    "            x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
    "    elif distance == 'l_2':\n",
    "        delta = 0.001 * torch.randn(x_natural.shape).cuda().detach()\n",
    "        delta = Variable(delta.data, requires_grad=True)\n",
    "\n",
    "        # Setup optimizers\n",
    "        optimizer_delta = optim.SGD([delta], lr=epsilon / perturb_steps * 2)\n",
    "\n",
    "        for _ in range(perturb_steps):\n",
    "            adv = x_natural + delta\n",
    "\n",
    "            # optimize\n",
    "            optimizer_delta.zero_grad()\n",
    "            with torch.enable_grad():\n",
    "                loss = (-1) * criterion_kl(F.log_softmax(model(adv), dim=1),\n",
    "                                           F.softmax(model(x_natural), dim=1))\n",
    "            loss.backward()\n",
    "            # renorming gradient\n",
    "            grad_norms = delta.grad.view(batch_size, -1).norm(p=2, dim=1)\n",
    "            delta.grad.div_(grad_norms.view(-1, 1, 1, 1))\n",
    "            # avoid nan or inf if gradient is 0\n",
    "            if (grad_norms == 0).any():\n",
    "                delta.grad[grad_norms == 0] = torch.randn_like(delta.grad[grad_norms == 0])\n",
    "            optimizer_delta.step()\n",
    "\n",
    "            # projection\n",
    "            delta.data.add_(x_natural)\n",
    "            delta.data.clamp_(0, 1).sub_(x_natural)\n",
    "            delta.data.renorm_(p=2, dim=0, maxnorm=epsilon)\n",
    "        x_adv = Variable(x_natural + delta, requires_grad=False)\n",
    "    else:\n",
    "        x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
    "    model.train()\n",
    "\n",
    "    x_adv = Variable(torch.clamp(x_adv, 0.0, 1.0), requires_grad=False)\n",
    "    # zero gradient\n",
    "    optimizer.zero_grad()\n",
    "    # calculate robust loss\n",
    "    logits = model(x_natural)\n",
    "    loss_natural = F.cross_entropy(logits, y)\n",
    "    loss_robust = (1.0 / batch_size) * criterion_kl(F.log_softmax(model(x_adv), dim=1),\n",
    "                                                    F.softmax(model(x_natural), dim=1))\n",
    "    loss = loss_natural + beta * loss_robust\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d824aac-2798-43f7-bfaf-bccc40831fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/82332 (0%)]\tLoss: 0.705058\n",
      "Epoch 1, Training Loss: 0.2773, Validation Loss: 0.1762, Validation Accuracy: 0.9258\n",
      "Train Epoch: 1 [0/82332 (0%)]\tLoss: 0.190182\n",
      "Epoch 2, Training Loss: 0.2040, Validation Loss: 0.1628, Validation Accuracy: 0.9343\n",
      "Train Epoch: 2 [0/82332 (0%)]\tLoss: 0.182946\n",
      "Epoch 3, Training Loss: 0.1901, Validation Loss: 0.1589, Validation Accuracy: 0.9326\n",
      "Train Epoch: 3 [0/82332 (0%)]\tLoss: 0.184759\n",
      "Epoch 4, Training Loss: 0.1826, Validation Loss: 0.1456, Validation Accuracy: 0.9412\n",
      "Train Epoch: 4 [0/82332 (0%)]\tLoss: 0.158653\n",
      "Epoch 5, Training Loss: 0.1784, Validation Loss: 0.1448, Validation Accuracy: 0.9436\n",
      "Train Epoch: 5 [0/82332 (0%)]\tLoss: 0.214495\n",
      "Epoch 6, Training Loss: 0.1743, Validation Loss: 0.1377, Validation Accuracy: 0.9521\n",
      "Train Epoch: 6 [0/82332 (0%)]\tLoss: 0.208758\n",
      "Epoch 7, Training Loss: 0.1721, Validation Loss: 0.1404, Validation Accuracy: 0.9470\n",
      "Train Epoch: 7 [0/82332 (0%)]\tLoss: 0.243931\n",
      "Epoch 8, Training Loss: 0.1703, Validation Loss: 0.1355, Validation Accuracy: 0.9491\n",
      "Train Epoch: 8 [0/82332 (0%)]\tLoss: 0.165198\n",
      "Epoch 9, Training Loss: 0.1682, Validation Loss: 0.1309, Validation Accuracy: 0.9547\n",
      "Train Epoch: 9 [0/82332 (0%)]\tLoss: 0.148023\n",
      "Epoch 10, Training Loss: 0.1668, Validation Loss: 0.1333, Validation Accuracy: 0.9550\n"
     ]
    }
   ],
   "source": [
    "# Adversarial training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # calculate robust loss - TRADES loss\n",
    "        loss = trades_loss(model=model,\n",
    "                           x_natural=data,\n",
    "                           y=target,\n",
    "                           optimizer=optimizer,\n",
    "                           step_size=0.01,\n",
    "                           epsilon=0.3,\n",
    "                           perturb_steps=10,\n",
    "                           beta=1.0,\n",
    "\t\t\t   distance='l_inf')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print progress\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_train_loss / len(val_loader)\n",
    "    val_accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping check using min_delta\n",
    "    if best_loss - avg_val_loss > min_delta:\n",
    "        best_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65dbda0f-023f-4e7d-a875-9f91aa62ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2222/2152490654.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/TRADES/TRADES.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/TRADES/TRADES.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f8ba48-e84d-42c6-b472-b24b2e15feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_performance_metrics(x_test, y_test, model, 'DNN', 'baseline', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0575444-678d-4c09-909d-4ec33601e1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start XGB 100 baseline\n",
      "(2492, 56) (2492,)\n",
      "Accuracy: 0.6460674157303371\n",
      "\n",
      "macro\n",
      "Precision: 0.6729671913150603\n",
      "Recall: 0.5779237302568438\n",
      "F1 Score: 0.5455488289003573\n",
      "\n",
      "weighted\n",
      "Precision: 0.6662207161150496\n",
      "Recall: 0.6460674157303371\n",
      "F1 Score: 0.585859183687124\n",
      "\n",
      "start XGB 100 BIM\n",
      "(1475, 56) (1475,)\n",
      "Accuracy: 0.7125423728813559\n",
      "\n",
      "macro\n",
      "Precision: 0.7074591162629525\n",
      "Recall: 0.7086094948352023\n",
      "F1 Score: 0.7079480713551882\n",
      "\n",
      "weighted\n",
      "Precision: 0.7135048830102844\n",
      "Recall: 0.7125423728813559\n",
      "F1 Score: 0.7129397178782136\n",
      "\n",
      "start XGB 100 FGSM\n",
      "(1387, 56) (1387,)\n",
      "Accuracy: 0.7303532804614276\n",
      "\n",
      "macro\n",
      "Precision: 0.7296037695437996\n",
      "Recall: 0.7246093504469056\n",
      "F1 Score: 0.7257861595324486\n",
      "\n",
      "weighted\n",
      "Precision: 0.7299864312359218\n",
      "Recall: 0.7303532804614276\n",
      "F1 Score: 0.7288734312218701\n",
      "\n",
      "start XGB 100 PGD\n",
      "(1475, 56) (1475,)\n",
      "Accuracy: 0.7125423728813559\n",
      "\n",
      "macro\n",
      "Precision: 0.7074591162629525\n",
      "Recall: 0.7086094948352023\n",
      "F1 Score: 0.7079480713551882\n",
      "\n",
      "weighted\n",
      "Precision: 0.7135048830102844\n",
      "Recall: 0.7125423728813559\n",
      "F1 Score: 0.7129397178782136\n",
      "\n",
      "start XGB 100 DF\n",
      "(2392, 56) (2392,)\n",
      "Accuracy: 0.9464882943143813\n",
      "\n",
      "macro\n",
      "Precision: 0.7328941993464052\n",
      "Recall: 0.9146112356826859\n",
      "F1 Score: 0.7928533541172778\n",
      "\n",
      "weighted\n",
      "Precision: 0.9682836101274399\n",
      "Recall: 0.9464882943143813\n",
      "F1 Score: 0.9539463011200661\n",
      "\n",
      "start XGB 100 AutoPGD\n",
      "(4746, 56) (4746,)\n",
      "Accuracy: 0.9127686472819216\n",
      "\n",
      "macro\n",
      "Precision: 0.8215539684590091\n",
      "Recall: 0.8557060169455107\n",
      "F1 Score: 0.837155388471178\n",
      "\n",
      "weighted\n",
      "Precision: 0.9182299083069876\n",
      "Recall: 0.9127686472819216\n",
      "F1 Score: 0.9149664352621968\n",
      "\n",
      "start XGB 100 ZOO\n",
      "(7353, 56) (7353,)\n",
      "Accuracy: 0.7802257581939345\n",
      "\n",
      "macro\n",
      "Precision: 0.8064787313719006\n",
      "Recall: 0.7154095497220403\n",
      "F1 Score: 0.729623894212067\n",
      "\n",
      "weighted\n",
      "Precision: 0.7943271482476776\n",
      "Recall: 0.7802257581939345\n",
      "F1 Score: 0.7616457590959083\n",
      "\n",
      "start XGB 100 CaFA\n",
      "(650, 56) (650,)\n",
      "Accuracy: 0.19846153846153847\n",
      "\n",
      "macro\n",
      "Precision: 0.5003260059612519\n",
      "Recall: 0.5029876227059326\n",
      "F1 Score: 0.17438484173982577\n",
      "\n",
      "weighted\n",
      "Precision: 0.9672493694829759\n",
      "Recall: 0.19846153846153847\n",
      "F1 Score: 0.31060254931852455\n",
      "\n",
      "start XGB 100 SINIFGSM\n",
      "(679, 56) (679,)\n",
      "Accuracy: 0.7378497790868925\n",
      "\n",
      "macro\n",
      "Precision: 0.7405313883823912\n",
      "Recall: 0.7482258064516129\n",
      "F1 Score: 0.736362446557892\n",
      "\n",
      "weighted\n",
      "Precision: 0.757609005474778\n",
      "Recall: 0.7378497790868925\n",
      "F1 Score: 0.7398912158914029\n",
      "\n",
      "start XGB 100 VNIFGSM\n",
      "(1473, 56) (1473,)\n",
      "Accuracy: 0.6829599456890699\n",
      "\n",
      "macro\n",
      "Precision: 0.6759809524532829\n",
      "Recall: 0.6743817637231144\n",
      "F1 Score: 0.6750370483397572\n",
      "\n",
      "weighted\n",
      "Precision: 0.6817921460241175\n",
      "Recall: 0.6829599456890699\n",
      "F1 Score: 0.6822365507136979\n",
      "\n",
      "start XGB 50 baseline\n",
      "(2406, 56) (2406,)\n",
      "Accuracy: 0.64214463840399\n",
      "\n",
      "macro\n",
      "Precision: 0.6726094688159248\n",
      "Recall: 0.5730927615883089\n",
      "F1 Score: 0.5364208533478344\n",
      "\n",
      "weighted\n",
      "Precision: 0.665232039613467\n",
      "Recall: 0.64214463840399\n",
      "F1 Score: 0.5776430080085461\n",
      "\n",
      "start XGB 50 BIM\n",
      "(1435, 56) (1435,)\n",
      "Accuracy: 0.6662020905923345\n",
      "\n",
      "macro\n",
      "Precision: 0.6635808674535405\n",
      "Recall: 0.662319614447274\n",
      "F1 Score: 0.66271065096626\n",
      "\n",
      "weighted\n",
      "Precision: 0.6653839053351387\n",
      "Recall: 0.6662020905923345\n",
      "F1 Score: 0.6655564134012112\n",
      "\n",
      "start XGB 50 FGSM\n",
      "(1270, 56) (1270,)\n",
      "Accuracy: 0.7007874015748031\n",
      "\n",
      "macro\n",
      "Precision: 0.7142879586498354\n",
      "Recall: 0.7030323929929716\n",
      "F1 Score: 0.6974188435456041\n",
      "\n",
      "weighted\n",
      "Precision: 0.7153975934779202\n",
      "Recall: 0.7007874015748031\n",
      "F1 Score: 0.696815519719479\n",
      "\n",
      "start XGB 50 PGD\n",
      "(1435, 56) (1435,)\n",
      "Accuracy: 0.6662020905923345\n",
      "\n",
      "macro\n",
      "Precision: 0.6635808674535405\n",
      "Recall: 0.662319614447274\n",
      "F1 Score: 0.66271065096626\n",
      "\n",
      "weighted\n",
      "Precision: 0.6653839053351387\n",
      "Recall: 0.6662020905923345\n",
      "F1 Score: 0.6655564134012112\n",
      "\n",
      "start XGB 50 DF\n",
      "(2390, 56) (2390,)\n",
      "Accuracy: 0.9158995815899582\n",
      "\n",
      "macro\n",
      "Precision: 0.6929087912038011\n",
      "Recall: 0.933781484002723\n",
      "F1 Score: 0.7529644624473997\n",
      "\n",
      "weighted\n",
      "Precision: 0.9640106082828619\n",
      "Recall: 0.9158995815899582\n",
      "F1 Score: 0.9317649795899289\n",
      "\n",
      "start XGB 50 AutoPGD\n",
      "(4605, 56) (4605,)\n",
      "Accuracy: 0.8883821932681868\n",
      "\n",
      "macro\n",
      "Precision: 0.7579008862014065\n",
      "Recall: 0.822534825897298\n",
      "F1 Score: 0.7840281746892046\n",
      "\n",
      "weighted\n",
      "Precision: 0.9048494455715335\n",
      "Recall: 0.8883821932681868\n",
      "F1 Score: 0.8945762774700008\n",
      "\n",
      "start XGB 50 ZOO\n",
      "(6977, 56) (6977,)\n",
      "Accuracy: 0.7566289236061344\n",
      "\n",
      "macro\n",
      "Precision: 0.7755837536750994\n",
      "Recall: 0.6856215687684848\n",
      "F1 Score: 0.6961367875456297\n",
      "\n",
      "weighted\n",
      "Precision: 0.7670361898942913\n",
      "Recall: 0.7566289236061344\n",
      "F1 Score: 0.7337379064910446\n",
      "\n",
      "start XGB 50 CaFA\n",
      "(668, 56) (668,)\n",
      "Accuracy: 0.20658682634730538\n",
      "\n",
      "macro\n",
      "Precision: 0.5028142589118199\n",
      "Recall: 0.6015037593984962\n",
      "F1 Score: 0.17434701492537313\n",
      "\n",
      "weighted\n",
      "Precision: 0.9955342598105853\n",
      "Recall: 0.20658682634730538\n",
      "F1 Score: 0.33603455402627586\n",
      "\n",
      "start XGB 50 SINIFGSM\n",
      "(1025, 56) (1025,)\n",
      "Accuracy: 0.45170731707317074\n",
      "\n",
      "macro\n",
      "Precision: 0.4957293171033629\n",
      "Recall: 0.4956129940150218\n",
      "F1 Score: 0.4514770744936125\n",
      "\n",
      "weighted\n",
      "Precision: 0.5462387697695834\n",
      "Recall: 0.45170731707317074\n",
      "F1 Score: 0.4550622803753042\n",
      "\n",
      "start XGB 50 VNIFGSM\n",
      "(1516, 56) (1516,)\n",
      "Accuracy: 0.6325857519788918\n",
      "\n",
      "macro\n",
      "Precision: 0.6378137360793511\n",
      "Recall: 0.6308328400821699\n",
      "F1 Score: 0.6271528152785695\n",
      "\n",
      "weighted\n",
      "Precision: 0.6374468600021258\n",
      "Recall: 0.6325857519788918\n",
      "F1 Score: 0.6278653315671364\n",
      "\n",
      "start XGB 20 baseline\n",
      "(2428, 56) (2428,)\n",
      "Accuracy: 0.6359143327841845\n",
      "\n",
      "macro\n",
      "Precision: 0.6570927276746242\n",
      "Recall: 0.5793069585910409\n",
      "F1 Score: 0.5489746635095868\n",
      "\n",
      "weighted\n",
      "Precision: 0.6522016434043147\n",
      "Recall: 0.6359143327841845\n",
      "F1 Score: 0.5815974287158149\n",
      "\n",
      "start XGB 20 BIM\n",
      "(1095, 56) (1095,)\n",
      "Accuracy: 0.7168949771689498\n",
      "\n",
      "macro\n",
      "Precision: 0.7167788677524692\n",
      "Recall: 0.7159534958285183\n",
      "F1 Score: 0.71612576268465\n",
      "\n",
      "weighted\n",
      "Precision: 0.7168346605889598\n",
      "Recall: 0.7168949771689498\n",
      "F1 Score: 0.7166250773498972\n",
      "\n",
      "start XGB 20 FGSM\n",
      "(869, 56) (869,)\n",
      "Accuracy: 0.7779056386651323\n",
      "\n",
      "macro\n",
      "Precision: 0.7950488737781556\n",
      "Recall: 0.7901574254667039\n",
      "F1 Score: 0.7777066475808001\n",
      "\n",
      "weighted\n",
      "Precision: 0.8060441900920257\n",
      "Recall: 0.7779056386651323\n",
      "F1 Score: 0.7769948717791504\n",
      "\n",
      "start XGB 20 PGD\n",
      "(1095, 56) (1095,)\n",
      "Accuracy: 0.7168949771689498\n",
      "\n",
      "macro\n",
      "Precision: 0.7167788677524692\n",
      "Recall: 0.7159534958285183\n",
      "F1 Score: 0.71612576268465\n",
      "\n",
      "weighted\n",
      "Precision: 0.7168346605889598\n",
      "Recall: 0.7168949771689498\n",
      "F1 Score: 0.7166250773498972\n",
      "\n",
      "start XGB 20 DF\n",
      "(2318, 56) (2318,)\n",
      "Accuracy: 0.9003451251078516\n",
      "\n",
      "macro\n",
      "Precision: 0.6735169105538624\n",
      "Recall: 0.7808670606289654\n",
      "F1 Score: 0.7093823932161111\n",
      "\n",
      "weighted\n",
      "Precision: 0.9299202324476575\n",
      "Recall: 0.9003451251078516\n",
      "F1 Score: 0.9120325727755206\n",
      "\n",
      "start XGB 20 AutoPGD\n",
      "(4490, 56) (4490,)\n",
      "Accuracy: 0.878173719376392\n",
      "\n",
      "macro\n",
      "Precision: 0.7797576240781343\n",
      "Recall: 0.811406616531958\n",
      "F1 Score: 0.7939132830245106\n",
      "\n",
      "weighted\n",
      "Precision: 0.8860897966069041\n",
      "Recall: 0.878173719376392\n",
      "F1 Score: 0.8814314373962663\n",
      "\n",
      "start XGB 20 ZOO\n",
      "(6689, 56) (6689,)\n",
      "Accuracy: 0.7433099117954851\n",
      "\n",
      "macro\n",
      "Precision: 0.7584256243405423\n",
      "Recall: 0.6700514878568749\n",
      "F1 Score: 0.6779167674490182\n",
      "\n",
      "weighted\n",
      "Precision: 0.7517793318171483\n",
      "Recall: 0.7433099117954851\n",
      "F1 Score: 0.7178599588033134\n",
      "\n",
      "start XGB 20 CaFA\n",
      "(631, 56) (631,)\n",
      "Accuracy: 0.16798732171156894\n",
      "\n",
      "macro\n",
      "Precision: 0.49074074074074076\n",
      "Recall: 0.08426073131955485\n",
      "F1 Score: 0.14382632293080055\n",
      "\n",
      "weighted\n",
      "Precision: 0.9783706051534895\n",
      "Recall: 0.16798732171156894\n",
      "F1 Score: 0.28674091005855323\n",
      "\n",
      "start XGB 20 SINIFGSM\n",
      "(494, 56) (494,)\n",
      "Accuracy: 0.6659919028340081\n",
      "\n",
      "macro\n",
      "Precision: 0.6760662637808198\n",
      "Recall: 0.6505580504556862\n",
      "F1 Score: 0.6461425588351487\n",
      "\n",
      "weighted\n",
      "Precision: 0.6738624973237047\n",
      "Recall: 0.6659919028340081\n",
      "F1 Score: 0.6532679643732008\n",
      "\n",
      "start XGB 20 VNIFGSM\n",
      "(1155, 56) (1155,)\n",
      "Accuracy: 0.6961038961038961\n",
      "\n",
      "macro\n",
      "Precision: 0.7011320754716981\n",
      "Recall: 0.7013728109679798\n",
      "F1 Score: 0.6961002511977056\n",
      "\n",
      "weighted\n",
      "Precision: 0.7065836804704729\n",
      "Recall: 0.6961038961038961\n",
      "F1 Score: 0.696194107532112\n",
      "\n",
      "start XGB 1 baseline\n",
      "(1654, 56) (1654,)\n",
      "Accuracy: 0.5713422007255139\n",
      "\n",
      "macro\n",
      "Precision: 0.6018994855559953\n",
      "Recall: 0.5454034515439378\n",
      "F1 Score: 0.4856845625898265\n",
      "\n",
      "weighted\n",
      "Precision: 0.5990270017307636\n",
      "Recall: 0.5713422007255139\n",
      "F1 Score: 0.5004049863287001\n",
      "\n",
      "start XGB 1 BIM\n",
      "(72, 56) (72,)\n",
      "Accuracy: 0.7361111111111112\n",
      "\n",
      "macro\n",
      "Precision: 0.712962962962963\n",
      "Recall: 0.6761702127659575\n",
      "F1 Score: 0.6850103615012664\n",
      "\n",
      "weighted\n",
      "Precision: 0.7271090534979424\n",
      "Recall: 0.7361111111111112\n",
      "F1 Score: 0.723776447412183\n",
      "\n",
      "start XGB 1 FGSM\n",
      "(44, 56) (44,)\n",
      "Accuracy: 0.7045454545454546\n",
      "\n",
      "macro\n",
      "Precision: 0.7382352941176471\n",
      "Recall: 0.6705263157894736\n",
      "F1 Score: 0.6656925774400935\n",
      "\n",
      "weighted\n",
      "Precision: 0.7298128342245991\n",
      "Recall: 0.7045454545454546\n",
      "F1 Score: 0.6812337282822379\n",
      "\n",
      "start XGB 1 PGD\n",
      "(72, 56) (72,)\n",
      "Accuracy: 0.7361111111111112\n",
      "\n",
      "macro\n",
      "Precision: 0.712962962962963\n",
      "Recall: 0.6761702127659575\n",
      "F1 Score: 0.6850103615012664\n",
      "\n",
      "weighted\n",
      "Precision: 0.7271090534979424\n",
      "Recall: 0.7361111111111112\n",
      "F1 Score: 0.723776447412183\n",
      "\n",
      "start XGB 1 DF\n",
      "(2162, 56) (2162,)\n",
      "Accuracy: 0.8418131359851989\n",
      "\n",
      "macro\n",
      "Precision: 0.5488126649076517\n",
      "Recall: 0.9195294117647059\n",
      "F1 Score: 0.5451859105582237\n",
      "\n",
      "weighted\n",
      "Precision: 0.9845569552281065\n",
      "Recall: 0.8418131359851989\n",
      "F1 Score: 0.8999153760172868\n",
      "\n",
      "start XGB 1 AutoPGD\n",
      "(2561, 56) (2561,)\n",
      "Accuracy: 0.8196017180788754\n",
      "\n",
      "macro\n",
      "Precision: 0.6240658695420092\n",
      "Recall: 0.6240658695420092\n",
      "F1 Score: 0.6240658695420092\n",
      "\n",
      "weighted\n",
      "Precision: 0.8196017180788754\n",
      "Recall: 0.8196017180788754\n",
      "F1 Score: 0.8196017180788754\n",
      "\n",
      "start XGB 1 ZOO\n",
      "(4408, 56) (4408,)\n",
      "Accuracy: 0.6356624319419237\n",
      "\n",
      "macro\n",
      "Precision: 0.6541307585058531\n",
      "Recall: 0.5849752312551101\n",
      "F1 Score: 0.5587841691895924\n",
      "\n",
      "weighted\n",
      "Precision: 0.649914358182179\n",
      "Recall: 0.6356624319419237\n",
      "F1 Score: 0.5873628277344808\n",
      "\n",
      "start XGB 1 CaFA\n",
      "(708, 56) (708,)\n",
      "Accuracy: 0.2401129943502825\n",
      "\n",
      "macro\n",
      "Precision: 0.5018518518518519\n",
      "Recall: 0.6189801699716714\n",
      "F1 Score: 0.19590971653423628\n",
      "\n",
      "weighted\n",
      "Precision: 0.9971856036827789\n",
      "Recall: 0.2401129943502825\n",
      "F1 Score: 0.38337422004325145\n",
      "\n",
      "start XGB 1 SINIFGSM\n",
      "(99, 56) (99,)\n",
      "Accuracy: 0.9696969696969697\n",
      "\n",
      "macro\n",
      "Precision: 0.9669890664423886\n",
      "Recall: 0.9705508474576271\n",
      "F1 Score: 0.9686609686609686\n",
      "\n",
      "weighted\n",
      "Precision: 0.9700155465504497\n",
      "Recall: 0.9696969696969697\n",
      "F1 Score: 0.9697545253100809\n",
      "\n",
      "start XGB 1 VNIFGSM\n",
      "(64, 56) (64,)\n",
      "Accuracy: 0.515625\n",
      "\n",
      "macro\n",
      "Precision: 0.6142857142857143\n",
      "Recall: 0.5875\n",
      "F1 Score: 0.5058530510585305\n",
      "\n",
      "weighted\n",
      "Precision: 0.6607142857142857\n",
      "Recall: 0.515625\n",
      "F1 Score: 0.48848069738480693\n",
      "\n",
      "start RF 100 baseline\n",
      "(2202, 56) (2202,)\n",
      "Accuracy: 0.8692098092643051\n",
      "\n",
      "macro\n",
      "Precision: 0.9008654836409729\n",
      "Recall: 0.7320328047762727\n",
      "F1 Score: 0.7751968431366154\n",
      "\n",
      "weighted\n",
      "Precision: 0.8789210625213566\n",
      "Recall: 0.8692098092643051\n",
      "F1 Score: 0.8521765611877996\n",
      "\n",
      "start RF 100 BIM\n",
      "(665, 56) (665,)\n",
      "Accuracy: 0.7578947368421053\n",
      "\n",
      "macro\n",
      "Precision: 0.5405071119356833\n",
      "Recall: 0.5569494472736306\n",
      "F1 Score: 0.5430216527451139\n",
      "\n",
      "weighted\n",
      "Precision: 0.8031618936022803\n",
      "Recall: 0.7578947368421053\n",
      "F1 Score: 0.7781568917021285\n",
      "\n",
      "start RF 100 FGSM\n",
      "(658, 56) (658,)\n",
      "Accuracy: 0.7917933130699089\n",
      "\n",
      "macro\n",
      "Precision: 0.5790685043112227\n",
      "Recall: 0.6847867479055598\n",
      "F1 Score: 0.5876117934993939\n",
      "\n",
      "weighted\n",
      "Precision: 0.8958683539142122\n",
      "Recall: 0.7917933130699089\n",
      "F1 Score: 0.8319240220999669\n",
      "\n",
      "start RF 100 PGD\n",
      "(665, 56) (665,)\n",
      "Accuracy: 0.7578947368421053\n",
      "\n",
      "macro\n",
      "Precision: 0.5405071119356833\n",
      "Recall: 0.5569494472736306\n",
      "F1 Score: 0.5430216527451139\n",
      "\n",
      "weighted\n",
      "Precision: 0.8031618936022803\n",
      "Recall: 0.7578947368421053\n",
      "F1 Score: 0.7781568917021285\n",
      "\n",
      "start RF 100 DF\n",
      "(2466, 56) (2466,)\n",
      "Accuracy: 0.9521492295214923\n",
      "\n",
      "macro\n",
      "Precision: 0.7698288969724965\n",
      "Recall: 0.8900891319604394\n",
      "F1 Score: 0.8166145267451328\n",
      "\n",
      "weighted\n",
      "Precision: 0.964232838306416\n",
      "Recall: 0.9521492295214923\n",
      "F1 Score: 0.9564965690445075\n",
      "\n",
      "start RF 100 AutoPGD\n",
      "(4776, 56) (4776,)\n",
      "Accuracy: 0.9960217755443886\n",
      "\n",
      "macro\n",
      "Precision: 0.9877042409010006\n",
      "Recall: 0.9840246829998478\n",
      "F1 Score: 0.9858561124727722\n",
      "\n",
      "weighted\n",
      "Precision: 0.9960094593529127\n",
      "Recall: 0.9960217755443886\n",
      "F1 Score: 0.9960142435638464\n",
      "\n",
      "start RF 100 ZOO\n",
      "(6777, 56) (6777,)\n",
      "Accuracy: 0.9852442083517781\n",
      "\n",
      "macro\n",
      "Precision: 0.9894039667320096\n",
      "Recall: 0.9654365944560417\n",
      "F1 Score: 0.9768491063215297\n",
      "\n",
      "weighted\n",
      "Precision: 0.9854237232183429\n",
      "Recall: 0.9852442083517781\n",
      "F1 Score: 0.9850590676552031\n",
      "\n",
      "start RF 100 CaFA\n",
      "(161, 56) (161,)\n",
      "Accuracy: 0.8136645962732919\n",
      "\n",
      "macro\n",
      "Precision: 0.8100092678405931\n",
      "Recall: 0.8311881188118813\n",
      "F1 Score: 0.8097826086956522\n",
      "\n",
      "weighted\n",
      "Precision: 0.8399829609887233\n",
      "Recall: 0.8136645962732919\n",
      "F1 Score: 0.8167026735079667\n",
      "\n",
      "start RF 100 SINIFGSM\n",
      "(555, 56) (555,)\n",
      "Accuracy: 0.9117117117117117\n",
      "\n",
      "macro\n",
      "Precision: 0.8629506859999291\n",
      "Recall: 0.8899055489964581\n",
      "F1 Score: 0.875266597867217\n",
      "\n",
      "weighted\n",
      "Precision: 0.9161290868633017\n",
      "Recall: 0.9117117117117117\n",
      "F1 Score: 0.9132909999783064\n",
      "\n",
      "start RF 100 VNIFGSM\n",
      "(752, 56) (752,)\n",
      "Accuracy: 0.7154255319148937\n",
      "\n",
      "macro\n",
      "Precision: 0.5553494124922697\n",
      "Recall: 0.5537115235632373\n",
      "F1 Score: 0.5544629014396456\n",
      "\n",
      "weighted\n",
      "Precision: 0.7112313977815498\n",
      "Recall: 0.7154255319148937\n",
      "F1 Score: 0.713288859828939\n",
      "\n",
      "start RF 50 baseline\n",
      "(2233, 56) (2233,)\n",
      "Accuracy: 0.7819077474249888\n",
      "\n",
      "macro\n",
      "Precision: 0.820566178630455\n",
      "Recall: 0.6682983158927404\n",
      "F1 Score: 0.6851236881613483\n",
      "\n",
      "weighted\n",
      "Precision: 0.8012486706083414\n",
      "Recall: 0.7819077474249888\n",
      "F1 Score: 0.749620335085826\n",
      "\n",
      "start RF 50 BIM\n",
      "(572, 56) (572,)\n",
      "Accuracy: 0.8321678321678322\n",
      "\n",
      "macro\n",
      "Precision: 0.49177489177489175\n",
      "Recall: 0.4751722499406035\n",
      "F1 Score: 0.47402298850574714\n",
      "\n",
      "weighted\n",
      "Precision: 0.9201162473889746\n",
      "Recall: 0.8321678321678322\n",
      "F1 Score: 0.8731420303834098\n",
      "\n",
      "start RF 50 FGSM\n",
      "(584, 56) (584,)\n",
      "Accuracy: 0.8287671232876712\n",
      "\n",
      "macro\n",
      "Precision: 0.49885714285714283\n",
      "Recall: 0.4961177612423164\n",
      "F1 Score: 0.4812209075080837\n",
      "\n",
      "weighted\n",
      "Precision: 0.9271056751467711\n",
      "Recall: 0.8287671232876712\n",
      "F1 Score: 0.8738463395603374\n",
      "\n",
      "start RF 50 PGD\n",
      "(572, 56) (572,)\n",
      "Accuracy: 0.8321678321678322\n",
      "\n",
      "macro\n",
      "Precision: 0.49177489177489175\n",
      "Recall: 0.4751722499406035\n",
      "F1 Score: 0.47402298850574714\n",
      "\n",
      "weighted\n",
      "Precision: 0.9201162473889746\n",
      "Recall: 0.8321678321678322\n",
      "F1 Score: 0.8731420303834098\n",
      "\n",
      "start RF 50 DF\n",
      "(2418, 56) (2418,)\n",
      "Accuracy: 0.9201819685690653\n",
      "\n",
      "macro\n",
      "Precision: 0.7116411566685235\n",
      "Recall: 0.9135754449377516\n",
      "F1 Score: 0.7695094431320408\n",
      "\n",
      "weighted\n",
      "Precision: 0.9586280400367628\n",
      "Recall: 0.9201819685690653\n",
      "F1 Score: 0.9328985755752592\n",
      "\n",
      "start RF 50 AutoPGD\n",
      "(4413, 56) (4413,)\n",
      "Accuracy: 0.972807613868117\n",
      "\n",
      "macro\n",
      "Precision: 0.9017462557730718\n",
      "Recall: 0.9272886460318609\n",
      "F1 Score: 0.914023646581922\n",
      "\n",
      "weighted\n",
      "Precision: 0.9738275395156308\n",
      "Recall: 0.972807613868117\n",
      "F1 Score: 0.97322646373094\n",
      "\n",
      "start RF 50 ZOO\n",
      "(6735, 56) (6735,)\n",
      "Accuracy: 0.910913140311804\n",
      "\n",
      "macro\n",
      "Precision: 0.92255202897661\n",
      "Recall: 0.8478229841201963\n",
      "F1 Score: 0.876290576139982\n",
      "\n",
      "weighted\n",
      "Precision: 0.9134821234777687\n",
      "Recall: 0.910913140311804\n",
      "F1 Score: 0.9066181155113702\n",
      "\n",
      "start RF 50 CaFA\n",
      "(312, 56) (312,)\n",
      "Accuracy: 0.4935897435897436\n",
      "\n",
      "macro\n",
      "Precision: 0.5863828289936664\n",
      "Recall: 0.6499236641221374\n",
      "F1 Score: 0.4698670796231772\n",
      "\n",
      "weighted\n",
      "Precision: 0.832284505314062\n",
      "Recall: 0.4935897435897436\n",
      "F1 Score: 0.5460671517582086\n",
      "\n",
      "start RF 50 SINIFGSM\n",
      "(215, 56) (215,)\n",
      "Accuracy: 0.6651162790697674\n",
      "\n",
      "macro\n",
      "Precision: 0.6923076923076923\n",
      "Recall: 0.788235294117647\n",
      "F1 Score: 0.6434494195688225\n",
      "\n",
      "weighted\n",
      "Precision: 0.8711985688729875\n",
      "Recall: 0.6651162790697674\n",
      "F1 Score: 0.6945505032974661\n",
      "\n",
      "start RF 50 VNIFGSM\n",
      "(606, 56) (606,)\n",
      "Accuracy: 0.8003300330033003\n",
      "\n",
      "macro\n",
      "Precision: 0.5200289575289575\n",
      "Recall: 0.5301270417422868\n",
      "F1 Score: 0.5203281283730301\n",
      "\n",
      "weighted\n",
      "Precision: 0.8433529887737808\n",
      "Recall: 0.8003300330033003\n",
      "F1 Score: 0.8202869722102094\n",
      "\n",
      "start RF 20 baseline\n",
      "(2296, 56) (2296,)\n",
      "Accuracy: 0.676829268292683\n",
      "\n",
      "macro\n",
      "Precision: 0.6726928374655647\n",
      "Recall: 0.5973701327068508\n",
      "F1 Score: 0.5863103245640022\n",
      "\n",
      "weighted\n",
      "Precision: 0.6741941308875898\n",
      "Recall: 0.676829268292683\n",
      "F1 Score: 0.6345196688962232\n",
      "\n",
      "start RF 20 BIM\n",
      "(403, 56) (403,)\n",
      "Accuracy: 0.9081885856079405\n",
      "\n",
      "macro\n",
      "Precision: 0.5595238095238095\n",
      "Recall: 0.9535175879396984\n",
      "F1 Score: 0.5820088021753147\n",
      "\n",
      "weighted\n",
      "Precision: 0.9890700697152309\n",
      "Recall: 0.9081885856079405\n",
      "F1 Score: 0.9420892934366123\n",
      "\n",
      "start RF 20 FGSM\n",
      "(410, 56) (410,)\n",
      "Accuracy: 0.9390243902439024\n",
      "\n",
      "macro\n",
      "Precision: 0.6428571428571428\n",
      "Recall: 0.96875\n",
      "F1 Score: 0.7060931899641577\n",
      "\n",
      "weighted\n",
      "Precision: 0.9825783972125435\n",
      "Recall: 0.9390243902439024\n",
      "F1 Score: 0.9549785820438851\n",
      "\n",
      "start RF 20 PGD\n",
      "(403, 56) (403,)\n",
      "Accuracy: 0.9081885856079405\n",
      "\n",
      "macro\n",
      "Precision: 0.5595238095238095\n",
      "Recall: 0.9535175879396984\n",
      "F1 Score: 0.5820088021753147\n",
      "\n",
      "weighted\n",
      "Precision: 0.9890700697152309\n",
      "Recall: 0.9081885856079405\n",
      "F1 Score: 0.9420892934366123\n",
      "\n",
      "start RF 20 DF\n",
      "(2331, 56) (2331,)\n",
      "Accuracy: 0.9094809094809094\n",
      "\n",
      "macro\n",
      "Precision: 0.6930190019756072\n",
      "Recall: 0.8933756287151349\n",
      "F1 Score: 0.747013199172692\n",
      "\n",
      "weighted\n",
      "Precision: 0.9542308608257742\n",
      "Recall: 0.9094809094809094\n",
      "F1 Score: 0.9247013855536815\n",
      "\n",
      "start RF 20 AutoPGD\n",
      "(4048, 56) (4048,)\n",
      "Accuracy: 0.8935276679841897\n",
      "\n",
      "macro\n",
      "Precision: 0.7270931499100335\n",
      "Recall: 0.7940955659106038\n",
      "F1 Score: 0.7539193413506503\n",
      "\n",
      "weighted\n",
      "Precision: 0.9106302494966375\n",
      "Recall: 0.8935276679841897\n",
      "F1 Score: 0.9003501149072457\n",
      "\n",
      "start RF 20 ZOO\n",
      "(6429, 56) (6429,)\n",
      "Accuracy: 0.7981023487323068\n",
      "\n",
      "macro\n",
      "Precision: 0.7904405987271156\n",
      "Recall: 0.7284900333329727\n",
      "F1 Score: 0.7456730997809303\n",
      "\n",
      "weighted\n",
      "Precision: 0.7952695765996977\n",
      "Recall: 0.7981023487323068\n",
      "F1 Score: 0.7862119195422378\n",
      "\n",
      "start RF 20 CaFA\n",
      "(425, 56) (425,)\n",
      "Accuracy: 0.24941176470588236\n",
      "\n",
      "macro\n",
      "Precision: 0.5157545605306799\n",
      "Recall: 0.558641975308642\n",
      "F1 Score: 0.22848200312989048\n",
      "\n",
      "weighted\n",
      "Precision: 0.9342932396839333\n",
      "Recall: 0.24941176470588236\n",
      "F1 Score: 0.34359569179784594\n",
      "\n",
      "start RF 20 SINIFGSM\n",
      "(149, 56) (149,)\n",
      "Accuracy: 0.8590604026845637\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.42953020134228187\n",
      "F1 Score: 0.4620938628158845\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.8590604026845637\n",
      "F1 Score: 0.9241877256317689\n",
      "\n",
      "start RF 20 VNIFGSM\n",
      "(392, 56) (392,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9311224489795918\n",
      "\n",
      "macro\n",
      "Precision: 0.625\n",
      "Recall: 0.9647519582245431\n",
      "F1 Score: 0.6817320703653587\n",
      "\n",
      "weighted\n",
      "Precision: 0.982780612244898\n",
      "Recall: 0.9311224489795918\n",
      "F1 Score: 0.950527464030267\n",
      "\n",
      "start RF 1 baseline\n",
      "(1608, 56) (1608,)\n",
      "Accuracy: 0.5796019900497512\n",
      "\n",
      "macro\n",
      "Precision: 0.5771822940686262\n",
      "Recall: 0.5447971110453677\n",
      "F1 Score: 0.5083903180288722\n",
      "\n",
      "weighted\n",
      "Precision: 0.5775832722597841\n",
      "Recall: 0.5796019900497512\n",
      "F1 Score: 0.5286367737995142\n",
      "\n",
      "start RF 1 BIM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_BIM_Def3.npy not found\n",
      "start RF 1 FGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_FGSM_Def3.npy not found\n",
      "start RF 1 PGD\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_PGD_Def3.npy not found\n",
      "start RF 1 DF\n",
      "(1692, 56) (1692,)\n",
      "Accuracy: 0.8640661938534279\n",
      "\n",
      "macro\n",
      "Precision: 0.6204620462046204\n",
      "Recall: 0.9289684990735021\n",
      "F1 Score: 0.6559175531914894\n",
      "\n",
      "weighted\n",
      "Precision: 0.9672502711264034\n",
      "Recall: 0.8640661938534279\n",
      "F1 Score: 0.9004447556712439\n",
      "\n",
      "start RF 1 AutoPGD\n",
      "(2390, 56) (2390,)\n",
      "Accuracy: 0.7669456066945607\n",
      "\n",
      "macro\n",
      "Precision: 0.5079890828609326\n",
      "Recall: 0.5113217768147346\n",
      "F1 Score: 0.5060244585111827\n",
      "\n",
      "weighted\n",
      "Precision: 0.8098897683776934\n",
      "Recall: 0.7669456066945607\n",
      "F1 Score: 0.7869240250643876\n",
      "\n",
      "start RF 1 ZOO\n",
      "(4115, 56) (4115,)\n",
      "Accuracy: 0.6291616038882138\n",
      "\n",
      "macro\n",
      "Precision: 0.6053764226374415\n",
      "Recall: 0.5687016072034936\n",
      "F1 Score: 0.5542432110270445\n",
      "\n",
      "weighted\n",
      "Precision: 0.6133990897973334\n",
      "Recall: 0.6291616038882138\n",
      "F1 Score: 0.5920354767797743\n",
      "\n",
      "start RF 1 CaFA\n",
      "(589, 56) (589,)\n",
      "Accuracy: 0.3073005093378608\n",
      "\n",
      "macro\n",
      "Precision: 0.5048543689320388\n",
      "Recall: 0.6512820512820513\n",
      "F1 Score: 0.24189884918231375\n",
      "\n",
      "weighted\n",
      "Precision: 0.9932747622265813\n",
      "Recall: 0.3073005093378608\n",
      "F1 Score: 0.46154257490701217\n",
      "\n",
      "start RF 1 SINIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_SINIFGSM_Def3.npy not found\n",
      "start RF 1 VNIFGSM\n",
      "/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data/RF/UNSW_Input1/x_test_adv_VNIFGSM_Def3.npy not found\n",
      "start DT 100 baseline\n",
      "(2010, 56) (2010,)\n",
      "Accuracy: 0.8417910447761194\n",
      "\n",
      "macro\n",
      "Precision: 0.9148366363149438\n",
      "Recall: 0.6550976138828634\n",
      "F1 Score: 0.6902092994401103\n",
      "\n",
      "weighted\n",
      "Precision: 0.8687382583600477\n",
      "Recall: 0.8417910447761194\n",
      "F1 Score: 0.8075072645365383\n",
      "\n",
      "start DT 100 BIM\n",
      "(4270, 56) (4270,)\n",
      "Accuracy: 0.5491803278688525\n",
      "\n",
      "macro\n",
      "Precision: 0.5524888732428124\n",
      "Recall: 0.5533191869555506\n",
      "F1 Score: 0.5483507680550761\n",
      "\n",
      "weighted\n",
      "Precision: 0.5617333382582884\n",
      "Recall: 0.5491803278688525\n",
      "F1 Score: 0.5509346428848714\n",
      "\n",
      "start DT 100 FGSM\n",
      "(4999, 56) (4999,)\n",
      "Accuracy: 0.8207641528305661\n",
      "\n",
      "macro\n",
      "Precision: 0.7653170254632828\n",
      "Recall: 0.7954664764152792\n",
      "F1 Score: 0.7772733601454378\n",
      "\n",
      "weighted\n",
      "Precision: 0.8345342282276319\n",
      "Recall: 0.8207641528305661\n",
      "F1 Score: 0.8255680249062435\n",
      "\n",
      "start DT 100 PGD\n",
      "(4270, 56) (4270,)\n",
      "Accuracy: 0.5491803278688525\n",
      "\n",
      "macro\n",
      "Precision: 0.5524888732428124\n",
      "Recall: 0.5533191869555506\n",
      "F1 Score: 0.5483507680550761\n",
      "\n",
      "weighted\n",
      "Precision: 0.5617333382582884\n",
      "Recall: 0.5491803278688525\n",
      "F1 Score: 0.5509346428848714\n",
      "\n",
      "start DT 100 DF\n",
      "(2829, 56) (2829,)\n",
      "Accuracy: 0.8009897490279251\n",
      "\n",
      "macro\n",
      "Precision: 0.5977937380749343\n",
      "Recall: 0.7472161339860564\n",
      "F1 Score: 0.6114034691783788\n",
      "\n",
      "weighted\n",
      "Precision: 0.9136866962791635\n",
      "Recall: 0.8009897490279251\n",
      "F1 Score: 0.8421499282057872\n",
      "\n",
      "start DT 100 AutoPGD\n",
      "(7506, 56) (7506,)\n",
      "Accuracy: 0.8298694377831068\n",
      "\n",
      "macro\n",
      "Precision: 0.8218594355285003\n",
      "Recall: 0.7881892952476558\n",
      "F1 Score: 0.8005704898374124\n",
      "\n",
      "weighted\n",
      "Precision: 0.8276652465152025\n",
      "Recall: 0.8298694377831068\n",
      "F1 Score: 0.82519504879907\n",
      "\n",
      "start DT 100 ZOO\n",
      "(6325, 56) (6325,)\n",
      "Accuracy: 0.961106719367589\n",
      "\n",
      "macro\n",
      "Precision: 0.9717242157526518\n",
      "Recall: 0.9069818609469069\n",
      "F1 Score: 0.9350756918249491\n",
      "\n",
      "weighted\n",
      "Precision: 0.9622124468017729\n",
      "Recall: 0.961106719367589\n",
      "F1 Score: 0.9596768002516387\n",
      "\n",
      "start DT 100 CaFA\n",
      "(918, 56) (918,)\n",
      "Accuracy: 0.6830065359477124\n",
      "\n",
      "macro\n",
      "Precision: 0.6794854740242773\n",
      "Recall: 0.6904567453115548\n",
      "F1 Score: 0.6770181078685864\n",
      "\n",
      "weighted\n",
      "Precision: 0.707402464988656\n",
      "Recall: 0.6830065359477124\n",
      "F1 Score: 0.6876535561371142\n",
      "\n",
      "start DT 100 SINIFGSM\n",
      "(4563, 56) (4563,)\n",
      "Accuracy: 0.5264080648696033\n",
      "\n",
      "macro\n",
      "Precision: 0.5141137232571382\n",
      "Recall: 0.5142049095128931\n",
      "F1 Score: 0.5141078648635824\n",
      "\n",
      "weighted\n",
      "Precision: 0.5280328677258763\n",
      "Recall: 0.5264080648696033\n",
      "F1 Score: 0.5271704739608857\n",
      "\n",
      "start DT 100 VNIFGSM\n",
      "(3220, 56) (3220,)\n",
      "Accuracy: 0.6481366459627329\n",
      "\n",
      "macro\n",
      "Precision: 0.6496928037879729\n",
      "Recall: 0.649471561867756\n",
      "F1 Score: 0.6481154346038567\n",
      "\n",
      "weighted\n",
      "Precision: 0.6508118386285948\n",
      "Recall: 0.6481366459627329\n",
      "F1 Score: 0.6480068324464102\n",
      "\n",
      "start DT 50 baseline\n",
      "(2289, 56) (2289,)\n",
      "Accuracy: 0.7763215377894277\n",
      "\n",
      "macro\n",
      "Precision: 0.8192157644147073\n",
      "Recall: 0.6818203927404793\n",
      "F1 Score: 0.6966636228670108\n",
      "\n",
      "weighted\n",
      "Precision: 0.7993340361660594\n",
      "Recall: 0.7763215377894277\n",
      "F1 Score: 0.747120426607297\n",
      "\n",
      "start DT 50 BIM\n",
      "(3998, 56) (3998,)\n",
      "Accuracy: 0.5747873936968484\n",
      "\n",
      "macro\n",
      "Precision: 0.5763527425511863\n",
      "Recall: 0.5762344302285434\n",
      "F1 Score: 0.5747634502034148\n",
      "\n",
      "weighted\n",
      "Precision: 0.5775201213578111\n",
      "Recall: 0.5747873936968484\n",
      "F1 Score: 0.5746229817086043\n",
      "\n",
      "start DT 50 FGSM\n",
      "(3497, 56) (3497,)\n",
      "Accuracy: 0.6825850729196454\n",
      "\n",
      "macro\n",
      "Precision: 0.6824233313249899\n",
      "Recall: 0.6923121750044827\n",
      "F1 Score: 0.6783983639176365\n",
      "\n",
      "weighted\n",
      "Precision: 0.7080755482373576\n",
      "Recall: 0.6825850729196454\n",
      "F1 Score: 0.6867193168965666\n",
      "\n",
      "start DT 50 PGD\n",
      "(3998, 56) (3998,)\n",
      "Accuracy: 0.5747873936968484\n",
      "\n",
      "macro\n",
      "Precision: 0.5763527425511863\n",
      "Recall: 0.5762344302285434\n",
      "F1 Score: 0.5747634502034148\n",
      "\n",
      "weighted\n",
      "Precision: 0.5775201213578111\n",
      "Recall: 0.5747873936968484\n",
      "F1 Score: 0.5746229817086043\n",
      "\n",
      "start DT 50 DF\n",
      "(2693, 56) (2693,)\n",
      "Accuracy: 0.7961381359079094\n",
      "\n",
      "macro\n",
      "Precision: 0.6193299963478711\n",
      "Recall: 0.7805662794522445\n",
      "F1 Score: 0.6360679126626203\n",
      "\n",
      "weighted\n",
      "Precision: 0.9106898882989201\n",
      "Recall: 0.7961381359079094\n",
      "F1 Score: 0.8353042543615439\n",
      "\n",
      "start DT 50 AutoPGD\n",
      "(6683, 56) (6683,)\n",
      "Accuracy: 0.8804429148585965\n",
      "\n",
      "macro\n",
      "Precision: 0.8504749432576075\n",
      "Recall: 0.8753953830839578\n",
      "F1 Score: 0.860953867959326\n",
      "\n",
      "weighted\n",
      "Precision: 0.8874831797367205\n",
      "Recall: 0.8804429148585965\n",
      "F1 Score: 0.8824915237053224\n",
      "\n",
      "start DT 50 ZOO\n",
      "(6917, 56) (6917,)\n",
      "Accuracy: 0.8820297816972676\n",
      "\n",
      "macro\n",
      "Precision: 0.8911782044181896\n",
      "Recall: 0.8196610677110309\n",
      "F1 Score: 0.8450535708873753\n",
      "\n",
      "weighted\n",
      "Precision: 0.8845428536522617\n",
      "Recall: 0.8820297816972676\n",
      "F1 Score: 0.8761424773422152\n",
      "\n",
      "start DT 50 CaFA\n",
      "(1109, 56) (1109,)\n",
      "Accuracy: 0.42560865644724977\n",
      "\n",
      "macro\n",
      "Precision: 0.49203170970905524\n",
      "Recall: 0.48737319231599396\n",
      "F1 Score: 0.3993207812206381\n",
      "\n",
      "weighted\n",
      "Precision: 0.6896049617516171\n",
      "Recall: 0.42560865644724977\n",
      "F1 Score: 0.47852433632150687\n",
      "\n",
      "start DT 50 SINIFGSM\n",
      "(3973, 56) (3973,)\n",
      "Accuracy: 0.5401459854014599\n",
      "\n",
      "macro\n",
      "Precision: 0.542826166393455\n",
      "Recall: 0.5436439406869514\n",
      "F1 Score: 0.5388821180239578\n",
      "\n",
      "weighted\n",
      "Precision: 0.5530910772675595\n",
      "Recall: 0.5401459854014599\n",
      "F1 Score: 0.5423030667428698\n",
      "\n",
      "start DT 50 VNIFGSM\n",
      "(4360, 56) (4360,)\n",
      "Accuracy: 0.6277522935779817\n",
      "\n",
      "macro\n",
      "Precision: 0.6252708622716102\n",
      "Recall: 0.6239759959817062\n",
      "F1 Score: 0.6241813481615436\n",
      "\n",
      "weighted\n",
      "Precision: 0.6266953876511938\n",
      "Recall: 0.6277522935779817\n",
      "F1 Score: 0.6267860377594161\n",
      "\n",
      "start DT 20 baseline\n",
      "(2269, 56) (2269,)\n",
      "Accuracy: 0.6954605553107096\n",
      "\n",
      "macro\n",
      "Precision: 0.7123298265641578\n",
      "Recall: 0.6556534015593608\n",
      "F1 Score: 0.6529648013191897\n",
      "\n",
      "weighted\n",
      "Precision: 0.7071510297102185\n",
      "Recall: 0.6954605553107096\n",
      "F1 Score: 0.6729281718970699\n",
      "\n",
      "start DT 20 BIM\n",
      "(11472, 56) (11472,)\n",
      "Accuracy: 0.7502615062761506\n",
      "\n",
      "macro\n",
      "Precision: 0.6241920626032067\n",
      "Recall: 0.7079232838147812\n",
      "F1 Score: 0.6344584407300159\n",
      "\n",
      "weighted\n",
      "Precision: 0.8402959681510275\n",
      "Recall: 0.7502615062761506\n",
      "F1 Score: 0.7807322215251645\n",
      "\n",
      "start DT 20 FGSM\n",
      "(6165, 56) (6165,)\n",
      "Accuracy: 0.821735604217356\n",
      "\n",
      "macro\n",
      "Precision: 0.7450466243196474\n",
      "Recall: 0.7885239118188374\n",
      "F1 Score: 0.7613042900640452\n",
      "\n",
      "weighted\n",
      "Precision: 0.8425716434279382\n",
      "Recall: 0.821735604217356\n",
      "F1 Score: 0.8289632049752149\n",
      "\n",
      "start DT 20 PGD\n",
      "(11472, 56) (11472,)\n",
      "Accuracy: 0.7502615062761506\n",
      "\n",
      "macro\n",
      "Precision: 0.6241920626032067\n",
      "Recall: 0.7079232838147812\n",
      "F1 Score: 0.6344584407300159\n",
      "\n",
      "weighted\n",
      "Precision: 0.8402959681510275\n",
      "Recall: 0.7502615062761506\n",
      "F1 Score: 0.7807322215251645\n",
      "\n",
      "start DT 20 DF\n",
      "(3313, 56) (3313,)\n",
      "Accuracy: 0.6658617567159674\n",
      "\n",
      "macro\n",
      "Precision: 0.5601238500876011\n",
      "Recall: 0.6502088900115645\n",
      "F1 Score: 0.531118887958298\n",
      "\n",
      "weighted\n",
      "Precision: 0.8621829514331297\n",
      "Recall: 0.6658617567159674\n",
      "F1 Score: 0.7307295229253183\n",
      "\n",
      "start DT 20 AutoPGD\n",
      "(11316, 56) (11316,)\n",
      "Accuracy: 0.7875574407917992\n",
      "\n",
      "macro\n",
      "Precision: 0.7832923713475015\n",
      "Recall: 0.8005125422111594\n",
      "F1 Score: 0.7832787603965579\n",
      "\n",
      "weighted\n",
      "Precision: 0.8099928745809817\n",
      "Recall: 0.7875574407917992\n",
      "F1 Score: 0.7906574658328797\n",
      "\n",
      "start DT 20 ZOO\n",
      "(6799, 56) (6799,)\n",
      "Accuracy: 0.7733490219149874\n",
      "\n",
      "macro\n",
      "Precision: 0.7776960959683168\n",
      "Recall: 0.7387505412145053\n",
      "F1 Score: 0.7475366881425056\n",
      "\n",
      "weighted\n",
      "Precision: 0.7754916698539249\n",
      "Recall: 0.7733490219149874\n",
      "F1 Score: 0.764907177705128\n",
      "\n",
      "start DT 20 CaFA\n",
      "(910, 56) (910,)\n",
      "Accuracy: 0.48131868131868133\n",
      "\n",
      "macro\n",
      "Precision: 0.5018859131751787\n",
      "Recall: 0.502850978579134\n",
      "F1 Score: 0.44459386767079073\n",
      "\n",
      "weighted\n",
      "Precision: 0.6728510279823138\n",
      "Recall: 0.48131868131868133\n",
      "F1 Score: 0.528087888442918\n",
      "\n",
      "start DT 20 SINIFGSM\n",
      "(9740, 56) (9740,)\n",
      "Accuracy: 0.5924024640657084\n",
      "\n",
      "macro\n",
      "Precision: 0.5756000372748058\n",
      "Recall: 0.6297395491850264\n",
      "F1 Score: 0.5355394179986205\n",
      "\n",
      "weighted\n",
      "Precision: 0.7824799171377943\n",
      "Recall: 0.5924024640657084\n",
      "F1 Score: 0.6407227050898535\n",
      "\n",
      "start DT 20 VNIFGSM\n",
      "(7456, 56) (7456,)\n",
      "Accuracy: 0.5421137339055794\n",
      "\n",
      "macro\n",
      "Precision: 0.5469183068608342\n",
      "Recall: 0.5640513069592705\n",
      "F1 Score: 0.5117275389309238\n",
      "\n",
      "weighted\n",
      "Precision: 0.6812374551316543\n",
      "Recall: 0.5421137339055795\n",
      "F1 Score: 0.5747543885073869\n",
      "\n",
      "start DT 1 baseline\n",
      "(2656, 56) (2656,)\n",
      "Accuracy: 0.6114457831325302\n",
      "\n",
      "macro\n",
      "Precision: 0.6282505536222713\n",
      "Recall: 0.626669906957367\n",
      "F1 Score: 0.6113080338226811\n",
      "\n",
      "weighted\n",
      "Precision: 0.6415249101435797\n",
      "Recall: 0.6114457831325302\n",
      "F1 Score: 0.6102721590126162\n",
      "\n",
      "start DT 1 BIM\n",
      "(2570, 56) (2570,)\n",
      "Accuracy: 0.6295719844357976\n",
      "\n",
      "macro\n",
      "Precision: 0.6111117449090183\n",
      "Recall: 0.5915097631084599\n",
      "F1 Score: 0.5882674464315525\n",
      "\n",
      "weighted\n",
      "Precision: 0.6185594967180983\n",
      "Recall: 0.6295719844357976\n",
      "F1 Score: 0.6120150186502095\n",
      "\n",
      "start DT 1 FGSM\n",
      "(2036, 56) (2036,)\n",
      "Accuracy: 0.7716110019646365\n",
      "\n",
      "macro\n",
      "Precision: 0.6786409556392623\n",
      "Recall: 0.6937208527648235\n",
      "F1 Score: 0.685134429978379\n",
      "\n",
      "weighted\n",
      "Precision: 0.7821046507577977\n",
      "Recall: 0.7716110019646365\n",
      "F1 Score: 0.7762306501400974\n",
      "\n",
      "start DT 1 PGD\n",
      "(2570, 56) (2570,)\n",
      "Accuracy: 0.6295719844357976\n",
      "\n",
      "macro\n",
      "Precision: 0.6111117449090183\n",
      "Recall: 0.5915097631084599\n",
      "F1 Score: 0.5882674464315525\n",
      "\n",
      "weighted\n",
      "Precision: 0.6185594967180983\n",
      "Recall: 0.6295719844357976\n",
      "F1 Score: 0.6120150186502095\n",
      "\n",
      "start DT 1 DF\n",
      "(5863, 56) (5863,)\n",
      "Accuracy: 0.44073000170561144\n",
      "\n",
      "macro\n",
      "Precision: 0.47511380439729856\n",
      "Recall: 0.4620424062679828\n",
      "F1 Score: 0.4069130339938563\n",
      "\n",
      "weighted\n",
      "Precision: 0.6500445377995315\n",
      "Recall: 0.44073000170561144\n",
      "F1 Score: 0.4910931286191897\n",
      "\n",
      "start DT 1 AutoPGD\n",
      "(5660, 56) (5660,)\n",
      "Accuracy: 0.6945229681978798\n",
      "\n",
      "macro\n",
      "Precision: 0.6947974981718793\n",
      "Recall: 0.6953978515257304\n",
      "F1 Score: 0.6943542006847355\n",
      "\n",
      "weighted\n",
      "Precision: 0.6964763545513374\n",
      "Recall: 0.6945229681978798\n",
      "F1 Score: 0.6947577200018776\n",
      "\n",
      "start DT 1 ZOO\n",
      "(7892, 56) (7892,)\n",
      "Accuracy: 0.6425494171312722\n",
      "\n",
      "macro\n",
      "Precision: 0.6528361782390764\n",
      "Recall: 0.6536353768663139\n",
      "F1 Score: 0.6425135959784334\n",
      "\n",
      "weighted\n",
      "Precision: 0.6648668323243837\n",
      "Recall: 0.6425494171312722\n",
      "F1 Score: 0.6430078372011446\n",
      "\n",
      "start DT 1 CaFA\n",
      "(2002, 56) (2002,)\n",
      "Accuracy: 0.7327672327672328\n",
      "\n",
      "macro\n",
      "Precision: 0.552675585284281\n",
      "Recall: 0.8620422898401238\n",
      "F1 Score: 0.5152921882063951\n",
      "\n",
      "weighted\n",
      "Precision: 0.971846715157752\n",
      "Recall: 0.7327672327672328\n",
      "F1 Score: 0.8195302072937416\n",
      "\n",
      "start DT 1 SINIFGSM\n",
      "(3150, 56) (3150,)\n",
      "Accuracy: 0.7726984126984127\n",
      "\n",
      "macro\n",
      "Precision: 0.7030349688381938\n",
      "Recall: 0.7516544980027602\n",
      "F1 Score: 0.7165477593272552\n",
      "\n",
      "weighted\n",
      "Precision: 0.8106276924771162\n",
      "Recall: 0.7726984126984127\n",
      "F1 Score: 0.7847135311087887\n",
      "\n",
      "start DT 1 VNIFGSM\n",
      "(2553, 56) (2553,)\n",
      "Accuracy: 0.7477477477477478\n",
      "\n",
      "macro\n",
      "Precision: 0.638834633574518\n",
      "Recall: 0.6588470944730981\n",
      "F1 Score: 0.6463562996868224\n",
      "\n",
      "weighted\n",
      "Precision: 0.7675659361208493\n",
      "Recall: 0.7477477477477478\n",
      "F1 Score: 0.7562032159839918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def3\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "percentage = [\"100\", \"50\", \"20\", \"1\"]\n",
    "model_name = [\"XGB\", \"RF\", \"DT\" ]\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "\n",
    "                new_row = {\n",
    "                    \"model\" : \"0\",\n",
    "                    \"attack_model\" : \"0\",\n",
    "                    'epsilon': \"0\",\n",
    "                    'Accuracy': \"0\",\n",
    "                    'Macro Precision': \"0\",\n",
    "                    'Weighted Precision': \"0\",\n",
    "                    'Macro Recall': \"0\",\n",
    "                    'Weighted Recall': \"0\",\n",
    "                    'Macro F1': \"0\",\n",
    "                    'Weighted F1': \"0\",\n",
    "                }\n",
    "                new_row_df = pd.DataFrame([new_row])\n",
    "                new_row_df.to_csv(\"./TRADES.csv\", mode='a', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fdd08f-c86d-4544-804e-c1bf1c0cf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"./TRADES.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e4d6f0-4bb1-43a3-b387-278ab1839807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for epsilon in epsilon_values:\n",
    "#     filename = f'/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "#     x_test_adv = np.load(filename)\n",
    "\n",
    "#     calculate_performance_metrics(x_test_adv, y_test, model, 'DNN', 'BIM', epsilon)\n",
    "\n",
    "# end_time = time.time()\n",
    "# result = end_time - start_time\n",
    "# print(f\"Execution Time: {result:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb86307-4afd-47b9-bc25-af15b6d56c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
