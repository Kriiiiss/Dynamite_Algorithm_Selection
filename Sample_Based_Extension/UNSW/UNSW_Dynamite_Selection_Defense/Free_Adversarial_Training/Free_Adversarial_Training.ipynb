{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddea530e-6be0-41c5-9465-167ce81f9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac054ea5-7fdd-4616-856d-8a5f56d2d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\n",
    "            \"model\" : '',\n",
    "            \"attack_model\": '',\n",
    "            'epsilon': '',\n",
    "            'Accuracy': '',\n",
    "            'Macro Precision': '',\n",
    "            'Weighted Precision': '',\n",
    "            'Macro Recall': '',\n",
    "            'Weighted Recall': '',\n",
    "            'Macro F1': '',\n",
    "            'Weighted F1': '',\n",
    "\n",
    "        }\n",
    "head = pd.DataFrame([head])\n",
    "head.to_csv(\"./Free_Adversarial_Training.csv\", mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e4b2a1-406e-4f69-9a23-4f1a87c2633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    num_classes = len(np.unique(y_test))\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        probabilities = np.array(probabilities)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "        precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        \n",
    "        print(\"\\nmacro\")\n",
    "        print(f\"Precision: {precision_macro}\\nRecall: {recall_macro}\\nF1 Score: {f1_macro}\")\n",
    "    \n",
    "        print(\"\\nweighted\")\n",
    "        print(f\"Precision: {precision_weighted}\\nRecall: {recall_weighted}\\nF1 Score: {f1_weighted}\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "        new_row = {\n",
    "            \"model\" : model_name,\n",
    "            \"attack_model\" : attack_name,\n",
    "            'epsilon': eps,\n",
    "            'Accuracy': accuracy,\n",
    "            'Macro Precision': precision_macro,\n",
    "            'Weighted Precision': precision_weighted,\n",
    "            'Macro Recall': recall_macro,\n",
    "            'Weighted Recall': recall_weighted,\n",
    "            'Macro F1': f1_macro,\n",
    "            'Weighted F1': f1_weighted,\n",
    "\n",
    "        }\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        new_row_df.to_csv(\"./Free_Adversarial_Training.csv\", mode='a', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38849fa5-c16f-43cd-ae85-f38862e14cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_performance_metrics(X_test, y_test, model, model_name, attack_name, eps):\n",
    "#     model.eval()\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model.to(device)\n",
    "    \n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     probabilities = []\n",
    "\n",
    "#     num_classes = len(np.unique(y_test))\n",
    "    \n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "#     test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "#     test_loader = DataLoader(dataset=test_dataset)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "        \n",
    "#         all_preds = np.array(all_preds)\n",
    "#         all_labels = np.array(all_labels)\n",
    "#         probabilities = np.array(probabilities)\n",
    "\n",
    "#         np.save(f\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense_Label/UNSW_Def4/y_pred_{attack_name}{eps}_Def4.npy\", all_preds)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc5288c-f704-4c1e-8b20-f7df5fcf0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_test.npy')\n",
    "x_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_train.npy')\n",
    "x_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/x_val.npy')\n",
    "y_test = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_test.npy')\n",
    "y_train = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_train.npy')\n",
    "y_val = np.load('/home/jovyan/Sample_Based_Extension/UNSW/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4e66be-bf25-4a39-b3ef-4d0d8b807d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03857e0-e780-4fa8-96f3-e1399d7f2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "output_shape = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ac046-77b7-4630-a4a8-fe44438ac801",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884d3dd2-ab96-48dc-85be-71553ba9454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "        self.fc3 = nn.Linear(30, 20)\n",
    "        self.fc4 = nn.Linear(20, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d5036a-16aa-465d-a2d1-c9eeb7a12e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(grad, epsilon):\n",
    "    sign_grad = grad.sign()\n",
    "    return epsilon * sign_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5f35a4-8402-4f6a-bcec-7288dc61b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNNModel(input_size=input_shape, output_size=output_shape).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping variables\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Adversarial training parameters\n",
    "epsilon = 0.03  # Step size for FGSM\n",
    "clip_eps = 0.1  # Maximum perturbation\n",
    "n_repeats = 4   # Number of iterations to update noise\n",
    "\n",
    "global_noise_data = torch.zeros(train_loader.batch_size, input_shape).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9401734a-1d79-40a8-abd8-26586d9bffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         for j in range(n_repeats):\n",
    "#             noise_batch = Variable(global_noise_data[0:inputs.size(0)], requires_grad=True).to(device)\n",
    "#             inputs_adv = inputs + noise_batch\n",
    "#             inputs_adv.clamp_(0, 1.0)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs_adv)\n",
    "#             loss = loss_function(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             pert = fgsm(noise_batch.grad, epsilon)\n",
    "#             global_noise_data[0:inputs.size(0)] += pert.data\n",
    "#             global_noise_data.clamp_(-clip_eps, clip_eps)\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "#     model.eval()\n",
    "#     val_train_loss = 0.0\n",
    "#     correct_predictions = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = loss_function(outputs, labels)\n",
    "#             val_train_loss += loss.item()\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "#     avg_val_loss = val_train_loss / len(val_loader)\n",
    "#     val_accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "#     # Early stopping check using min_delta\n",
    "#     if best_loss - avg_val_loss > min_delta:\n",
    "#         best_loss = avg_val_loss\n",
    "#         patience_counter = 0\n",
    "#     else:\n",
    "#         patience_counter += 1\n",
    "\n",
    "#     if patience_counter >= patience:\n",
    "#         print(\"Early stopping triggered\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35cf713-d051-4056-a9e1-95ce436bdccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3541/1052584200.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/Free_Adversarial_Training/Free_Adversarial_Training.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Defense/Free_Adversarial_Training/Free_Adversarial_Training.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f8ba48-e84d-42c6-b472-b24b2e15feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_performance_metrics(x_test, y_test, model, 'DNN', 'baseline', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc82ea54-6188-4b08-813a-1aa9bee0d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_empty_file():\n",
    "    new_row = {\n",
    "        \"model\" : \"0\",\n",
    "        \"attack_model\" : \"0\",\n",
    "        'epsilon': \"0\",\n",
    "        'Accuracy': \"0\",\n",
    "        'Macro Precision': \"0\",\n",
    "        'Weighted Precision': \"0\",\n",
    "        'Macro Recall': \"0\",\n",
    "        'Weighted Recall': \"0\",\n",
    "        'Macro F1': \"0\",\n",
    "        'Weighted F1': \"0\",\n",
    "    }\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    new_row_df.to_csv(\"./Free_Adversarial_Training.csv\", mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "059664c3-644d-4483-9e99-aeb0a3b6aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage = [\"100\", \"50\", \"20\", \"1\"]\n",
    "# model_name = [\"XGB\", \"RF\", \"DT\" ]\n",
    "\n",
    "percentage = [\"10\"]\n",
    "model_name = [\"RF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0575444-678d-4c09-909d-4ec33601e1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(853, 56) (853,)\n",
      "Accuracy: 0.7069167643610785\n",
      "\n",
      "macro\n",
      "Precision: 0.6003510716925351\n",
      "Recall: 0.5180556663741057\n",
      "F1 Score: 0.46895668977607774\n",
      "\n",
      "weighted\n",
      "Precision: 0.6484207297577612\n",
      "Recall: 0.7069167643610785\n",
      "F1 Score: 0.6169003438525669\n",
      "\n",
      "start RF 10 BIM\n",
      "(518, 56) (518,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8957528957528957\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.44787644787644787\n",
      "F1 Score: 0.4725050916496945\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.8957528957528957\n",
      "F1 Score: 0.945010183299389\n",
      "\n",
      "start RF 10 FGSM\n",
      "(393, 56) (393,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 10 PGD\n",
      "(518, 56) (518,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8957528957528957\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.44787644787644787\n",
      "F1 Score: 0.4725050916496945\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.8957528957528957\n",
      "F1 Score: 0.945010183299389\n",
      "\n",
      "start RF 10 DF\n",
      "(189, 56) (189,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9206349206349206\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.4603174603174603\n",
      "F1 Score: 0.4793388429752066\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9206349206349206\n",
      "F1 Score: 0.9586776859504131\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(1898, 56) (1898,)\n",
      "Accuracy: 0.946786090621707\n",
      "\n",
      "macro\n",
      "Precision: 0.5447574859783479\n",
      "Recall: 0.6285867237687366\n",
      "F1 Score: 0.5618962298000516\n",
      "\n",
      "weighted\n",
      "Precision: 0.9743671228007282\n",
      "Recall: 0.946786090621707\n",
      "F1 Score: 0.9595508471076417\n",
      "\n",
      "start RF 10 ZOO\n",
      "(2319, 56) (2319,)\n",
      "Accuracy: 0.7705907718844329\n",
      "\n",
      "macro\n",
      "Precision: 0.6134197199880846\n",
      "Recall: 0.5218889863601716\n",
      "F1 Score: 0.49366313487672664\n",
      "\n",
      "weighted\n",
      "Precision: 0.7061776008708158\n",
      "Recall: 0.7705907718844329\n",
      "F1 Score: 0.6992193342416305\n",
      "\n",
      "start RF 10 CaFA\n",
      "(591, 56) (591,)\n",
      "Accuracy: 0.7258883248730964\n",
      "\n",
      "macro\n",
      "Precision: 0.7353475810849411\n",
      "Recall: 0.7099666388657214\n",
      "F1 Score: 0.7112656517648194\n",
      "\n",
      "weighted\n",
      "Precision: 0.7324119498467825\n",
      "Recall: 0.7258883248730964\n",
      "F1 Score: 0.7181921811318979\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(326, 56) (326,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9815950920245399\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.49079754601226994\n",
      "F1 Score: 0.4953560371517028\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9815950920245399\n",
      "F1 Score: 0.9907120743034055\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(355, 56) (355,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bde7b68-71d3-40f2-a3cd-df5984f252d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(889, 56) (889,)\n",
      "Accuracy: 0.6872890888638921\n",
      "\n",
      "macro\n",
      "Precision: 0.6164980732177263\n",
      "Recall: 0.5141830870279146\n",
      "F1 Score: 0.448461936727844\n",
      "\n",
      "weighted\n",
      "Precision: 0.6441915858783548\n",
      "Recall: 0.6872890888638921\n",
      "F1 Score: 0.5827766940829889\n",
      "\n",
      "start RF 10 BIM\n",
      "(376, 56) (376,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9654255319148937\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.48271276595744683\n",
      "F1 Score: 0.4912043301759134\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9654255319148937\n",
      "F1 Score: 0.9824086603518268\n",
      "\n",
      "start RF 10 FGSM\n",
      "(338, 56) (338,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 10 PGD\n",
      "(376, 56) (376,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9654255319148937\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.48271276595744683\n",
      "F1 Score: 0.4912043301759134\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9654255319148937\n",
      "F1 Score: 0.9824086603518268\n",
      "\n",
      "start RF 10 DF\n",
      "(212, 56) (212,)\n",
      "Accuracy: 0.8160377358490566\n",
      "\n",
      "macro\n",
      "Precision: 0.524390243902439\n",
      "Recall: 0.9071428571428571\n",
      "F1 Score: 0.49533052554477197\n",
      "\n",
      "weighted\n",
      "Precision: 0.9910262310170271\n",
      "Recall: 0.8160377358490566\n",
      "F1 Score: 0.8900470920731222\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(1887, 56) (1887,)\n",
      "Accuracy: 0.9523052464228935\n",
      "\n",
      "macro\n",
      "Precision: 0.48384491114701134\n",
      "Recall: 0.4917898193760263\n",
      "F1 Score: 0.48778501628664495\n",
      "\n",
      "weighted\n",
      "Precision: 0.9369206705517644\n",
      "Recall: 0.9523052464228935\n",
      "F1 Score: 0.9445503177060947\n",
      "\n",
      "start RF 10 ZOO\n",
      "(2288, 56) (2288,)\n",
      "Accuracy: 0.7482517482517482\n",
      "\n",
      "macro\n",
      "Precision: 0.6595803044849815\n",
      "Recall: 0.5245253474261108\n",
      "F1 Score: 0.4862011050344095\n",
      "\n",
      "weighted\n",
      "Precision: 0.7056894552437002\n",
      "Recall: 0.7482517482517482\n",
      "F1 Score: 0.665498913551536\n",
      "\n",
      "start RF 10 CaFA\n",
      "(177, 56) (177,)\n",
      "Accuracy: 0.1751412429378531\n",
      "\n",
      "macro\n",
      "Precision: 0.5408805031446541\n",
      "Recall: 0.5548780487804879\n",
      "F1 Score: 0.17448249424993612\n",
      "\n",
      "weighted\n",
      "Precision: 0.9325587179760509\n",
      "Recall: 0.1751412429378531\n",
      "F1 Score: 0.1943767046250294\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(314, 56) (314,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9904458598726115\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.49522292993630573\n",
      "F1 Score: 0.4976\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9904458598726115\n",
      "F1 Score: 0.9952\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(352, 56) (352,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}_ExcludeCaFA/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}_ExcludeCaFA/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}_ExcludeCaFA\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0032d054-3b27-4949-aece-192bce0f877b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(1216, 56) (1216,)\n",
      "Accuracy: 0.7138157894736842\n",
      "\n",
      "macro\n",
      "Precision: 0.58428957383145\n",
      "Recall: 0.5096557347044044\n",
      "F1 Score: 0.4502112533325018\n",
      "\n",
      "weighted\n",
      "Precision: 0.6431244524392351\n",
      "Recall: 0.7138157894736842\n",
      "F1 Score: 0.6148858210406514\n",
      "\n",
      "start RF 10 BIM\n",
      "(100, 56) (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.34\n",
      "F1 Score: 0.40476190476190477\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.68\n",
      "F1 Score: 0.8095238095238095\n",
      "\n",
      "start RF 10 FGSM\n",
      "(54, 56) (54,)\n",
      "Accuracy: 0.9444444444444444\n",
      "\n",
      "macro\n",
      "Precision: 0.49038461538461536\n",
      "Recall: 0.4811320754716981\n",
      "F1 Score: 0.4857142857142857\n",
      "\n",
      "weighted\n",
      "Precision: 0.9626068376068375\n",
      "Recall: 0.9444444444444444\n",
      "F1 Score: 0.9534391534391534\n",
      "\n",
      "start RF 10 PGD\n",
      "(100, 56) (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.34\n",
      "F1 Score: 0.40476190476190477\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.68\n",
      "F1 Score: 0.8095238095238095\n",
      "\n",
      "start RF 10 DF\n",
      "(195, 56) (195,)\n",
      "Accuracy: 0.8974358974358975\n",
      "\n",
      "macro\n",
      "Precision: 0.602881698685541\n",
      "Recall: 0.8092705167173253\n",
      "F1 Score: 0.6388888888888888\n",
      "\n",
      "weighted\n",
      "Precision: 0.9606958595836249\n",
      "Recall: 0.8974358974358975\n",
      "F1 Score: 0.9225071225071225\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(2567, 56) (2567,)\n",
      "Accuracy: 0.9333852746396571\n",
      "\n",
      "macro\n",
      "Precision: 0.4793917567026811\n",
      "Recall: 0.4862012987012987\n",
      "F1 Score: 0.4827725166230103\n",
      "\n",
      "weighted\n",
      "Precision: 0.9203126517455444\n",
      "Recall: 0.9333852746396571\n",
      "F1 Score: 0.9268028679073606\n",
      "\n",
      "start RF 10 ZOO\n",
      "(3225, 56) (3225,)\n",
      "Accuracy: 0.7686821705426357\n",
      "\n",
      "macro\n",
      "Precision: 0.6135902745929833\n",
      "Recall: 0.5172897751813863\n",
      "F1 Score: 0.48210324827184775\n",
      "\n",
      "weighted\n",
      "Precision: 0.7027159423999545\n",
      "Recall: 0.7686821705426357\n",
      "F1 Score: 0.691273607961781\n",
      "\n",
      "start RF 10 CaFA\n",
      "(185, 56) (185,)\n",
      "Accuracy: 0.34054054054054056\n",
      "\n",
      "macro\n",
      "Precision: 0.5121136173767753\n",
      "Recall: 0.5039747807017544\n",
      "F1 Score: 0.3028786755621448\n",
      "\n",
      "weighted\n",
      "Precision: 0.5897039897039897\n",
      "Recall: 0.34054054054054056\n",
      "F1 Score: 0.2406928054815379\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(39, 56) (39,)\n",
      "Accuracy: 0.8974358974358975\n",
      "\n",
      "macro\n",
      "Precision: 0.4861111111111111\n",
      "Recall: 0.4605263157894737\n",
      "F1 Score: 0.47297297297297297\n",
      "\n",
      "weighted\n",
      "Precision: 0.9472934472934472\n",
      "Recall: 0.8974358974358975\n",
      "F1 Score: 0.9216909216909216\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(37, 56) (37,)\n",
      "Accuracy: 0.9459459459459459\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.47297297297297297\n",
      "F1 Score: 0.4861111111111111\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9459459459459459\n",
      "F1 Score: 0.9722222222222222\n",
      "\n",
      "start RF 10 baseline\n",
      "(1818, 56) (1818,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6611661166116611\n",
      "\n",
      "macro\n",
      "Precision: 0.5418247902079214\n",
      "Recall: 0.5053225716489566\n",
      "F1 Score: 0.42983870967741933\n",
      "\n",
      "weighted\n",
      "Precision: 0.5839288562989604\n",
      "Recall: 0.6611661166116611\n",
      "F1 Score: 0.5504965281474383\n",
      "\n",
      "start RF 10 BIM\n",
      "(2684, 56) (2684,)\n",
      "Accuracy: 0.5432190760059612\n",
      "\n",
      "macro\n",
      "Precision: 0.5637264395603907\n",
      "Recall: 0.7348169171205459\n",
      "F1 Score: 0.45458113629869196\n",
      "\n",
      "weighted\n",
      "Precision: 0.9309364182068918\n",
      "Recall: 0.5432190760059612\n",
      "F1 Score: 0.6423428348283234\n",
      "\n",
      "start RF 10 FGSM\n",
      "(4093, 56) (4093,)\n",
      "Accuracy: 0.7730271194722698\n",
      "\n",
      "macro\n",
      "Precision: 0.6268608841971224\n",
      "Recall: 0.8469966958211856\n",
      "F1 Score: 0.6341092544238857\n",
      "\n",
      "weighted\n",
      "Precision: 0.9310688033067295\n",
      "Recall: 0.7730271194722698\n",
      "F1 Score: 0.8217750618068533\n",
      "\n",
      "start RF 10 PGD\n",
      "(2684, 56) (2684,)\n",
      "Accuracy: 0.5432190760059612\n",
      "\n",
      "macro\n",
      "Precision: 0.5637264395603907\n",
      "Recall: 0.7348169171205459\n",
      "F1 Score: 0.45458113629869196\n",
      "\n",
      "weighted\n",
      "Precision: 0.9309364182068918\n",
      "Recall: 0.5432190760059612\n",
      "F1 Score: 0.6423428348283234\n",
      "\n",
      "start RF 10 DF\n",
      "(1463, 56) (1463,)\n",
      "Accuracy: 0.2706766917293233\n",
      "\n",
      "macro\n",
      "Precision: 0.32352263486039573\n",
      "Recall: 0.2162282913950172\n",
      "F1 Score: 0.23257147042932647\n",
      "\n",
      "weighted\n",
      "Precision: 0.5025794018795973\n",
      "Recall: 0.2706766917293233\n",
      "F1 Score: 0.3406921136885199\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(5711, 56) (5711,)\n",
      "Accuracy: 0.744177902293819\n",
      "\n",
      "macro\n",
      "Precision: 0.5432654904421624\n",
      "Recall: 0.6230455546137962\n",
      "F1 Score: 0.5298432363946484\n",
      "\n",
      "weighted\n",
      "Precision: 0.891993561102026\n",
      "Recall: 0.744177902293819\n",
      "F1 Score: 0.8018192530556031\n",
      "\n",
      "start RF 10 ZOO\n",
      "(4664, 56) (4664,)\n",
      "Accuracy: 0.741852487135506\n",
      "\n",
      "macro\n",
      "Precision: 0.5322453197662864\n",
      "Recall: 0.5050158737695881\n",
      "F1 Score: 0.4584390810317658\n",
      "\n",
      "weighted\n",
      "Precision: 0.6451254222118169\n",
      "Recall: 0.741852487135506\n",
      "F1 Score: 0.656845265150626\n",
      "\n",
      "start RF 10 CaFA\n",
      "(503, 56) (503,)\n",
      "Accuracy: 0.4831013916500994\n",
      "\n",
      "macro\n",
      "Precision: 0.3802660753880266\n",
      "Recall: 0.48975332068311195\n",
      "F1 Score: 0.3356025198130461\n",
      "\n",
      "weighted\n",
      "Precision: 0.37876951153390076\n",
      "Recall: 0.4831013916500994\n",
      "F1 Score: 0.3312460130499264\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(5075, 56) (5075,)\n",
      "Accuracy: 0.46916256157635466\n",
      "\n",
      "macro\n",
      "Precision: 0.5685779873025781\n",
      "Recall: 0.697434627865691\n",
      "F1 Score: 0.41930915711112626\n",
      "\n",
      "weighted\n",
      "Precision: 0.9174967683957116\n",
      "Recall: 0.46916256157635466\n",
      "F1 Score: 0.5587444692637052\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(3808, 56) (3808,)\n",
      "Accuracy: 0.5028886554621849\n",
      "\n",
      "macro\n",
      "Precision: 0.5149011197093972\n",
      "Recall: 0.6146059782608696\n",
      "F1 Score: 0.3741678810348892\n",
      "\n",
      "weighted\n",
      "Precision: 0.950291660587952\n",
      "Recall: 0.5028886554621849\n",
      "F1 Score: 0.6389137934643937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "total_num_attack = [\"2\", \"3\"]\n",
    "for num_attack in total_num_attack:\n",
    "    for m_name in model_name:\n",
    "        for p in percentage:\n",
    "            for attack in attack_names:\n",
    "                print(f\"start {m_name} {p} {attack}\")\n",
    "                \n",
    "                x_path = f\"{base_path}/{m_name}_Exclude{num_attack}Attack/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "                y_path = f\"{base_path}/{m_name}_Exclude{num_attack}Attack/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "    \n",
    "                try:\n",
    "                    x_test_adv = np.load(x_path)\n",
    "                    y_test_adv = np.load(y_path)\n",
    "                    print(x_test_adv.shape, y_test_adv.shape)\n",
    "    \n",
    "                    m_per_name = f\"{m_name}{p}_Exclude{num_attack}Attack\"\n",
    "                    calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "                except FileNotFoundError:\n",
    "                    print(x_path, \"not found\")\n",
    "                    print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c8bdf1-b9da-4a09-9d73-2336c04e7545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start baseline\n",
      "Accuracy: 0.9138321995464853\n",
      "\n",
      "macro\n",
      "Precision: 0.8151260504201681\n",
      "Recall: 0.5400041562759768\n",
      "F1 Score: 0.5519357828690941\n",
      "\n",
      "weighted\n",
      "Precision: 0.8976733550563083\n",
      "Recall: 0.9138321995464853\n",
      "F1 Score: 0.8815689361589297\n",
      "\n",
      "start BIM\n",
      "Accuracy: 0.6554959785522788\n",
      "\n",
      "macro\n",
      "Precision: 0.5327906150017775\n",
      "Recall: 0.5996347589639599\n",
      "F1 Score: 0.4908733656042393\n",
      "\n",
      "weighted\n",
      "Precision: 0.8748318158988\n",
      "Recall: 0.6554959785522788\n",
      "F1 Score: 0.7331891589204955\n",
      "\n",
      "start FGSM\n",
      "Accuracy: 0.7620614035087719\n",
      "\n",
      "macro\n",
      "Precision: 0.5517007750971163\n",
      "Recall: 0.6456794972505892\n",
      "F1 Score: 0.5444449417683446\n",
      "\n",
      "weighted\n",
      "Precision: 0.8992531176902864\n",
      "Recall: 0.7620614035087719\n",
      "F1 Score: 0.8155736481990409\n",
      "\n",
      "start PGD\n",
      "Accuracy: 0.6554959785522788\n",
      "\n",
      "macro\n",
      "Precision: 0.5327906150017775\n",
      "Recall: 0.5996347589639599\n",
      "F1 Score: 0.4908733656042393\n",
      "\n",
      "weighted\n",
      "Precision: 0.8748318158988\n",
      "Recall: 0.6554959785522788\n",
      "F1 Score: 0.7331891589204955\n",
      "\n",
      "start DF\n",
      "Accuracy: 0.6775818639798489\n",
      "\n",
      "macro\n",
      "Precision: 0.5630131362889984\n",
      "Recall: 0.7676703092304116\n",
      "F1 Score: 0.5168111973223795\n",
      "\n",
      "weighted\n",
      "Precision: 0.9388413925459004\n",
      "Recall: 0.6775818639798489\n",
      "F1 Score: 0.763232612155444\n",
      "\n",
      "start AutoPGD\n",
      "Accuracy: 0.7893417975275643\n",
      "\n",
      "macro\n",
      "Precision: 0.5522762148337595\n",
      "Recall: 0.6927028451001054\n",
      "F1 Score: 0.5458687350070003\n",
      "\n",
      "weighted\n",
      "Precision: 0.9329623853783295\n",
      "Recall: 0.7893417975275643\n",
      "F1 Score: 0.8459466459666368\n",
      "\n",
      "start ZOO\n",
      "Accuracy: 0.961510353227771\n",
      "\n",
      "macro\n",
      "Precision: 0.8038307373158469\n",
      "Recall: 0.577505792660139\n",
      "F1 Score: 0.6174810211986959\n",
      "\n",
      "weighted\n",
      "Precision: 0.9514715614661563\n",
      "Recall: 0.961510353227771\n",
      "F1 Score: 0.9501988313937814\n",
      "\n",
      "start CaFA\n",
      "Accuracy: 0.8428246013667426\n",
      "\n",
      "macro\n",
      "Precision: 0.8220482288733746\n",
      "Recall: 0.8289505116428373\n",
      "F1 Score: 0.825255347217527\n",
      "\n",
      "weighted\n",
      "Precision: 0.8448928375425531\n",
      "Recall: 0.8428246013667426\n",
      "F1 Score: 0.8436576263479555\n",
      "\n",
      "start SINIFGSM\n",
      "Accuracy: 0.6097509048328721\n",
      "\n",
      "macro\n",
      "Precision: 0.5342163827623347\n",
      "Recall: 0.6090668536005914\n",
      "F1 Score: 0.4731013096885003\n",
      "\n",
      "weighted\n",
      "Precision: 0.8774039390063404\n",
      "Recall: 0.609750904832872\n",
      "F1 Score: 0.6970992455417954\n",
      "\n",
      "start VNIFGSM\n",
      "Accuracy: 0.5930588023736738\n",
      "\n",
      "macro\n",
      "Precision: 0.5037970104288056\n",
      "Recall: 0.5175730468847468\n",
      "F1 Score: 0.4205895467980137\n",
      "\n",
      "weighted\n",
      "Precision: 0.8994417122363635\n",
      "Recall: 0.5930588023736737\n",
      "F1 Score: 0.7020316312921117\n",
      "\n",
      "start baseline\n",
      "Accuracy: 0.93048128342246\n",
      "\n",
      "macro\n",
      "Precision: 0.8407955418908533\n",
      "Recall: 0.530755224139426\n",
      "F1 Score: 0.5401609758922195\n",
      "\n",
      "weighted\n",
      "Precision: 0.9184122045156544\n",
      "Recall: 0.93048128342246\n",
      "F1 Score: 0.902323848302119\n",
      "\n",
      "start BIM\n",
      "Accuracy: 0.6047221656828822\n",
      "\n",
      "macro\n",
      "Precision: 0.5483598134000406\n",
      "Recall: 0.6444877058493796\n",
      "F1 Score: 0.4865469601961456\n",
      "\n",
      "weighted\n",
      "Precision: 0.8787400064757364\n",
      "Recall: 0.6047221656828822\n",
      "F1 Score: 0.6884525828075534\n",
      "\n",
      "start FGSM\n",
      "Accuracy: 0.6993766696349065\n",
      "\n",
      "macro\n",
      "Precision: 0.5279443368543189\n",
      "Recall: 0.6115854237332939\n",
      "F1 Score: 0.4885593723357184\n",
      "\n",
      "weighted\n",
      "Precision: 0.9125296016212061\n",
      "Recall: 0.6993766696349066\n",
      "F1 Score: 0.7801948401945398\n",
      "\n",
      "start PGD\n",
      "Accuracy: 0.6047221656828822\n",
      "\n",
      "macro\n",
      "Precision: 0.5483598134000406\n",
      "Recall: 0.6444877058493796\n",
      "F1 Score: 0.4865469601961456\n",
      "\n",
      "weighted\n",
      "Precision: 0.8787400064757364\n",
      "Recall: 0.6047221656828822\n",
      "F1 Score: 0.6884525828075534\n",
      "\n",
      "start DF\n",
      "Accuracy: 0.8803611738148984\n",
      "\n",
      "macro\n",
      "Precision: 0.6589781562384303\n",
      "Recall: 0.8695352839931153\n",
      "F1 Score: 0.7038658005927981\n",
      "\n",
      "weighted\n",
      "Precision: 0.9474469367168584\n",
      "Recall: 0.8803611738148984\n",
      "F1 Score: 0.903584249238859\n",
      "\n",
      "start AutoPGD\n",
      "Accuracy: 0.7629001607952054\n",
      "\n",
      "macro\n",
      "Precision: 0.5755044366157833\n",
      "Recall: 0.7640149649065188\n",
      "F1 Score: 0.5683060666290274\n",
      "\n",
      "weighted\n",
      "Precision: 0.9323442869896876\n",
      "Recall: 0.7629001607952054\n",
      "F1 Score: 0.8234857376856113\n",
      "\n",
      "start ZOO\n",
      "Accuracy: 0.9614060963618486\n",
      "\n",
      "macro\n",
      "Precision: 0.781820430373485\n",
      "Recall: 0.5450162143710531\n",
      "F1 Score: 0.5703384477111102\n",
      "\n",
      "weighted\n",
      "Precision: 0.9491595875313827\n",
      "Recall: 0.9614060963618486\n",
      "F1 Score: 0.947601337829215\n",
      "\n",
      "start CaFA\n",
      "Accuracy: 0.8541076487252125\n",
      "\n",
      "macro\n",
      "Precision: 0.8325455193117968\n",
      "Recall: 0.8456697203276968\n",
      "F1 Score: 0.8382588774341351\n",
      "\n",
      "weighted\n",
      "Precision: 0.8583201177165752\n",
      "Recall: 0.8541076487252125\n",
      "F1 Score: 0.8555180220376915\n",
      "\n",
      "start SINIFGSM\n",
      "Accuracy: 0.5615835777126099\n",
      "\n",
      "macro\n",
      "Precision: 0.5474755389468186\n",
      "Recall: 0.6348076621228402\n",
      "F1 Score: 0.46759080438977774\n",
      "\n",
      "weighted\n",
      "Precision: 0.8702622407085833\n",
      "Recall: 0.5615835777126099\n",
      "F1 Score: 0.6477041373721107\n",
      "\n",
      "start VNIFGSM\n",
      "Accuracy: 0.5252001884126236\n",
      "\n",
      "macro\n",
      "Precision: 0.5020853273029694\n",
      "Recall: 0.5151946456071304\n",
      "F1 Score: 0.37566256117969155\n",
      "\n",
      "weighted\n",
      "Precision: 0.9335384288355371\n",
      "Recall: 0.5252001884126236\n",
      "F1 Score: 0.6595297861836247\n",
      "\n",
      "start baseline\n",
      "Accuracy: 0.9421742482652274\n",
      "\n",
      "macro\n",
      "Precision: 0.8466834755624515\n",
      "Recall: 0.5371536654819065\n",
      "F1 Score: 0.5540073999697399\n",
      "\n",
      "weighted\n",
      "Precision: 0.9315890103856066\n",
      "Recall: 0.9421742482652274\n",
      "F1 Score: 0.9193975158445831\n",
      "\n",
      "start BIM\n",
      "Accuracy: 0.5454236712514858\n",
      "\n",
      "macro\n",
      "Precision: 0.5380920383763211\n",
      "Recall: 0.6291289506043435\n",
      "F1 Score: 0.4431298127199662\n",
      "\n",
      "weighted\n",
      "Precision: 0.8900815972859286\n",
      "Recall: 0.5454236712514858\n",
      "F1 Score: 0.6435430973627414\n",
      "\n",
      "start FGSM\n",
      "Accuracy: 0.7062866383666869\n",
      "\n",
      "macro\n",
      "Precision: 0.5375894611980581\n",
      "Recall: 0.611578832276405\n",
      "F1 Score: 0.5122953230569188\n",
      "\n",
      "weighted\n",
      "Precision: 0.8846543543538993\n",
      "Recall: 0.7062866383666869\n",
      "F1 Score: 0.7733753015779816\n",
      "\n",
      "start PGD\n",
      "Accuracy: 0.5454236712514858\n",
      "\n",
      "macro\n",
      "Precision: 0.5380920383763211\n",
      "Recall: 0.6291289506043435\n",
      "F1 Score: 0.4431298127199662\n",
      "\n",
      "weighted\n",
      "Precision: 0.8900815972859286\n",
      "Recall: 0.5454236712514858\n",
      "F1 Score: 0.6435430973627414\n",
      "\n",
      "start DF\n",
      "Accuracy: 0.6472081218274112\n",
      "\n",
      "macro\n",
      "Precision: 0.5197576992753623\n",
      "Recall: 0.5704410132203047\n",
      "F1 Score: 0.4672308964443796\n",
      "\n",
      "weighted\n",
      "Precision: 0.886987730357537\n",
      "Recall: 0.6472081218274112\n",
      "F1 Score: 0.7344459908995357\n",
      "\n",
      "start AutoPGD\n",
      "Accuracy: 0.688816644993498\n",
      "\n",
      "macro\n",
      "Precision: 0.5541529225102122\n",
      "Recall: 0.7238765469858486\n",
      "F1 Score: 0.5131821989924642\n",
      "\n",
      "weighted\n",
      "Precision: 0.9301720687874332\n",
      "Recall: 0.688816644993498\n",
      "F1 Score: 0.771823788448847\n",
      "\n",
      "start ZOO\n",
      "Accuracy: 0.9552825552825552\n",
      "\n",
      "macro\n",
      "Precision: 0.7673191052271171\n",
      "Recall: 0.5389065147337297\n",
      "F1 Score: 0.5592764122384479\n",
      "\n",
      "weighted\n",
      "Precision: 0.9403128429834661\n",
      "Recall: 0.9552825552825552\n",
      "F1 Score: 0.9388592834092901\n",
      "\n",
      "start CaFA\n",
      "Accuracy: 0.8316086547507056\n",
      "\n",
      "macro\n",
      "Precision: 0.8100042599300685\n",
      "Recall: 0.8224331302998915\n",
      "F1 Score: 0.8152853133588257\n",
      "\n",
      "weighted\n",
      "Precision: 0.8364772507666238\n",
      "Recall: 0.8316086547507056\n",
      "F1 Score: 0.8332616513473516\n",
      "\n",
      "start SINIFGSM\n",
      "Accuracy: 0.5383845126835781\n",
      "\n",
      "macro\n",
      "Precision: 0.5470704151032483\n",
      "Recall: 0.6176640962949032\n",
      "F1 Score: 0.4622983700643417\n",
      "\n",
      "weighted\n",
      "Precision: 0.8479656317607789\n",
      "Recall: 0.5383845126835782\n",
      "F1 Score: 0.6189939663547124\n",
      "\n",
      "start VNIFGSM\n",
      "Accuracy: 0.5072512085347558\n",
      "\n",
      "macro\n",
      "Precision: 0.4937942842267219\n",
      "Recall: 0.4697502779208807\n",
      "F1 Score: 0.3743363741081678\n",
      "\n",
      "weighted\n",
      "Precision: 0.8914798539707736\n",
      "Recall: 0.5072512085347559\n",
      "F1 Score: 0.6314652888813393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "rec_list = [\"Euclidean\", \"cosine\", \"manhattan\"]\n",
    "for rec in rec_list:\n",
    "    for attack in attack_names:\n",
    "        print(f\"start {attack}\")\n",
    "        \n",
    "        x_path = f\"{base_path}/Recommendation_{rec}/x_test_adv_{attack}_{Def}.npy\"\n",
    "        y_path = f\"{base_path}/Recommendation_{rec}/y_test_adv_{attack}_{Def}.npy\"\n",
    "    \n",
    "        try:\n",
    "            x_test_adv = np.load(x_path)\n",
    "            y_test_adv = np.load(y_path)\n",
    "            m_per_name = f\"Recommendation_{rec}\"\n",
    "            calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "        except FileNotFoundError:\n",
    "            print(x_path, \"not found\")\n",
    "            print_empty_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ceceb1-fa74-4d66-9dd6-71430bed6fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(68, 56) (68,)\n",
      "Accuracy: 0.9117647058823529\n",
      "\n",
      "macro\n",
      "Precision: 0.5841269841269842\n",
      "Recall: 0.6358974358974359\n",
      "F1 Score: 0.6015625\n",
      "\n",
      "weighted\n",
      "Precision: 0.9343604108309991\n",
      "Recall: 0.9117647058823529\n",
      "F1 Score: 0.9221047794117647\n",
      "\n",
      "start RF 10 BIM\n",
      "(895, 56) (895,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32849162011173183\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.16424581005586592\n",
      "F1 Score: 0.24726661059714045\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.32849162011173183\n",
      "F1 Score: 0.4945332211942809\n",
      "\n",
      "start RF 10 FGSM\n",
      "(862, 56) (862,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.728538283062645\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.3642691415313225\n",
      "F1 Score: 0.4214765100671141\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.728538283062645\n",
      "F1 Score: 0.8429530201342282\n",
      "\n",
      "start RF 10 PGD\n",
      "(895, 56) (895,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32849162011173183\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.16424581005586592\n",
      "F1 Score: 0.24726661059714045\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.32849162011173183\n",
      "F1 Score: 0.4945332211942809\n",
      "\n",
      "start RF 10 DF\n",
      "(583, 56) (583,)\n",
      "Accuracy: 0.4957118353344768\n",
      "\n",
      "macro\n",
      "Precision: 0.5121314604887935\n",
      "Recall: 0.5710882474796299\n",
      "F1 Score: 0.3764116071948309\n",
      "\n",
      "weighted\n",
      "Precision: 0.9273134108193737\n",
      "Recall: 0.4957118353344768\n",
      "F1 Score: 0.6248367881444467\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(1068, 56) (1068,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40730337078651685\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.20365168539325842\n",
      "F1 Score: 0.2894211576846307\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.40730337078651685\n",
      "F1 Score: 0.5788423153692615\n",
      "\n",
      "start RF 10 ZOO\n",
      "(198, 56) (198,)\n",
      "Accuracy: 0.9090909090909091\n",
      "\n",
      "macro\n",
      "Precision: 0.5836065573770491\n",
      "Recall: 0.6349206349206349\n",
      "F1 Score: 0.6008064516129032\n",
      "\n",
      "weighted\n",
      "Precision: 0.9323397913561848\n",
      "Recall: 0.9090909090909091\n",
      "F1 Score: 0.9197214076246335\n",
      "\n",
      "start RF 10 CaFA\n",
      "(1, 56) (1,)\n",
      "Accuracy: 1.0\n",
      "\n",
      "macro\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(1713, 56) (1713,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29071803852889666\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.14535901926444833\n",
      "F1 Score: 0.22523744911804613\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.29071803852889666\n",
      "F1 Score: 0.45047489823609227\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(2193, 56) (2193,)\n",
      "Accuracy: 0.3743730050159599\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.18718650250797994\n",
      "F1 Score: 0.2723954877239549\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.3743730050159599\n",
      "F1 Score: 0.5447909754479098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}_Cluster/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}_Cluster/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}_Cluster\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac17e6c4-32b8-4f1f-9dd9-66e85bd306a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "(325, 56) (325,)\n",
      "Accuracy: 0.963076923076923\n",
      "\n",
      "macro\n",
      "Precision: 0.9814241486068112\n",
      "Recall: 0.5714285714285714\n",
      "F1 Score: 0.6155362776025237\n",
      "\n",
      "weighted\n",
      "Precision: 0.9644486782567279\n",
      "Recall: 0.963076923076923\n",
      "F1 Score: 0.9495801989808298\n",
      "\n",
      "start RF 10 BIM\n",
      "(507, 56) (507,)\n",
      "Accuracy: 0.9428007889546351\n",
      "\n",
      "macro\n",
      "Precision: 0.8243243243243243\n",
      "Recall: 0.8970240700218819\n",
      "F1 Score: 0.8555881861844754\n",
      "\n",
      "weighted\n",
      "Precision: 0.9508857970396432\n",
      "Recall: 0.9428007889546351\n",
      "F1 Score: 0.9456783621424829\n",
      "\n",
      "start RF 10 FGSM\n",
      "(439, 56) (439,)\n",
      "Accuracy: 0.9658314350797267\n",
      "\n",
      "macro\n",
      "Precision: 0.5833333333333334\n",
      "Recall: 0.9827981651376148\n",
      "F1 Score: 0.6341056842807135\n",
      "\n",
      "weighted\n",
      "Precision: 0.9943052391799544\n",
      "Recall: 0.9658314350797267\n",
      "F1 Score: 0.9777354691993084\n",
      "\n",
      "start RF 10 PGD\n",
      "(507, 56) (507,)\n",
      "Accuracy: 0.9428007889546351\n",
      "\n",
      "macro\n",
      "Precision: 0.8243243243243243\n",
      "Recall: 0.8970240700218819\n",
      "F1 Score: 0.8555881861844754\n",
      "\n",
      "weighted\n",
      "Precision: 0.9508857970396432\n",
      "Recall: 0.9428007889546351\n",
      "F1 Score: 0.9456783621424829\n",
      "\n",
      "start RF 10 DF\n",
      "(106, 56) (106,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9433962264150944\n",
      "\n",
      "macro\n",
      "Precision: 0.5\n",
      "Recall: 0.4716981132075472\n",
      "F1 Score: 0.4854368932038835\n",
      "\n",
      "weighted\n",
      "Precision: 1.0\n",
      "Recall: 0.9433962264150944\n",
      "F1 Score: 0.9708737864077671\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "(914, 56) (914,)\n",
      "Accuracy: 0.9879649890590809\n",
      "\n",
      "macro\n",
      "Precision: 0.9149345650500385\n",
      "Recall: 0.9605238565668972\n",
      "F1 Score: 0.9363940607463923\n",
      "\n",
      "weighted\n",
      "Precision: 0.9888577815286291\n",
      "Recall: 0.9879649890590809\n",
      "F1 Score: 0.9882782996806648\n",
      "\n",
      "start RF 10 ZOO\n",
      "(1331, 56) (1331,)\n",
      "Accuracy: 0.9887302779864763\n",
      "\n",
      "macro\n",
      "Precision: 0.778208174904943\n",
      "Recall: 0.762042259826305\n",
      "F1 Score: 0.7698744769874477\n",
      "\n",
      "weighted\n",
      "Precision: 0.9884061484975133\n",
      "Recall: 0.9887302779864763\n",
      "F1 Score: 0.9885616679702982\n",
      "\n",
      "start RF 10 CaFA\n",
      "(530, 56) (530,)\n",
      "Accuracy: 0.8943396226415095\n",
      "\n",
      "macro\n",
      "Precision: 0.8435927216415021\n",
      "Recall: 0.9032098765432099\n",
      "F1 Score: 0.8659221915035868\n",
      "\n",
      "weighted\n",
      "Precision: 0.9119058576030503\n",
      "Recall: 0.8943396226415095\n",
      "F1 Score: 0.8985323583831701\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "(472, 56) (472,)\n",
      "Accuracy: 0.875\n",
      "\n",
      "macro\n",
      "Precision: 0.8431109572841856\n",
      "Recall: 0.7950396825396826\n",
      "F1 Score: 0.8148687368288094\n",
      "\n",
      "weighted\n",
      "Precision: 0.87038158691702\n",
      "Recall: 0.875\n",
      "F1 Score: 0.8703057378193494\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "(514, 56) (514,)\n",
      "Accuracy: 0.9396887159533074\n",
      "\n",
      "macro\n",
      "Precision: 0.825093574547723\n",
      "Recall: 0.8531105746834371\n",
      "F1 Score: 0.8383106537997098\n",
      "\n",
      "weighted\n",
      "Precision: 0.9425393413614065\n",
      "Recall: 0.9396887159533074\n",
      "F1 Score: 0.9409341466922951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for m_name in model_name:\n",
    "    for p in percentage:\n",
    "        for attack in attack_names:\n",
    "            print(f\"start {m_name} {p} {attack}\")\n",
    "            \n",
    "            x_path = f\"{base_path}/{m_name}_ActiveLearning/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "            y_path = f\"{base_path}/{m_name}_ActiveLearning/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "\n",
    "            try:\n",
    "                x_test_adv = np.load(x_path)\n",
    "                y_test_adv = np.load(y_path)\n",
    "                print(x_test_adv.shape, y_test_adv.shape)\n",
    "\n",
    "                m_per_name = f\"{m_name}{p}_ActiveLearning\"\n",
    "                calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "            except FileNotFoundError:\n",
    "                print(x_path, \"not found\")\n",
    "                print_empty_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bed583c6-8ddf-4865-8295-c4d3fa215239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start RF 10 baseline\n",
      "Accuracy: 0.7199363732767763\n",
      "\n",
      "macro\n",
      "Precision: 0.7329848947966904\n",
      "Recall: 0.7369276933940886\n",
      "F1 Score: 0.7197082910596397\n",
      "\n",
      "weighted\n",
      "Precision: 0.7524857183181798\n",
      "Recall: 0.7199363732767763\n",
      "F1 Score: 0.7210869590338546\n",
      "\n",
      "start RF 10 BIM\n",
      "Accuracy: 0.8039558344586544\n",
      "\n",
      "macro\n",
      "Precision: 0.6682013526769125\n",
      "Recall: 0.7268351438165676\n",
      "F1 Score: 0.6868889204308908\n",
      "\n",
      "weighted\n",
      "Precision: 0.8420896431590617\n",
      "Recall: 0.8039558344586544\n",
      "F1 Score: 0.8183731169033328\n",
      "\n",
      "start RF 10 FGSM\n",
      "Accuracy: 0.8486856257798047\n",
      "\n",
      "macro\n",
      "Precision: 0.7973629716058097\n",
      "Recall: 0.7554426419126854\n",
      "F1 Score: 0.7726104023886358\n",
      "\n",
      "weighted\n",
      "Precision: 0.8415064900662234\n",
      "Recall: 0.8486856257798047\n",
      "F1 Score: 0.8429647056036316\n",
      "\n",
      "start RF 10 PGD\n",
      "Accuracy: 0.8039558344586544\n",
      "\n",
      "macro\n",
      "Precision: 0.6682013526769125\n",
      "Recall: 0.7268351438165676\n",
      "F1 Score: 0.6868889204308908\n",
      "\n",
      "weighted\n",
      "Precision: 0.8420896431590617\n",
      "Recall: 0.8039558344586544\n",
      "F1 Score: 0.8183731169033328\n",
      "\n",
      "start RF 10 DF\n",
      "Accuracy: 0.5071065989847716\n",
      "\n",
      "macro\n",
      "Precision: 0.508143406757287\n",
      "Recall: 0.5079302495382897\n",
      "F1 Score: 0.5042451587187065\n",
      "\n",
      "weighted\n",
      "Precision: 0.5082083425259205\n",
      "Recall: 0.5071065989847716\n",
      "F1 Score: 0.5038627836274728\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "Accuracy: 0.7653500408608008\n",
      "\n",
      "macro\n",
      "Precision: 0.7282777065491911\n",
      "Recall: 0.7518987518248788\n",
      "F1 Score: 0.7359684302413598\n",
      "\n",
      "weighted\n",
      "Precision: 0.7833669244056636\n",
      "Recall: 0.7653500408608008\n",
      "F1 Score: 0.771093922603651\n",
      "\n",
      "start RF 10 ZOO\n",
      "Accuracy: 0.7241427473985613\n",
      "\n",
      "macro\n",
      "Precision: 0.7360071325516508\n",
      "Recall: 0.7375520812398224\n",
      "F1 Score: 0.7241015376467217\n",
      "\n",
      "weighted\n",
      "Precision: 0.7503098822400199\n",
      "Recall: 0.7241427473985613\n",
      "F1 Score: 0.7245849869068753\n",
      "\n",
      "start RF 10 CaFA\n",
      "Accuracy: 0.6036879746572784\n",
      "\n",
      "macro\n",
      "Precision: 0.6164723650233603\n",
      "Recall: 0.6352966190995606\n",
      "F1 Score: 0.5937507267306594\n",
      "\n",
      "weighted\n",
      "Precision: 0.6907240390292131\n",
      "Recall: 0.6036879746572784\n",
      "F1 Score: 0.6177588575563802\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "Accuracy: 0.7903155975845961\n",
      "\n",
      "macro\n",
      "Precision: 0.712284274143596\n",
      "Recall: 0.7726152102557289\n",
      "F1 Score: 0.7291482171714347\n",
      "\n",
      "weighted\n",
      "Precision: 0.8319259844544401\n",
      "Recall: 0.7903155975845961\n",
      "F1 Score: 0.8031913971537056\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "Accuracy: 0.8092877349242361\n",
      "\n",
      "macro\n",
      "Precision: 0.650103159035948\n",
      "Recall: 0.6943791121019622\n",
      "F1 Score: 0.6657620868016073\n",
      "\n",
      "weighted\n",
      "Precision: 0.8388360325831673\n",
      "Recall: 0.8092877349242361\n",
      "F1 Score: 0.8214772315398824\n",
      "\n",
      "start RF 10 baseline\n",
      "Accuracy: 0.9100227790432802\n",
      "\n",
      "macro\n",
      "Precision: 0.7064220183486238\n",
      "Recall: 0.5171099950887977\n",
      "F1 Score: 0.5116555778505298\n",
      "\n",
      "weighted\n",
      "Precision: 0.8756974775866753\n",
      "Recall: 0.9100227790432802\n",
      "F1 Score: 0.873350892930959\n",
      "\n",
      "start RF 10 BIM\n",
      "Accuracy: 0.9419776627621902\n",
      "\n",
      "macro\n",
      "Precision: 0.9284317426945609\n",
      "Recall: 0.9548339794182812\n",
      "F1 Score: 0.9381072586517278\n",
      "\n",
      "weighted\n",
      "Precision: 0.9497670417632113\n",
      "Recall: 0.9419776627621902\n",
      "F1 Score: 0.9428419686909971\n",
      "\n",
      "start RF 10 FGSM\n",
      "Accuracy: 0.7084755403868032\n",
      "\n",
      "macro\n",
      "Precision: 0.7676535219582591\n",
      "Recall: 0.7631151610290773\n",
      "F1 Score: 0.7084141911728119\n",
      "\n",
      "weighted\n",
      "Precision: 0.8208551133116074\n",
      "Recall: 0.7084755403868032\n",
      "F1 Score: 0.7073219345786134\n",
      "\n",
      "start RF 10 PGD\n",
      "Accuracy: 0.9419776627621902\n",
      "\n",
      "macro\n",
      "Precision: 0.9284317426945609\n",
      "Recall: 0.9548339794182812\n",
      "F1 Score: 0.9381072586517278\n",
      "\n",
      "weighted\n",
      "Precision: 0.9497670417632113\n",
      "Recall: 0.9419776627621902\n",
      "F1 Score: 0.9428419686909971\n",
      "\n",
      "start RF 10 DF\n",
      "Accuracy: 0.3718213058419244\n",
      "\n",
      "macro\n",
      "Precision: 0.515595516949704\n",
      "Recall: 0.5145928462709285\n",
      "F1 Score: 0.37149800372033936\n",
      "\n",
      "weighted\n",
      "Precision: 0.6475231638463556\n",
      "Recall: 0.3718213058419244\n",
      "F1 Score: 0.3642971837395819\n",
      "\n",
      "start RF 10 AutoPGD\n",
      "Accuracy: 0.9770491803278688\n",
      "\n",
      "macro\n",
      "Precision: 0.9585034892925894\n",
      "Recall: 0.9832693004395665\n",
      "F1 Score: 0.9700139869184516\n",
      "\n",
      "weighted\n",
      "Precision: 0.9787105105007603\n",
      "Recall: 0.9770491803278688\n",
      "F1 Score: 0.9773507793233088\n",
      "\n",
      "start RF 10 ZOO\n",
      "Accuracy: 0.9579985390796202\n",
      "\n",
      "macro\n",
      "Precision: 0.6487765892044756\n",
      "Recall: 0.5390333773011413\n",
      "F1 Score: 0.5569074285939442\n",
      "\n",
      "weighted\n",
      "Precision: 0.9397954585728122\n",
      "Recall: 0.9579985390796202\n",
      "F1 Score: 0.9458349315063501\n",
      "\n",
      "start RF 10 CaFA\n",
      "Accuracy: 0.43051407510961426\n",
      "\n",
      "macro\n",
      "Precision: 0.610337466545869\n",
      "Recall: 0.5487886236203575\n",
      "F1 Score: 0.39617200392382246\n",
      "\n",
      "weighted\n",
      "Precision: 0.6790973859076953\n",
      "Recall: 0.43051407510961426\n",
      "F1 Score: 0.35364932745156713\n",
      "\n",
      "start RF 10 SINIFGSM\n",
      "Accuracy: 0.9561224489795919\n",
      "\n",
      "macro\n",
      "Precision: 0.962474185360932\n",
      "Recall: 0.948346299274197\n",
      "F1 Score: 0.9540733975550133\n",
      "\n",
      "weighted\n",
      "Precision: 0.9579297109886472\n",
      "Recall: 0.9561224489795919\n",
      "F1 Score: 0.9557825902086876\n",
      "\n",
      "start RF 10 VNIFGSM\n",
      "Accuracy: 0.9580272822665268\n",
      "\n",
      "macro\n",
      "Precision: 0.9568058256718529\n",
      "Recall: 0.9593600821399045\n",
      "F1 Score: 0.9577726747554371\n",
      "\n",
      "weighted\n",
      "Precision: 0.9587558704107182\n",
      "Recall: 0.9580272822665268\n",
      "F1 Score: 0.9580857731812364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0\n",
    "\n",
    "Def = \"Def4\"\n",
    "attack_names = [\n",
    "    \"baseline\", \"BIM\", \"FGSM\", \"PGD\", \"DF\",\n",
    "    \"AutoPGD\", \"ZOO\", \"CaFA\", \"SINIFGSM\", \"VNIFGSM\"\n",
    "]\n",
    "\n",
    "\n",
    "active_learning_name = [\"DensityWeighted\", \"BatchMode\"]\n",
    "\n",
    "base_path = \"/home/jovyan/Sample_Based_Extension/UNSW/UNSW_Dynamite_Selection_Data\"\n",
    "\n",
    "for ac_name in active_learning_name:\n",
    "    for m_name in model_name:\n",
    "        for p in percentage:\n",
    "            for attack in attack_names:\n",
    "                print(f\"start {m_name} {p} {attack}\")\n",
    "                \n",
    "                x_path = f\"{base_path}/{m_name}_ActiveLearning_{ac_name}/UNSW_Input{p}/x_test_adv_{attack}_{Def}.npy\"\n",
    "                y_path = f\"{base_path}/{m_name}_ActiveLearning_{ac_name}/UNSW_Input{p}/y_test_adv_{attack}_{Def}.npy\"\n",
    "    \n",
    "                try:\n",
    "                    x_test_adv = np.load(x_path)\n",
    "                    y_test_adv = np.load(y_path)\n",
    "                    m_per_name = f\"{m_name}{p}_ActiveLearning_{ac_name}\"\n",
    "                    calculate_performance_metrics(x_test_adv, y_test_adv, model, m_per_name, attack, epsilon)\n",
    "                except FileNotFoundError:\n",
    "                    print(x_path, \"not found\")\n",
    "                    print_empty_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180bbf0-a46d-495c-a138-34c6aa1c257e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fdd08f-c86d-4544-804e-c1bf1c0cf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.save(model.state_dict(), \"./Free_Adversarial_Training.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12f42d01-6668-43aa-98b6-f449e2673e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# epsilon_values = [0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# for epsilon in epsilon_values:\n",
    "#     filename = f'/home/jovyan/Sample_Based_Extension/UNSW/transfer_attack/x_test_adv_BIM_eps_{epsilon}.npy'\n",
    "#     x_test_adv = np.load(filename)\n",
    "\n",
    "#     calculate_performance_metrics(x_test_adv, y_test, model, 'DNN', 'BIM', epsilon)\n",
    "\n",
    "# end_time = time.time()\n",
    "# result = end_time - start_time\n",
    "# print(f\"Execution Time: {result:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e0229-c943-472c-bd6a-cd87d7826807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
